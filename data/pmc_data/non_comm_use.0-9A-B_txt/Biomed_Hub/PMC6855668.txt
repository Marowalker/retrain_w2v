
==== Front
Biomed HubBiomed HubBMHBiomedicine Hub2296-6870S. Karger AG Allschwilerstrasse 10, P.O. Box · Postfach · Case postale, CH-4009, Basel, Switzerland · Schweiz · Suisse, Phone: +41 61 306 11 11, Fax: +41 61 306 12 34, karger@karger.ch 10.1159/000499074bmh-0004-0001Research ArticleBalance and Sound Conditions in Adults with Bilateral Cochlear Implants Tonini Ross aCohen Helen S. a*Mulavara Ajitkumar P. bSangi-Haghpeykar Haleh caBobby R. Alford Department of Otolaryngology – Head and Neck Surgery, Baylor College of Medicine, Houston, Texas, USAbKBRwyle, Houston, Texas, USAcDepartment of Obstetrics and Gynecology, Baylor College of Medicine, Houston, Texas, USA*Helen S. Cohen, EdD, OTR, Bobby R. Alford Department of Otolaryngology – Head and Neck Surgery, Baylor College of Medicine, One Baylor Plaza, Houston, TX 77030 (USA), E-Mail hcohen@bcm.eduJan-Apr 2019 25 4 2019 25 4 2019 4 1 1 9 22 11 2018 18 2 2019 2019 Copyright © 2019 by S. Karger AG, Basel2019This article is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND) (http://www.karger.com/Services/OpenAccessLicense). Usage and distribution for commercial purposes requires written permission.Purpose
To determine if (1) balance is impaired in patients with bilateral cochlear implants compared to healthy controls and (2) the presence of sound, non-speech, or speech affects standing balance.

Materials and Methods
Four patients with bilateral cochlear implants were tested on three balance conditions on Romberg tests on medium-density compliant foam with eyes closed, with head stationary or moving in yaw or pitch, under 5 sound conditions: no sound, ambient background noise, pink noise, foreign language, English language.

Results
Dependent measures were duration of standing and kinematics. Three of four subjects performed well with head still and no sound, background noise, or pink noise. All subjects performed poorly during the head movement conditions when hearing either foreign-language or English words. Subjects could not perform enough head movements during yaw and pitch conditions for accurate kinematic measurements.

Conclusion
The no-sound condition did not influence standing balance skills. The addition of ambient or pink noise also did not affect their balance. However, when subjects were distracted by paying attention to words, regardless whether or not they understood the words, standing balance skills deteriorated. Thus, distracted attention in these patients leads to impaired balance, which may impair functional motor skills.

Keywords
Postural controlRombergDual task performanceAttention
==== Body
What Is It about?
Some research suggests that sounds may affect standing balance. We tested the standing balance of 4 subjects who each had cochlear implants in both ears. They stood with eyes closed on compliant foam, so that the support surface was continuously unstable, sometimes when the person was moving his head, which is very challenging. Subjects heard no sound at all, minimal background noise, more background noise, and English and Romanian speakers. No sound and background noise did not affect balance skills. Balance decreased when people listened to either language. Therefore, being distracted by paying attention to words can affect balance.

Introduction
The influence of hearing on balance is unclear. Some older studies have shown that moving auditory fields cause increased postural sway during quiet standing, especially in older adults [1, 2]. The frequencies of the stimuli in those studies are unknown. More recent work showed that in elderly subjects hearing a rotating auditory sound that was meaningful, i.e., a story, was associated with reduced postural sway, but hearing a rotating non-meaningful sound, the musical note A at 440 Hz, was not associated with increased sway [3]. Describing a study that used a 500 Hz auditory signal during posturography testing, the authors concluded that the response was probably vestibular rather than cochlear in nature [4]. The 440 Hz signal used by Deviterne et al. [3] may have stimulated the saccule as well as the cochlea, as in vestibular evoked myogenic potentials, although the speech sounds would have had a much wider range. Research on vestibular evoked myogenic potentials has shown that low-frequency sounds influence the utricle and saccule and generate minute but recordable postural responses in the sternocleidomastoid muscles [5]. A slight but ill-defined effect of some musical tones was found in a study of middle-aged normal subjects who heard particular musical tones imbedded in a musical composition [6]. By contrast, normal young adults in their 20s have been shown to have reduced postural sway when listening to a moving white noise stimulus compared to a stationary stimulus or ambient noise [7]. In general, these studies show a slight effect of auditory stimuli in normal adults. When normal young adults were tested on the Clinical Test of Sensory Integration on Balance (CTSIB) with pink noise (100 Hz–4 kHz) in the background, subjects were more reliant on visual cues than when hearing was unavailable [8]. Furthermore, two different groups have shown that in normal subjects, postural sway was increased when ambient noise was unavailable [9, 10]. Recent work has also shown that postural sway decreases in seniors and young adults in the presence of white noise versus ambient noise [11].

The cognitive load inherent in hearing sounds may have determined the auditory influence on balance. Audio biofeedback has been shown to reduce postural sway during quiet standing with eyes closed in patients with bilateral vestibular impairment [12]. The frequency of that audio biofeedback might have been the same 400 Hz signal used in a subsequent study with that patient population [13]. In other studies, the same authors showed that an oscillating sound, from 20 to 50 dB SPL (400 to 1,000 Hz), was effective in reducing postural control during quiet standing in healthy subjects with intact vestibular systems [14], but a simpler signal at 400 Hz was also effective [15]. A different group also used an auditory signal, 60–95 dB SPL, to cue bilateral vestibular loss subjects about angular position or velocity compared to no feedback [16]. Subjects given the auditory feedback reduced their postural sway. Thus, vestibularly impaired subjects can learn to use an auditory biofeedback signal.

In subjects with known hearing impairments who wore hearing aids, the performance on quiet standing with eyes closed on foam, i.e., the modified Romberg or CTSIB [17, 18], was improved in the presence of broadband white noise (0–4 kHz) compared to without sound [19]. A study of cochlear implant users showed that these subjects were impaired on stabilometry with head still or during head movement conditions compared to normal controls; whether or not they could hear ambient noise, or their implants were off so that they heard nothing [20]. Another study in bilateral or bimodal cochlear implant users showed that with their implants turned on in the presence of white noise (0–4 kHz, 65 dB) postural sway was reduced compared to the test condition with implants turned off [21].

We tested subjects with bilateral cochlear implants on CTSIB using 5 different sound conditions and 3 different head movement conditions. The goal of the study was to determine if patients with bilateral cochlear implants have impaired standing balance compared to norms established with healthy controls tested previously [18] and to determine if the presence of sound, particular types of sound, or speech, affects standing balance.

Materials and Methods
Subjects
Subjects were patients who had bilateral cochlear implants, with the devices implanted at least 2 months apart. Subjects had no history of vertigo, central neurological lesions, peripheral neuropathy, or significant musculoskeletal problems. All subjects had been implanted with Cochlear Corporation implants (Cochlear Corporation, Sydney, NSW, Australia) and all were tested using the Cochlear Nucleus 5 speech processor with their routinely used map without modification for this study. No subjects had residual hearing after implantation for either ear. All subjects were ambulatory without gait aids. They were all fluent in English but did not speak Romanian. They gave written informed consent prior to participation. This study was approved by the Institutional Review Board for Human Subjects Research for the senior author's institution.

Instrumentation
All subjects were tested in an Otometrics (Quebec, QC, Canada) double-wall acoustically treated sound booth (1.96 m × 2.25 m × 1.98 m). They stood on a medium-density Sunmate compliant foam square (0.46 m × 0.46 m), PSI = 93 (Dynamic Systems, Leicester, NC, USA). The back edge of the foam block was 1.52 m from the corner of the sound-treated room facing a sound field speaker at a height of 1 m that was 1.34 m from the person standing on the foam block.

Test Conditions
Subjects were tested under 5 sound conditions: (1) No sound (both processors off); (2) Ambient background noise only – bilateral processors on, (3) Speech-weighted noise with bilateral implants on, (4) Conversational speech – bilateral implants on (Romanian language sample), (5) Conversational speech – bilateral implants on (English language sample). The digitally recorded Romanian speech sample was a 2-min weather forecast in Romanian spoken by a male native Romanian speaker of the faculty of this department. Romanian was used because it is easily recognizable as a language, but our participants were unlikely to be familiar with it. The English language sample was a digitally recorded version of the Rainbow Passage [22] read by a male speaker (Otosuite Audiometry Module, GN Otometrics, 2011).

Prior to balance testing, the speech reception threshold of each subject was measured in the binaural configuration in the sound field. Subsequently, for all sound conditions, the stimulus sound was presented at an intensity level that was 30 dB greater than each subject's measured bilateral speech reception threshold in the sound field, so that the subjects could hear the stimuli. The noise stimulus in condition 3 and the speech stimuli from condition 4 and condition 5 were all presented at 0° relative to the subject.

Subjects wore socks but no shoes. They stood on the foam with feet next to each other and arms crossed. A 0.33 Hz tone was used to cue head movement trials using an auditory signal that oscillated between 170 and 450 Hz at a comfortable intensity level via the amplifier on a laptop computer. For no-sound trials, when subjects could not hear the auditory cue from the computer, to cue head movements, the subject held a smart phone running a 0.33 Hz signal on the Vibronome vibrating metronome app. Before the head movement trials, subjects practiced moving the head movements while standing on the floor and holding the smart phone or hearing the tone. When fatigued, they were allowed to sit down to rest.

We attempted to obtain kinematic data by having subjects wear two lightweight inertial motion units (Xsens North America, Inc., 5.25 × 3.75 × 2 cm, weight 28.3 g) centered on the head with a headband and centered on the mid-torso back with a lightweight vest, as in previous work [18]. We also counted the number of head movements during head movement trials by observation.

Protocol
All balance tests were given in the same order, with trials lasting up to 30 s: head still, head moving in yaw (shaking “No”, left to right), nodding in pitch (nodding “Yes”, up-down) per established protocol [18]. Sound conditions were given in pseudorandom order to avoid potential order effects. Dependent measures were the length of time the subject could perform the trial and the number of head movements the subject could make during pitch and yaw head movement trials.

Statistical Methods
At each head movement condition (still, yaw, pitch), we assessed the association between trial duration (study outcome) and various sound conditions (no sound, background noise, pink noise, a paragraph in Romanian, a paragraph in English). This was done by using linear mixed methods where we compared least square means of trial duration between different sound conditions. All analyses were performed in SAS (Version 9.4, Cary, NC, USA).

Results
The sample included 4 patients: 2 males and 2 females, aged 48, 65, 70, and 79 years. Although other patients seen in this clinic have had bilateral cochlear implants, no other patients met all of the inclusion criteria. Subjects' ages, relative dates of surgery and testing, and implant details are shown in Table 1. The treating neurotologists were unable to make definitive diagnoses, but all 4 subjects had documented, progressive sensorineural hearing loss; none had Ménière's disease.

At each sound condition, the longest trial duration was found when the head was still (p < 0.0001), as shown in Figure 1. With the exception of the 48-year-old subject, on the no-sound condition with the head still, subjects stood for longer than most healthy controls under that condition. The 48-year-old subject's performance was better in the ambient noise and pink noise conditions with the head still. As shown in Figure 1, at the head still or pitch condition, no differences in trial duration were seen across the various noise conditions. With the head moving in yaw, no differences were found between the background noise and pink noise conditions, but there was a trend for decreased trial durations when subjects heard Romanian (6.4 s difference, p = 0.1) and English (7.4 s difference, p = 0.06). No such changes were found with the head moving in pitch (see Fig. 1).

To calculate kinematic measures accurately, we needed 5 cycles of head movements. Similar to many hearing subjects with chronic vestibular impairments [18], these subjects were unable to generate enough head movements during yaw and pitch trials. No apparent differences were found during the head still trials. Therefore, the kinematic analyses will not be discussed further.

The number of head movements might have indicated the difficulty of the task. In the yaw rotation trials, subjects made significantly fewer head movements in the Romanian language condition compared to the background noise condition (p = 0.03), and in the English language condition compared to the background noise condition (p = 0.019). In the pitch rotation trials, no differences were found in any of the sound conditions (see Fig. 2).

Discussion/Conclusion
Although no post-implant audiograms under insert earphones are available for any of the patients included in this series, based on a review of their pre-implant audiograms, and considering the era during which they were implanted and the electrodes with which they were implanted, we have no expectation that they would have had any meaningful low-frequency detection in either of the implanted ears. Previous research has shown that the presence of a low-frequency sound has no effect on measures of balance in normal-hearing adults [23], but high-frequency sound does have an effect of reduced postural sway. Therefore, the presence or absence of known low-frequency hearing in our study group is not the reason for the effects observed in this study. The probable lack of low-frequency hearing in our subjects and the lack of differences on the no-sound, background noise, and pink noise conditions is consistent with the existing literature. Our data suggest that the absence of sound, per se, does not impair simple standing balance. Unlike previous work with normal subjects [8, 9, 10, 11], or recent work with cochlear implant users [21], our small sample of bilateral cochlear implant users had no change in performance time across the sound conditions of absence of noise, ambient noise, or pink noise.

The lack of attention to sound may even have conferred a slight advantage in older people during quiet standing with the head still. Quiet standing, even without apparent dual tasking, is more challenging for older people than younger people [18, 24]. Dual tasking is also more challenging for older people than younger people [25]. The three older subjects all had balance at least as good as comparable hearing healthy controls [18]. The presence of ambient noise during head-still conditions did not affect performance significantly or even noticeably. Thus, the absence of the need to attend to anything other than maintaining balance may have helped the older subjects. The cochlear implant, per se, would not have conferred an advantage, but the total absence of sound might have provided a less distracting experience, with a hitherto unknown type of dual-tasking paradigm. Perhaps hearing some routine background noise actually does provide a type of dual-tasking for older subjects, as older adults are known to perform dual-tasking during balance worse than younger adults [26]. That idea has not been previously tested.

The effect of listening to speech was different. Listening to a voice provides a kind of cognitive task, so that listening to a voice and balancing is a type of dual tasking. In some elderly people, conversation during walking has been shown to be problematic [27, 28]. The English and Romanian language conditions presented such a dual-task problem, demanding divided attention. Similar to a previous study [3], we found differences in balance when subjects listened to language compared to their responses when they listened to noise. The results in the present study show that the language does not have to be intelligible to the listener. People tend to listen to words, probably trying to understand them, suggesting that sound with no meaning attached, i.e. the kind of random, ambient noise that is present constantly in our lives, has minimal influence on attention or balance during a balance task that is not very challenging.

The data in the present study support the idea that multitasking caused by adding a cognitive load makes that task more challenging. The cochlear implant, per se, does not cause a balance problem. Instead, because these people were so hearing-impaired, they had to work harder to derive meaning from sound when they knew the meaning should be there. In so doing, attentional resources were diverted from the novel and challenging balance task, thus making the balance task more difficult.

When subjects heard sentences spoken in either language, one in which they were fluent and one which they had never heard, in the yaw head movement trials, their balance tended to deteriorate. Thus, being distracted by speech while standing impairs simple balance skills in the yaw condition. These results, along with the finding that distraction did not affect balance during pitch head rotations, should be taken with caution as these interpretations are based on a small group of subjects. A study to investigate these issues systematically in a larger population is warranted. In tests of standing balance alone, pitch and yaw head movements appear to be equally challenging, but apparently the cognitive load is greater with yaw rather than pitch head movements.

The type of cognitive load may have affected performance under different sound conditions. Background noise poses a minimal cognitive load. Listening to language, whether comprehensible or not, poses a higher cognitive load. Fraizer and Mitra [26] reviewed the evidence about dual tasking and postural control and suggested that two possible mechanisms could be responsible for degraded performance during high cognitive load, either an absolute limit on cognitive capacity or a bottleneck in cognitive processing due to serial processing mechanisms. We are unable to determine which type of processing problem is most likely to be involved in this case.

Therefore, hearing-impaired patients should be careful when performing motor tasks in noisy environments if they will need to pay attention to some sounds such as voices or safety signals. These individuals might benefit from rehabilitation that introduces progressively greater cognitive sound challenges as an aspect of training dual-task performance during the execution of motor tasks, especially tasks that include balance components.

This study had some limitations. The sample size was small. In this institution few patients are implanted with bilateral cochlear implants. Of that limited group, fewer people met the inclusion criteria of being able to stand unassisted and without having joint replacements. Post hoc power analyses indicated that in the English language condition having 6 subjects would have yielded significant differences and in the Romanian language condition having 7 subjects would have yielded significant differences. Nonetheless, even with this small sample the magnitude of differences between the groups is large and the findings should be taken seriously.

Another minor limitation is that we used only one language which was unknown to subjects. Romanian is a Latin-based language and has some similarities to English. The results might have been different, perhaps even greater in magnitude, had we used a language that is more different from English, such as Chinese.

Statement of Ethics
Subjects gave written informed consent.

The study has been approved by the Institutional Review Board for Baylor College of Medicine and Affiliated Hospitals.

Disclosure Statement
The authors have no conflicts of interest to declare.

Funding Sources
This study was supported by NIH grant R01-DC009031 (HSC).

Author Contributions
Drs. Tonini and Cohen conceived the experiment. All authors contributed to the design of the experiment. Drs. Tonini and Cohen collected the data. Drs. Sangi-Haghpeykar and Mulavara analyzed the data. All authors contributed to interpreting the data. Dr. Cohen drafted the manuscript. Drs. Tonini, Mulavara, and Sangi-Haghpeykar contributed to revising the manuscript critically for important scientific content. All authors gave final approval of the submitted manuscript. All authors agree to be accountable for all aspect of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriate.

Acknowledgements
We thank the staff of the Center for Hearing and Balance, Baylor College of Medicine, and Chris Miller, KBRwyle, for their assistance.

Fig. 1 Mean trial duration influenced by sound and head movement conditions. Error bars are standard errors. The symbols for the yaw and pitch head movement conditions have been displaced rightward from the symbol for head still for improved visualization of the symbols and error bars. Sound conditions were None (processors off), ambient background noise (Ambient), speech-weighted noise (Sound-wt), Romanian language passage (Romanian), and English language passage (English). Head movement conditions were head still (None), head moving at 0.33 Hz in yaw (Yaw), and head moving at 0.33 Hz in pitch (Pitch).

Fig. 2 Mean number of head movements influenced by sound and head movement conditions. Sound conditions were None (processors off), ambient background noise (Ambient), speech-weighted noise (Sound-wt), Romanian language passage (Romanian), and English language passage (English). Head movement conditions were head still (None), head moving at 0.33 Hz in yaw (Yaw), and head moving at 0.33 Hz in pitch (Pitch).

Table 1 Subject details: age at test, internal device and external device per ear

Subject	Age, years	Right ear	Left ear	Test time from first implant, months	
1	48	Freedom CI24RE Contour
Advance (Nucleus 5) 1	2.25 months 2
Freedom CI24RE Contour
Advance (Nucleus 5)	54.5	
 	
2	65	21.25 months 2
Freedom CI24 Contour
Advance (Nucleus 5)	CI512 (Nucleus 5) 1	64.75	
 	
3	70	CI24RE (Nucleus 5) 1	1.75 months 2
CI24RE (Nucleus 5)	146.1	
 	
4	79	CI24RE Nucleus 24 Contour
(Nucleus 5) 1	104.75 months 2
Freedom CI24RE Contour
Advance (Nucleus 5)	149.25	
1 First implant.

2 Second implant, length of time from first to second implants, length of time from first implant to test in this study.
==== Refs
References
1 Soames RW  Raper SA   The influence of moving auditory fields on postural sway behaviour in man Eur J Appl Physiol Occup Physiol 1992 65 (3) 241 5 1396653 
2 Tanaka T  Kojima S  Takeda H  Ino S  Ifukube T   The influence of moving auditory stimuli on standing balance in healthy young adults and the elderly Ergonomics 2001 12 44 (15) 1403 12 11936831 
3 Deviterne D  Gauchard GC  Jamet M  Vançon G  Perrin PP   Added cognitive load through rotary auditory stimulation can improve the quality of postural control in the elderly Brain Res Bull 2005 1 64 (6) 487 92 15639544 
4 Alessandrini M  Lanciani R  Bruno E  Napolitano B  Di Girolamo S   Posturography frequency analysis of sound-evoked body sway in normal subjects Eur Arch Otorhinolaryngol 2006 3 263 (3) 248 52 16450156 
5 Fife TD  Colebatch JG  Kerber KA  Brantberg K  Strupp M  Lee H    Practice guideline: Cervical and ocular vestibular evoked myogenic potential testing: Report of the Guideline Development, Dissemination, and Implementation Subcommittee of the American Academy of Neurology Neurology 2017 11 89 (22) 2288 96 29093067 
6 Pagnacco G  Klotzek AS  Carrick FR  Wright CH  Oggero E   Effect of tone-based sound stimulation on balance performance of normal subjects: preliminary investigation Biomed Sci Instrum 2015 51 54 61 25996699 
7 Gandemer L  Parseihian G  Kronland-Martinet R  Bourdin C   The influence of horizontally rotating sound on standing balance Exp Brain Res 2014 12 232 (12) 3813 20 25146572 
8 Maheu M  Sharp A  Landry SP  Champoux F   Sensory reweighting after loss of auditory cues in healthy adults Gait Posture 2017 3 53 151 4 28157577 
9 Kanegaonkar RG  Amin K  Clarke M   The contribution of hearing to normal balance J Laryngol Otol 2012 10 126 (10) 984 8 22906584 
10 Vitkovic J  Le C  Lee SL  Clark RA   The contribution of hearing and hearing loss to balance control Audiol Neurotol 2016 21 (4) 195 202 
11 Ross JM  Will OJ  McGann Z  Balasubramaniam R   Auditory white noise reduces age-related fluctuations in balance Neurosci Lett 2016 9 630 216 21 27495013 
12 Dozza M  Chiari L  Horak FB   Audio-biofeedback improves balance in patients with bilateral vestibular loss Arch Phys Med Rehabil 2005 7 86 (7) 1401 3 16003671 
13 Dozza M  Horak FB  Chiari L   Auditory biofeedback substitutes for loss of sensory information in maintaining stance Exp Brain Res 2007 3 178 (1) 37 48 17021893 
14 Dozza M  Chiari L  Hlavacka F  Cappello A  Horak FB   Effects of linear versus sigmoid coding of visual or audio biofeedback for the control of upright stance IEEE Trans Neural Syst Rehabil Eng 2006 12 14 (4) 505 12 17190042 
15 Dozza M  Chiari L  Peterka RJ  Wall C  Horak FB   What is the most effective type of audio-biofeedback for postural motor learning? Gait Posture 2011 7 34 (3) 313 9 21703858 
16 Hegeman J  Honegger F  Kupper M  Allum JH   The balance control of bilateral peripheral vestibular loss subjects and its improvement with auditory prosthetic feedback J Vestib Res 2005 15 (2) 109 17 15951624 
17 Shumway-Cook A  Horak FB   Assessing the influence of sensory interaction of balance. Suggestion from the field Phys Ther 1986 10 66 (10) 1548 50 3763708 
18 Cohen HS  Mulavara AP  Peters BT  Sangi-Haghpeykar H  Bloomberg JJ   Standing balance tests for screening people with vestibular impairments Laryngoscope 2014 2 124 (2) 545 50 23877965 
19 Rumalla K  Karim AM  Hullar TE   The effect of hearing aids on postural stability Laryngoscope 2015 3 125 (3) 720 3 25346316 
20 Bernard-Demanze L  Léonard J  Dumitrescu M  Meller R  Magnan J  Lacour M   Static and dynamic posture control in postlingual cochlear implanted patients: effects of dual-tasking, visual and auditory inputs suppression Front Integr Nuerosci 2014 1 7 111 
21 Shayman CS  Mancini M  Weaver TS  King LA  Hullar TE   The contribution of cochlear implants to postural stability Laryngoscope 2018 7 128 (7) 1676 80 29114889 
22 Fairbanks G   Voice and Articulation Drillbook 1937 New York Harper and Brothers 
23 Siedlecka B  Sobera M  Sikora A  Drzewowska I   The influence of sounds on posture control Acta Bioeng Biomech 2015 17 (3) 96 102 26685979 
24 Cohen H  Heaton LG  Congdon SL  Jenkins HA   Changes in sensory organization test scores with age Age Ageing 1996 1 25 (1) 39 44 8670527 
25 Verhaeghen P  Cerella J   Aging, executive control, and attention: a review of meta-analyses Neurosci Biobehav Rev 2002 11 26 (7) 849 57 12470697 
26 Fraizer EV  Mitra S   Methodological and interpretive issues in posture-cognition dual-tasking in upright stance Gait Posture 2008 2 27 (2) 271 9 17524648 
27 Lundin-Olsson L  Nyberg L  Gustafson Y   “Stops walking when talking” as a predictor of falls in elderly people Lancet 1997 3 349 (9052) 617 
28 Hyndman D  Ashburn A   Stops walking when talking as a predictor of falls in people with stroke living in the community J Neurol Neurosurg Psychiatry 2004 7 75 (7) 994 7 15201358


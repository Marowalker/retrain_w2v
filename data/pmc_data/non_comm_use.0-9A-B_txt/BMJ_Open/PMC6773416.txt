
==== Front
BMJ OpenBMJ OpenbmjopenbmjopenBMJ Open2044-6055BMJ Publishing Group BMA House, Tavistock Square, London, WC1H 9JR bmjopen-2019-03131310.1136/bmjopen-2019-031313OphthalmologyOriginal Research15061718Keratoconus detection using deep learning of colour-coded maps with anterior segment optical coherence tomography: a diagnostic accuracy study Kamiya Kazutaka 1Ayatsuka Yuji 2Kato Yudai 2Fujimura Fusako 1Takahashi Masahide 3Shoji Nobuyuki 3Mori Yosai 4Miyata Kazunori 4
1 
Visual Phisiology, School of Allied Health Sciences, Kitasato University, Sagamihara, Japan

2 
Cresco Ltd, Technology Laboratory, Tokyo, Japan

3 
Department of Ophthalmology, School of Medicine, Kitasato University, Sagamihara, Japan

4 
Miyata Eye Hospital, Department of Ophthalmology, Miyakonojo, Japan
Correspondence to  Dr Kazutaka Kamiya; kamiyak-tky@umin.ac.jp2019 27 9 2019 9 9 e03131302 5 2019 21 8 2019 30 8 2019 © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.2019This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.Objective
To evaluate the diagnostic accuracy of keratoconus using deep learning of the colour-coded maps measured with the swept-source anterior segment optical coherence tomography (AS-OCT).

Design
A diagnostic accuracy study.

Setting
A single-centre study.

Participants
A total of 304 keratoconic eyes (grade 1 (108 eyes), 2 (75 eyes), 3 (42 eyes) and 4 (79 eyes)) according to the Amsler-Krumeich classification, and 239 age-matched healthy eyes.

Main outcome measures
The diagnostic accuracy of keratoconus using deep learning of six colour-coded maps (anterior elevation, anterior curvature, posterior elevation, posterior curvature, total refractive power and pachymetry map).

Results
Deep learning of the arithmetical mean output data of these six maps showed an accuracy of 0.991 in discriminating between normal and keratoconic eyes. For single map analysis, posterior elevation map (0.993) showed the highest accuracy, followed by posterior curvature map (0.991), anterior elevation map (0.983), corneal pachymetry map (0.982), total refractive power map (0.978) and anterior curvature map (0.976), in discriminating between normal and keratoconic eyes. This deep learning also showed an accuracy of 0.874 in classifying the stage of the disease. Posterior curvature map (0.869) showed the highest accuracy, followed by corneal pachymetry map (0.845), anterior curvature map (0.836), total refractive power map (0.836), posterior elevation map (0.829) and anterior elevation map (0.820), in classifying the stage.

Conclusions
Deep learning using the colour-coded maps obtained by the AS-OCT effectively discriminates keratoconus from normal corneas, and furthermore classifies the grade of the disease. It is suggested that this will become an aid for improving the diagnostic accuracy of keratoconus in daily practice.

Clinical trial registration number
000034587.

deep learningkeratoconusdiagnosisaccuracyoptical coherence tomographyspecial-featureunlocked
==== Body
Strengths and limitations of this study
Deep learning using the image of corneal colour-coded maps with anterior segment optical coherence tomography (AS-OCT) based on clinical diagnosis has not so far been investigated for keratoconus detection and grade classification.

Deep learning using colour-coded maps obtained from the AS-OCT will be an aid not only for the screening of keratoconus, but also for the grade classification of the disease.

This deep learning was not applied to other corneal disorders such as forme fruste keratoconus, subclinical keratoconus, or postsurgical eyes.

The arithmetic mean outputs from the six classifiers without any weighting were utilised for classifying the grade of the disease.

Introduction
Keratoconus is one of progressive corneal disorders characterised by anterior protrusion and thinning. The progressive thinning and the subsequent bulging of the cornea are often accompanied by high myopic astigmatism, as well as by irregular astigmatism, resulting in severe visual impairment. The elimination of keratoconus is essential for refractive surgery candidates, since iatrogenic keratectasia can occur when performing keratorefractive surgery in such eyes.

Deep learning is one of the machine learning techniques dealing with the training of multilayer artificial neural networks. Machine learning is a general technique to find appropriate parameters or functions to classify input data from large amounts of training data. Many methodologies to implement machine learning, such as support vector machines, decision trees, or neural networks, have so far been advocated. In recent years, multilayered neural networks, especially convolutional neural networks, have achieved impressive results in many types of image classifications in many scientific fields.1–3 Number of layers often referred to as a kind of depth, and then machine learning with multilayered neural network is called deep learning. In ophthalmology, it has been mainly applied in the diagnosis of retinal diseases4–6 and glaucoma.7–9 Until now, there have been several studies on the sensitivity and the specificity of keratoconus detection using machine learning.10–22 However, most previous studies have merely used either topographic numeric indices measured with a Placido disk-based corneal topographer, or tomographic numeric indices measured with a scanning slit tomographer and a rotating Scheimpflug camera, for machine learning in order to discriminate keratoconus from normal corneas. Accordingly, deep learning using the whole image of corneal colour-coded maps with the anterior segment optical coherence tomography (AS-OCT) based on clinical diagnosis, which enables us to precisely determine the curvature and the elevation of the anterior and posterior corneal surfaces even in eyes with opaque cornea, has not so far been performed to determine the diagnostic accuracy or the grade of keratoconus. It may give us intrinsic insights on keratoconus detection especially in the preoperative screening of the candidates for corneal refractive surgery, because it can result in unpredictable outcomes and subsequent corneal ectasia, when applied to such eyes. The aim of the current study is to assess the accuracy of deep learning using anterior and posterior corneal elevations, curvatures, total refractive power, and pachymetry map, obtained by the AS-OCT, in order to discriminate between normal and keratoconic eyes, as well as to classify the stage of the disease, according to the Amsler-Krumeich classification.

Materials and methods
Study population
We retrospectively reviewed the data of keratoconic patients who underwent corneal tomography obtained by a swept-source AS-OCT (CASIA SS-1000, Tomey, Aichi, Japan) between March 2013 and April 2018 at Miyata Eye Hospital. We enrolled 304 eyes with good quality scans of corneal tomography. Keratoconus was diagnosed by corneal specialists with evident findings characteristic of keratoconus (eg, corneal tomography with asymmetric bow-tie pattern with or without skewed axes), and at least one keratoconus sign (eg, stromal thinning, conical protrusion of the cornea at the apex, Fleischer ring, Vogt striae, or anterior stromal scar) on slit-lamp examination.23 The grade of keratoconus was determined by the Amsler-Krumeich classification, based on astigmatism, corneal power, corneal transparency, and corneal thickness, obtained from the slit-lamp biomicroscopy and the AS-OCT.24 The study group was divided into four keratoconus subgroups; grade 1 (108 eyes), 2 (75 eyes), 3 (42 eyes) and 4 (79 eyes), according to this classification. Other corneal diseases such as pellucid marginal degeneration and eyes with a history of trauma or corneal surgery such as corneal cross-linking for progressive keratoconus were excluded from the study. The patients were recruited in a continuous cohort. The control group comprised of 239 eyes in subjects with normal corneal and ocular findings applying for a contact lens fitting or a refractive surgery consultation. The control subjects had a refractive error (spherical equivalent) of less than 6 dioptres (D) and/or astigmatism of less than 3 D. The patients who wore rigid and soft contact lenses were asked to stop using them for 3 weeks and 2 weeks, respectively, before this assessment. Our Institutional Review Board waived the requirement for informed consent for this retrospective study. The data that support the findings of this study are available from the corresponding author on reasonable request.

Anterior segment optical coherence tomography imaging
We obtained six standardised colour-coded maps (anterior elevation (−130 to 130 µm, 5 µm step), anterior curvature (9.0 to 101.5 D, 5 D step (35.5 to 50.5 D, 1.5 D step)), posterior elevation (−260 to 260 µm, 10 µm step), posterior curvature (−3.0 to −10.5 D, 0.3 D step), total refractive power (9.0 to 101.5 D, 5 D step (35.5 to 50.5 D, 1.5 D step)) and pachymetry map (340 to 840 µm, 20 µm step)), based on the manufacturer’s instructions, by experienced examiners who were masked to the clinical condition of the subjects, using the swept-source AS-OCT (figure 1). In each map, a colour-scale bar was excluded for deep learning. The device utilises a wavelength of 1310 nm, with an axial resolution of 10 µm, a transverse resolution of 30 µm and a scan-rate of 30 000 A-scans/s. The patient’s chin was placed on the chin rest and the forehead against the forehead strap. The patient was asked to open both eyes and stare at the fixation target. After attaining perfect alignment, the instrument automatically began obtaining the measurements. The scan was initiated when a cross-sectional image of the cornea was visualised on a computer screen. Collected data were processed by the system to achieve cross-sectional images. Image quality was checked, and only one examination with a high image quality factor was recorded.

Figure 1 A representative example of six colour-coded maps (anterior elevation, anterior curvature, posterior elevation, posterior curvature, total refractive power and pachymetry map) measured with an anterior segment optical coherence tomography. A colour-scale bar was excluded in each map for deep learning.

Deep learning
Neural network is one of the powerful tools available for classifying data into some groups or categories. Convolutional neural network is a variation of neural network for classifying images or two-dimensional data.1–3 A typical convolutional neural network consists of mainly two types of layers: a convolution layer and a fully connected layer. A convolution layer automatically extracts two-dimensional patterns and their geometrical relations to distinguish training data, and finds out these characteristics in images. Colour-coded maps provide much information of the corneal shape as well as two-dimensional patterns, so that convolutional neural networks are expected to classify them well.

We exported each image data by taking a screenshot of the CASIA2 application displaying six types of corneal images, and stored it in a lossless compression format such as PNG. After that we cut out each type of images from the screenshots, we saved it in PNG format for deep learning. We used an open source deep learning platform (PyTorch) for deep learning with a network model called a ResNet-18. The ResNet-18 is one of the available convolutional neural networks which is pretrained with millions of images from the ImageNet database. Each input image is resized to 224-by-224 pixels without deformation. The output is one value (0–4) that can be mapped to the grades (including normal eyes). ‘Normal’ is represented as ‘0’, and grades 1, 2, 3 and 4 are denoted as ‘1’, ‘2’, ‘3’ and ‘4’ in teaching data. The output value of neural network for an image is not an integer, so that we aligned it to the nearest integer value to interpret. For example, if an output is 1.37, it is interpreted as 1, that is, grade 1.

We separately trained six neural networks from each image of six colour-coded maps (anterior elevation, anterior curvature, posterior elevation, posterior curvature, total refractive power and pachymetry map) without a colour-scaled bar. Each network classifies an image into 0–4. We integrated these six outputs by averaging them. For example, if these six classifiers outputs are 2, 2, 2, 3, 4 and 3, their average is 2.67, resulting in an integrated result of 3. We applied a floor function for values such as 2.5, that is, it was interpreted as 2. A total of 543 eyes were split into five groups (108 or 109 eyes in each group). We used fivefold cross-validation to increase the reliability of the accuracy outcomes of these six classifiers.

Patient and public involvement
Patients were not involved in the development of the research question, study design, or conduct of this study.

Results
The output data of deep learning in classifying the keratoconus grade of the disease are listed in table 1. Deep learning using the arithmetical mean data of these six colour-coded maps showed an accuracy of 0.991 (sensitivity 1.000, specificity 0.984) in discriminating between normal and keratoconic eyes (table 2). For a single map analysis, posterior elevation map (0.993) showed the highest accuracy, followed by posterior curvature map (0.991), anterior elevation map (0.983), corneal pachymetry map (0.982), total refractive power map (0.978) and anterior curvature map (0.976), in discriminating between normal and keratoconic eyes.

Table 1 The output data of deep learning in classifying the grading of the disease according to the Amsler-Krumeich classification

Actual category	Output of convolutional neural network		
Normal	G1	G2	G3	G4	Total	
Normal	239	0	0	0	0	239	
G1	5	96	7	0	0	108	
G2	0	10	51	12	2	75	
G3	0	0	8	30	4	42	
G4	0	0	8	12	59	79	
Note: G denotes grade.

Table 2 The sensitivity, the specificity, and the accuracy outcomes in classifying the grading the disease according to the Amsler-Krumeich classification

Category	Positive	Negative	False-negative	False-positive	Sensitivity	Specificity	Accuracy	
Normal	239	299	0	5	1.000	0.984	0.991	
G1	96	425	12	10	0.889	0.977	0.959	
G2	51	445	24	23	0.680	0.951	0.913	
G3	30	477	12	24	0.714	0.952	0.934	
G4	59	458	20	6	0.747	0.987	0.952	
Total							0.874	
Note: G denotes grade.

Deep learning using the arithmetical mean data of these six colour-coded maps showed an accuracy of 0.874 (sensitivity 0.889, specificity 0.977 for grade 1, sensitivity 0.680, specificity 0.951 for grade 2, sensitivity 0.714, specificity 0.952 for grade 3 and sensitivity 0.747, specificity 0.987 for grade 4) in classifying the stage of the disease, according to the Amsler-Krumeich classification (table 2). For a single map analysis, posterior curvature map (0.869) showed the highest accuracy, followed by corneal pachymetry map (0.845), anterior curvature map (0.836), total refractive power map (0.836), posterior elevation map (0.829) and anterior elevation map (0.820), in classifying the stage of the disease.

Discussion
In the present study, our results showed that deep learning using the colour-coded maps obtained by the AS-OCT provided an accuracy of 0.991 in discriminating between keratoconic and normal eyes, suggesting that it will be an aid to improve the diagnostic accuracy as a keratoconus screening test. Our results also showed that it provided an accuracy of 0.874 in determining the keratoconus stage, indicating that it will also be helpful to classify the grade of the disease. We applied the Amsler-Krumeich classification, since there is no other standardised classification of the disease, and thus it is still often used in daily practice. As far as we can ascertain, this is the first study on deep learning using the whole image of each colour-coded map for keratoconus detection and grade classification based on clinical diagnosis. We believe that deep learning will be an aid for the screening and the staging of keratoconus in a clinical setting, because the precise preoperative screening of early keratoconus for refractive candidates is still challenging in daily practice.

To date, there have been several studies on machine learning for the screening of keratoconus, as listed in table 3. Using 8, 11 and 10 indices measured with a Placido disk-based corneal topography, Maeda et al
10 11 and Smolek and Klyce12 demonstrated that the accuracy of distinguishing keratoconus from other conditions was 96%, 80% and 100%, respectively. Using 9 indices measured with another corneal topography, Accardo and Pensiero13 showed that the sensitivity and the specificity was 94.1% and 97.6%, respectively. Using 11 indices measured with a scanning-slit corneal tomography, Souza et al
14 described that the sensitivity at 75% and 90% specificity was 43%–100% and 22%–100%, respectively, and that the area under the curve was 71%–99%. Arbelaez et al
15 reported that the support vector machine algorithm, using the data from anterior and posterior corneal surfaces and pachymetry measured with a Scheimpflug camera combined with Placido corneal topography, increased its sensitivity from 89.3% to 96.0% in abnormal eyes, 92.8%–95.0% in eyes with keratoconus, 75.2%–92.0% in eyes with subclinical keratoconus, and 93.1%–97.2% in normal eyes. Using 55 indices measured with a dual Scheimpflug camera, Smadja et al
16 stated that the sensitivity and the specificity were 100% and 99.5%, respectively. Using 15 and 22 indices measured with a Scheimpflug camera, Kovács et al
17 and Ruiz Hidalgo et al
18 19 mentioned that the sensitivity and the specificity were 100% and 95%, and 99.1% and 98.4%, respectively. Yousefi et al
20 recently demonstrated that the specificity in identifying normal from keratoconus eyes was 94.1% and the sensitivity of identifying keratoconus from normal eyes was 97.7%, based on Ectasia Status Index diagnosis labels. Dos Santos et al
21 reported that the custom neural network architecture could segment both healthy and keratoconus images with high accuracy, and that deep learning algorithms could be applied for OCT image segmentation in various clinical settings. Issarti et al
22 stated that computer aided diagnosis detected suspect keratoconus with an accuracy of 96.56% (sensitivity 97.78%, specificity 95.56%), suggesting that the algorithm is highly accurate and provides a stable screening platform to assist ophthalmologists with the early detection of keratoconus. Since the inclusion criteria, the category of the disease, and the sample size, were different among these studies, we cannot directly compare the sensitivity and the specificity outcomes between these previous and current studies. Especially the category of the disease might affect the outcomes in this kind of the diagnostic accuracy test in a clinical setting. However, most previous studies have merely used topographic and tomographic numeric values for machine learning, except for one study.21 These numeric values are simple and easy to grasp the overall corneal shape, but hide the spatial gradients and distributions of the corneal curvature, elevation, refractive power and thickness. In the current study, we used the whole images of six colour-coded maps for deep learning, instead of topographic and tomographic numeric indices. We assume that the use of colour-coded maps has advantages over that of numeric values for machine learning, since these colour-coded maps can bring a larger amount of corneal information than these numeric values for this learning. Contrary to our expectations, the sensitivity to detect more advanced keratoconus (grade 2, 3, or 4) was lower than that to detect mild keratoconus (grade 1). We speculate that the colour-coded maps might not be typical for grade 2, 3 and 4, and thus the discrimination between grade 2 and grade 3, or that between grade 3 and grade 4, was still difficult even using this deep learning of these colour-coded maps. A further validation using another study population is still necessary to clarify this point.

Table 3 Previous studies on the diagnostic accuracy of keratoconus using machine learning

Author	Year	Sample size	Device	Machine learning	Input	Sensitivity	Specificity	Accuracy	
Maeda et al
10
	1994	200	TMS-1	Expert system	Eight parameters	89%	99%	96%	
Maeda et al
11
	1995	183	TMS-1	Neural network	11 parameters	44–100%	>90%	80%	
Smolek and Klyce12
	1997	300	TMS-1	Neural network	10 parameters	100%	100%	100%	
Accardo and Pensiero13
	2002	396	EyeSys	Neural network	Nine parameters	94.1%	97.6%	N.A.	
Souza et al
14
	2010	318	Orbscan II	Neural network, support vector machine and radial basis function neural network	11 parameters	N.A.	N.A.	71–99% (AUROC)	
Arbelaez et al
15
	2012	3502	Sirius	Support vector machine	Seven parameters	95.0%	99.3%	98.2%	
Smadja et al
16
	2013	372	GALILEI	Decision tree	55 parameters	100%	99.5%	N.A.	
Kovács et al
17
	2016	135	Pentacam	Neural network	15 parameters	100%	95%	99% (AUROC)	
Ruiz Hidalgo et al
18
	2016	860	Pentacam	Support vector machine	22 parameters	99.1%	98.4%	98.9%	
Ruiz Hidalgo et al
19
	2017	131	Pentacam	Support vector machine	25 parameters	N.A.	N.A.	92.6%, 98.0%	
Yousefi et al
20
	2018	3156	CASIA	Unsupervised machine learning	420 parameters	94.1%	97.7%	N.A.	
Dos Santos et al
21
	2019	142	UHR-OCT	Custom neural network	72 images	N.A.	N.A.	99.56%	
Issarti et al
22
	2019	851	Pentacam	Feedforward neural network	19 881 matrices	97.78%	95.56%	96.56%	
Current		543	CASIA	Convolutional neural network	Six colour-coded maps	100%	98.4%	99.1%	
AUROC, area under receiver operating characteristic; UHR-OCT, ultra-high-resolution optical coherence tomography.

In previous studies, simple multilayer neural networks, support vector machines, or decision trees were used for machine learning, whereas convolutional neural network was applied in our study. We also assume that convolutional neural network has advantages over other machine learning methods, since convolutional neural network can directly extract the morphological characteristics from the obtained images without preliminary learning, and subsequently provide a higher classification precision, especially in the field of image recognition.

Placido disk-based corneal topography is a highly sensitive and specific diagnostic tool, but it only examines the anterior corneal surface. It has been reported that both the curvature and the elevation of the posterior corneal surface play a vital role in early-stage keratoconus detection.25–29 Ishii et al
28 showed that the cases of lower staging had a larger area under the receiver operating characteristic curve in the posterior elevation differences than in the anterior elevation differences, suggesting a greater diagnostic value of the posterior elevation measurement. We29 previously demonstrated that anterior and posterior corneal surface height data effectively discriminate keratoconus from normal corneas, and may provide useful information for improving the diagnostic accuracy of keratoconus, especially in the early stage of the disease. Interestingly, for a single map analysis, the posterior elevation map (0.993) and the posterior curvature map (0.869) showed the highest accuracy in discriminating between normal and keratoconic eyes and in classifying the stage of the disease, respectively, supporting the significance of posterior corneal information for keratoconus detection. Moreover, the AS-OCT may have advantages over the Scheimpflug imaging system, in the grading of the disease, especially for grade 4 keratoconic eyes.30


There are at least two limitations to this study. One limitation is that we used the arithmetic mean outputs from these six classifiers, without any weighting. We investigated some variations to integrate outputs, including weighted averaging and machine learning with neural network, but the arithmetic mean data without weighting resulted in the best accuracy in this study population. Another limitation is that we did not include other corneal disorders such as forme fruste keratoconus or subclinical keratoconus, and did not apply this deep learning to other populations. We are currently conducting a new study to apply this deep learning to other corneal disorders as well as other populations to confirm the authenticity of our results.

In summary, our results may support the view that deep learning using six colour-coded maps obtained from the swept-source AS-OCT was effective not only for the screening of keratoconus, but also for the grade of the disease. It may be an aid for improving the accuracy of keratoconus detection in a clinical setting. A further study with a large sample size will be helpful to confirm our findings.

Supplementary Material
Reviewer comments
 Author's manuscript
 Contributors: KK and KM were involved in the design and conduct of the study. KK, YA, YK and YM were involved in collection, management, analysis and interpretation of data. KK, YA, YK, FF, MT, NS, YM and KM were involved in preparation, review and final approval of the manuscript.

Funding: The authors have not declared a specific grant for this research from any funding agency in the public, commercial or not-for-profit sectors.

Competing interests: None declared.

Patient consent for publication: Obtained.

Ethics approval: The study was approved by the Institutional Review Board of Miyata Eye Hospital

(18-023), and followed the tenets of the Declaration of Helsinki.

Provenance and peer review: Not commissioned; externally peer reviewed.

Data availability statement: Data are available upon reasonable request.
==== Refs
References
1. 
Matsugu M , Mori K , Mitari Y , et al 
Subject independent facial expression recognition with robust face detection using a convolutional neural network . Neural Netw 
2003 ;16 :555 –9 . 10.1016/S0893-6080(03)00115-1 
12850007 
2. 
Tivive FHC , Bouzerdoum A  
Efficient training algorithms for a class of shunting inhibitory convolutional neural networks . IEEE Trans Neural Netw 
2005 ;16 :541 –56 . 10.1109/TNN.2005.845144 
15940985 
3. 
Le Callet P , Viard-Gaudin C , Barba D  
A convolutional neural network approach for objective video quality assessment . IEEE Trans Neural Netw 
2006 ;17 :1316 –27 . 10.1109/TNN.2006.879766 
17001990 
4. 
Gulshan V , Peng L , Coram M , et al 
Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus Photographs . JAMA 
2016 ;316 :2402 –10 . 10.1001/jama.2016.17216 
27898976 
5. 
Wong TY , Bressler NM  
Artificial intelligence with deep learning technology looks into diabetic retinopathy screening . JAMA 
2016 ;316 :2366 –7 . 10.1001/jama.2016.17563 
27898977 
6. 
Gargeya R , Leng T  
Automated identification of diabetic retinopathy using deep learning . Ophthalmology 
2017 ;124 :962 –9 . 10.1016/j.ophtha.2017.02.008 
28359545 
7. 
Sample PA , Chan K , Boden C , et al 
Using unsupervised learning with variational Bayesian mixture of factor analysis to identify patterns of glaucomatous visual field defects . Invest Ophthalmol Vis Sci 
2004 ;45 :2596 –605 . 10.1167/iovs.03-0343 
15277482 
8. 
Xiangyu Chen , Yanwu Xu , Damon Wing Kee Wong , et al 
Glaucoma detection based on deep convolutional neural network . Conf Proc IEEE Eng Med Biol Soc 
2015 ;2015 :715 –8 . 10.1109/EMBC.2015.7318462 
26736362 
9. 
Asaoka R , Murata H , Iwase A , et al 
Detecting preperimetric glaucoma with standard automated perimetry using a deep learning classifier . Ophthalmology 
2016 ;123 :1974 –80 . 10.1016/j.ophtha.2016.05.029 
27395766 
10. 
Maeda N , Klyce SD , Smolek MK , et al 
Automated keratoconus screening with corneal topography analysis . Invest Ophthalmol Vis Sci 
1994 ;35 :2749 –57 .8188468 
11. 
Maeda N , Klyce SD , Smolek MK  
Neural network classification of corneal topography. Preliminary demonstration . Invest Ophthalmol Vis Sci 
1995 ;36 :1327 –35 .7775110 
12. 
Smolek MK , Klyce SD  
Current keratoconus detection methods compared with a neural network approach . Invest Ophthalmol Vis Sci 
1997 ;38 :2290 –9 .9344352 
13. 
Accardo PA , Pensiero S  
Neural network-based system for early keratoconus detection from corneal topography . J Biomed Inform 
2002 ;35 :151 –9 . 10.1016/S1532-0464(02)00513-0 
12669978 
14. 
Souza MB , Medeiros FW , Souza DB , et al 
Evaluation of machine learning classifiers in keratoconus detection from Orbscan II examinations . Clinics 
2010 ;65 :1223 –8 . 10.1590/S1807-59322010001200002 
21340208 
15. 
Arbelaez MC , Versaci F , Vestri G , et al 
Use of a support vector machine for keratoconus and subclinical keratoconus detection by topographic and tomographic data . Ophthalmology 
2012 ;119 :2231 –8 . 10.1016/j.ophtha.2012.06.005 
22892148 
16. 
Smadja D , Touboul D , Cohen A , et al 
Detection of subclinical keratoconus using an automated decision tree classification . Am J Ophthalmol 
2013 ;156 :237 –46 . 10.1016/j.ajo.2013.03.034 
23746611 
17. 
Kovács I , Miháltz K , Kránitz K , et al 
Accuracy of machine learning classifiers using bilateral data from a scheimpflug camera for identifying eyes with preclinical signs of keratoconus . J Cataract Refract Surg 
2016 ;42 :275 –83 . 10.1016/j.jcrs.2015.09.020 
27026453 
18. 
Ruiz Hidalgo I , Rodriguez P , Rozema JJ , et al 
Evaluation of a Machine-Learning classifier for keratoconus detection based on scheimpflug tomography . Cornea 
2016 ;35 :827 –32 . 10.1097/ICO.0000000000000834 
27055215 
19. 
Ruiz Hidalgo I , Rozema JJ , Saad A , et al 
Validation of an objective keratoconus detection system implemented in a scheimpflug Tomographer and comparison with other methods . Cornea 
2017 ;36 :689 –95 . 10.1097/ICO.0000000000001194 
28368992 
20. 
Yousefi S , Yousefi E , Takahashi H , et al 
Keratoconus severity identification using unsupervised machine learning . PLoS One 
2018 ;13 :e0205998
10.1371/journal.pone.0205998 
30399144 
21. 
Dos Santos VA , Schmetterer L , Stegmann H , et al 
CorneaNet: fast segmentation of cornea OCT scans of healthy and keratoconic eyes using deep learning . Biomed Opt Express 
2019 ;10 :622 –41 . 10.1364/BOE.10.000622 
30800504 
22. 
Issarti I , Consejo A , Jiménez-García M , et al 
Computer aided diagnosis for suspect keratoconus detection . Comput Biol Med 
2019 ;109 :33 –42 . 10.1016/j.compbiomed.2019.04.024 
31035069 
23. 
Rabinowitz YS , Keratoconus RYS  
Keratoconus . Surv Ophthalmol 
1998 ;42 :297 –319 . 10.1016/S0039-6257(97)00119-7 
9493273 
24. 
Krumeich JH , Kezirian GM  
Circular keratotomy to reduce astigmatism and improve vision in stage I and II keratoconus . J Refract Surg 
2009 ;25 :357 –65 . 10.3928/1081597X-20090401-07 
19431926 
25. 
Fam H-B , Lim K-L  
Corneal elevation indices in normal and keratoconic eyes . J Cataract Refract Surg 
2006 ;32 :1281 –7 . 10.1016/j.jcrs.2006.02.060 
16863962 
26. 
Quisling S , Sjoberg S , Zimmerman B , et al 
Comparison of Pentacam and Orbscan IIz on posterior curvature topography measurements in keratoconus eyes . Ophthalmology 
2006 ;113 :1629 –32 . 10.1016/j.ophtha.2006.03.046 
16949447 
27. 
de Sanctis U , Loiacono C , Richiardi L , et al 
Sensitivity and specificity of posterior corneal elevation measured by Pentacam in discriminating keratoconus/subclinical keratoconus . Ophthalmology 
2008 ;115 :1534 –9 . 10.1016/j.ophtha.2008.02.020 
18405974 
28. 
Ishii R , Kamiya K , Igarashi A , et al 
Correlation of corneal elevation with severity of keratoconus by means of anterior and posterior topographic analysis . Cornea 
2012 ;31 :253 –8 . 10.1097/ICO.0B013E31823D1EE0 
22316650 
29. 
Kamiya K , Ishii R , Shimizu K , et al 
Evaluation of corneal elevation, pachymetry and keratometry in keratoconic eyes with respect to the stage of Amsler-Krumeich classification . Br J Ophthalmol 
2014 ;98 :459 –63 . 10.1136/bjophthalmol-2013-304132 
24457362 
30. 
Samy El Gendy NM , Li Y , Zhang X , et al 
Repeatability of pachymetric mapping using Fourier domain optical coherence tomography in corneas with opacities . Cornea 
2012 ;31 :418 –23 . 10.1097/ICO.0b013e31823f098c 
22236789


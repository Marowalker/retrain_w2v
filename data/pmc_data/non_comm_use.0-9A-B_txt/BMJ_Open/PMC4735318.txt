
==== Front
BMJ OpenBMJ OpenbmjopenbmjopenBMJ Open2044-6055BMJ Publishing Group BMA House, Tavistock Square, London, WC1H 9JR bmjopen-2015-00983710.1136/bmjopen-2015-009837Emergency MedicineResearch1506169116911704Improving the governance of patient safety in emergency care: a systematic review of interventions Hesselink Gijs 12Berben Sivera 13Beune Thimpe 1http://orcid.org/0000-0002-7129-3766Schoonhoven Lisette 1241 Regional Emergency Healthcare Network, Radboud University Medical Center, Nijmegen, The Netherlands2 Radboud University Medical Center, Scientific Institute for Quality of Healthcare (IQ healthcare), Nijmegen, The Netherlands3 Faculty of Health and Social Studies, Department of Emergency and Critical Care, HAN University of Applied Sciences, Nijmegen, The Netherlands4 Faculty of Health Science, NIHR CLAHRC Wessex, University of Southampton, Southampton, UKCorrespondence to  Dr Gijs Hesselink; gijs.hesselink@radboudumc.nl2016 29 1 2016 6 1 e00983726 8 2015 2 11 2015 30 11 2015 Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://www.bmj.com/company/products-services/rights-and-licensing/2016This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/Objectives
To systematically review interventions that aim to improve the governance of patient safety within emergency care on effectiveness, reliability, validity and feasibility.

Design
A systematic review of the literature.

Methods
PubMed, EMBASE, Cumulative Index to Nursing and Allied Health Literature, the Cochrane Database of Systematic Reviews and PsychInfo were searched for studies published between January 1990 and July 2014. We included studies evaluating interventions relevant for higher management to oversee and manage patient safety, in prehospital emergency medical service (EMS) organisations and hospital-based emergency departments (EDs). Two reviewers independently selected candidate studies, extracted data and assessed study quality. Studies were categorised according to study quality, setting, sample, intervention characteristics and findings.

Results
Of the 18 included studies, 13 (72%) were non-experimental. Nine studies (50%) reported data on the reliability and/or validity of the intervention. Eight studies (44%) reported on the feasibility of the intervention. Only 4 studies (22%) reported statistically significant effects. The use of a simulation-based training programme and well-designed incident reporting systems led to a statistically significant improvement of safety knowledge and attitudes by ED staff and an increase of incident reports within EDs, respectively.

Conclusions
Characteristics of the interventions included in this review (eg, anonymous incident reporting and validation of incident reports by an independent party) could provide useful input for the design of an effective tool to govern patient safety in EMS organisations and EDs. However, executives cannot rely on a robust set of evidence-based and feasible tools to govern patient safety within their emergency care organisation and in the chain of emergency care. Established strategies from other high-risk sectors need to be evaluated in emergency care settings, using an experimental design with valid outcome measures to strengthen the evidence base.

ACCIDENT & EMERGENCY MEDICINEHEALTH SERVICES ADMINISTRATION & MANAGEMENT
==== Body
Strengths and limitations of this study
This is the first systematic review of the literature that has evaluated the effects, reliability, validity and feasibility of interventions aimed to improve the governance of patient safety (ie, the ability for higher management to monitor and manage patient safety) in emergency care settings.

The review provides an overview of a variety of promising tools and their characteristics to monitor and manage patient safety in various types of emergency medical service organisations and in emergency departments. However, robust evidence to support these tools is absent.

The small number of included studies and the heterogeneity in the selected studies in terms of design, aims, intervention activities, population samples and presented outcomes make generalisations difficult.

To date, no studies have examined the effectiveness of interventions aimed to improve the governance of patient safety in the chain of emergency care, nor have they evaluated their psychometric properties and feasibility.

Introduction
Executives of healthcare services are increasingly held accountable for patient safety.1
2 Therefore, they have a fundamental governance role in overseeing and managing safety risks within their service.3 Governance of patient safety is especially important in the field of emergency care, because emergency care involves high patient safety risks. Care is often delivered to high-acuity patients with unstable vital signs in a fast-paced setting under unpredictable conditions.4 Also, emergency care often involves collaboration between different emergency medical service (EMS) organisations, including: general practitioner out-of-hours services (GP OHS), ambulance EMS, helicopter EMS (HEMS) and psychiatric EMS, and between EMS organisations and the emergency department (ED) in the hospital. Frequent patient handovers between the different services involve inherent opportunities for miscommunication and adverse events (AEs) to occur.5–7

Executives of emergency care organisations, however, seem to fall short in the governance of patient safety. Evidence shows that suboptimal emergency care is an important cause of patient harm and mortality. Between 6% and 8.5% of the patients who receive care in the ED experience an AE.8
9 Furthermore, 36–71% of the AEs in the ED are believed to be preventable.10 Preventable AEs also occur in ambulance EMS, HEMS and GP OHS.11–13 Causes of AEs relate to system failures, stressed and fatigued care providers, medication errors, communication problems, lack of professional skills and problems with medical equipment.14
15

Several studies investigated board engagement with quality and safety issues in their health service,16
17 and systematically reviewed the effectiveness and usefulness of governance systems and tools.18
19 However, evidence on effective safety governance activities in emergency care is unknown. More insight into available valid, reliable and feasible means to monitor and manage safety risks could provide boards better oversight of patient safety and accountability of their emergency care organisation, and the chain of emergency care. We defined the chain of emergency care as: the interprofessional structure in which emergency care is delivered by multiple providers with the aim to provide seamless care to patients with acute care needs.6

The purpose of this study is to systematically review interventions aimed at improving the governance of patient safety in (the chain of) emergency care, and to evaluate their effects, reliability, validity and feasibility.

Methods
We planned and reported this systematic review in accordance with the guideline for performing and reporting systematic reviews and meta-analyses (PRISMA, Preferred Reporting Items for Systematic Reviews and Meta-Analyses).20

Data sources and searches
We searched for English and Dutch language studies published between January 1990 and July 2014 in the following databases: PubMed (including MEDLINE), Cumulative Index to Nursing and Allied Health Literature (CINAHL), Embase, PsychInfo and the Cochrane Library. Online supplementary appendix 1 provides a detailed listing of the search terms. We also searched for additional relevant studies (ie, ‘snowballing’): (1) via Google with the use of major key terms (ie, ‘governance’ AND ‘emergency care’ AND ‘patient safety’); (2) by reviewing references from the included studies and (3) by reviewing online archives/bibliographies of three high-impact journals in the field of emergency care (Annals of Emergency Medicine, Injury, Journal of Trauma and Acute Care Surgery).

Study selection
Two reviewers (GH and SB) independently screened the titles and abstracts of all studies identified by the search strategy for their eligibility. For inclusion, each study had to meet four criteria: (1) experimental or non-experimental study published as a full-text article or dissertation, (2) evaluating an intervention aimed at improving the governance of patient safety (ie, the ability for higher management to monitor and manage patient safety); (3) within the emergency care setting and (4) reporting data on the effect, validity, reliability or feasibility in terms of time and cost investment, and user friendliness of the intervention. Studies with a focus on acute dental care, intensive care (IC) and disaster medicine were excluded. When the title and abstract did not clearly indicate whether the inclusion criteria were met, a full-text copy was retained and reviewed.

Full-text copies of the potentially relevant studies were retrieved and evaluated for inclusion as described previously by two reviewers (GH and TB). A final set of studies was identified for data extraction. Inclusion discrepancies were reconciled by discussion.

Data extraction
GH and TB independently extracted data from each study meeting the inclusion criteria. A standardised form was used to ensure consistency of data extracted from each article. The extracted data described the study objectives, underlying theory-based concepts, setting, sample, intervention characteristics and findings. Disagreement between the reviewers was resolved by discussion. If no consensus was reached, a third reviewer (SB) was consulted.

Quality assessment
GH and TB independently assessed the study quality using a quality appraisal tool developed by Kmet et al.21 Studies were scored on up to 24 items: 14 items for studies with a quantitative research design and 10 items for studies with a qualitative research design. Items were scored depending on the degree to which the specific criteria were met (‘yes’=2, ‘partial’=1, ‘no’=0). Items not applicable to a particular study design were marked ‘NA’ and were excluded from the calculation of the summary score. Discrepancies were resolved through discussion. If no consensus was reached, a third reviewer (SB) was consulted. A study quality score (percentage) was calculated for each paper by summing the total score obtained across relevant items and dividing the obtained score by the total possible score.

Data synthesis
Study outcomes were organised in tabular form and a classification was made based on the study design, setting, sample size, intervention characteristics and outcomes, namely: effects and reported statistical significance, psychometric properties (ie, reliability and validity) and feasibility of the intervention.

Results
Search results
Our initial search identified 4287 records. After exclusion of duplicates, 3713 records were screened by title and abstract. Seventy full-text studies were retrieved and reviewed, of which 57 were excluded. Five articles were identified through snowballing. The final set consisted of 18 published studies that underwent full-text extraction (figure 1). Owing to the heterogeneity of the study designs, participants and outcome measures, a meta-analysis of the results was not possible.

Figure 1 Flow chart of the study selection and review process.

Study quality
Thirteen articles had a quantitative study design.22–34 Two articles had a qualitative study design.35
36 Three articles combined both quantitative and qualitative methods.37–39 The study quality scores ranged between 41% and 100% (tables 1 and 2). Two articles scored low (ie, <55%),32
34 10 articles scored high (ie, >75%),23–28
30
31
33
36 1 article scored high on the qualitative study and low on the quantitative study part,38 1 article scored high on the quantitative study and moderate on the qualitative study part,39 and 1 other article scored high on both (qualitative and quantitative) study parts.37 The three remaining studies scored a moderate in-between rating.22
29
35 Of the five articles with qualitative research, four had no or an unclear qualitative data analysis description (eg, omitting the types of analysis). Three qualitative studies failed to fully describe their qualitative data collection methods (eg, not mentioning an interview guide or the number of consensus rounds conducted in a Delphi study).35
38
39 Three qualitative studies showed no or poor use of verification procedures to establish credibility.35
36
39 Compared with the qualitative studies, the quantitative studies lacked in points related to sampling. Of the 16 articles with quantitative research, 8 had no or poor description of their sampling strategy (eg, inclusion and exclusion criteria),22–24
29
32–34
38 lacked an appropriate sample size23–26
32
34
37
38 and described sample characteristics insufficiently.25
28–30
33
35–37 Only two articles with quantitative research reported to appropriately control for confounding variables.28
31

Table 1 Quality assessment of studies with quantitative design

	Wolff and Bourke22	Hendrie et al23	Patterson et al37*	Clunas et al24	van Noord et al25	Patterson et al26	Patterson et al27	Flowerdew et al38*	Jaynes et al39*	Evans et al28	Zwart et al29	Reznek and Barton30	Pham et al31	Jones et al32	Patterson et al33	Shaw et al34	
Question/objective sufficiently described?	2	2	2	1	2	2	1	1	2	2	2	2	2	2	2	2	
Study design evident and appropriate?	2	1	2	2	2	2	2	1	2	2	2	2	2	2	2	1	
Method of subject/comparison group selection or source of information/input variables described and appropriate?	1	1	2	0	2	2	2	1	2	2	1	2	2	1	1	1	
Subject characteristics sufficiently described?	2	2	2	1	2	2	1	1	1	2	2	1	2	1	1	1	
If interventional and random allocation was possible, was it described?	NA	NA	NA	NA	NA	NA	NA	NA	NA	2	0	NA	NA	1	NA	NA	
If interventional and blinding of investigators was possible, was it reported?	0	NA	NA	NA	NA	NA	NA	NA	NA	2	NA	NA	NA	NA	2	NA	
If interventional and blinding of subjects was possible, was it reported?	0	NA	NA	NA	NA	NA	NA	NA	NA	2	NA	NA	NA	NA	NA	NA	
Outcome and exposure measure(s) well defined and robust to measurement/misclassification bias? Means of assessment reported?	2	2	1	2	1	2	2	1	1	2	2	2	2	1	1	1	
Sample size appropriate?	2	1	1	1	1	1	2	1	2	2	2	2	2	0	2	1	
Analytic methods described/justified and appropriate?	1	2	2	2	2	2	1	1	1	2	2	2	2	2	2	0	
Is some estimate of variance reported for the main results?	2	2	0	2	1	2	2	0	0	2	0	2	2	0	2	0	
Controlled for confounding?	0	1	NA	NA	NA	1	1	0	NA	2	1	NA	2	0	NA	0	
Results reported in sufficient detail?	2	2	2	2	2	2	2	1	2	2	1	2	2	2	2	1	
Conclusions supported by the results?	2	2	2	2	2	2	1	1	2	2	2	2	2	1	2	2	
Total points	18	18	16	15	17	20	17	9	15	28	17	19	22	13	19	10	
Max points possible	26	22	20	20	20	22	22	22	20	28	24	20	22	24	22	22	
Summary score, in percentage (%)	69	82	80	75	85	91	77	41	75	100	71	95	100	54	86	46	
NA, not available.

*Study using quantitative and qualitative research methods.

Table 2 Quality assessment of studies with qualitative design

	Patterson et al35	Patterson et al37*	Flowerdew et al38*	Jaynes et al39*	Schull et al36	
Question/objective sufficiently described?	2	2	1	2	2	
Study design evident and appropriate?	2	2	2	2	2	
Context for the study clear?	2	2	2	2	2	
Connection to a theoretical framework/wider body of knowledge?	2	2	2	1	1	
Sampling strategy described, relevant and justified?	2	2	2	1	2	
Data collection methods clearly described and systematic?	1	2	1	1	2	
Data analysis clearly described and systematic?	1	1	1	0	2	
Use of verification procedure(s) to establish credibility?	0	2	2	1	1	
Conclusions supported by the results?	2	2	1	2	2	
Reflexivity of the account?	0	1	1	1	1	
Total points	14	18	15	13	17	
Maximum points possible	20	20	20	20	20	
Summary score, in percentage	70	90	75	65	85	
*Study using quantitative and qualitative research methods.

Study characteristics
Table 3 shows a summary of the study characteristics. A more detailed overview of the study characteristics is provided in online supplementary appendix 2. Of the 18 included studies, 10 (56%) were performed in the USA,26
27
30–35
37
39 4 (22%) in Australia,22–24
28 2 (11%) in the Netherlands,25
29 1 (6%) in the UK38 and 1 (6%) in Canada.36 Thirteen studies (72%) were non-experimental. Five studies (28%) were quasi-experimental using an interrupted time series design,30
33 a non-equivalent group design28
29 and a before–after design.22

Table 3 Study characteristics

First author (year) (country)	Design	Setting	Sample	Intervention	Findings	
					Effects	Psychometrics	Feasibility	
Wolff (2002) (Australia)22	Quasi-experimental (BA)	ED (n=1)	Reviewed patient medical records (n=20 050)	Incident reporting in addition to standardised screening of medical records on AEs	Reduced AEs*	NR	NR	
Hendrie (2007) (Australia)23	Non-experimental	ED (n=1)	Patient case histories (n=3332)	AE screening	NR	Inter-rater reliability	Time†	
Patterson (2012) (USA)35	Non-experimental	EMS (n=NR)	Patient case reports (n=250)	AE identification and severity rating method	NR	Internal reliability; construct validity	NR	
Patterson (2014) (USA)37	Non-experimental	HEMS (n=NR)	Expert clinicians in emergency medicine and HEMS (n=10)	AE identification and severity rating method	NR	Content and face validity	NR	
Clunas (2009) (Australia)24	Non-experimental	ED (n=1)	Reviewed patient deaths (n=303)	Audit of all deaths that occurred within 48 h of ED presentation in addition to auditing all deaths that occurred in the ED itself	NR	NR	Usability‡	
van Noord (2010) (The Netherlands)25	Non-experimental	ED (n=31)	Closed and settled claim files (n=47)	Root Cause Analysis using PRISMA method	NR	Inter-rater reliability; face validity	Time†	
Patterson (2010) (USA)26	Non-experimental	EMS agencies (n=3)	EMTs and paramedics (n=71)	EMS-SAQ	NR	Internal reliability; construct validity	Response rate‡; user friendliness‡	
Patterson (2010) (USA)27	Non-experimental	EMS agencies (n=61)	Care providers (n=1595)	EMS-SAQ	NR	Inter-rater reliability; face validity	NR	
Flowerdew (2012) (UK)38	Non-experimental	ED (n=2)	NR	Observational physician (non-technical) skills assessment	NR	Face and content validity	NR	
Jaynes (2013) (USA)39	Non-experimental	EMS (n=NR)	EMS care providers (n=380)	EMS and HEMS working relationship satisfaction questionnaire	NR	Internal reliability; face, content and construct validity	NR	
Evans (2007) (Australia)28	Quasi experimental (NEG)	ED (n=4)	ED (n=2) attendances (n=66 669) with intervention vs ED (n=2) attendances (n=78 264) with usual procedure	Incident reporting programme comprising intense staff education, 24/7 reporting options, changes in report management and enhanced feedback	Increased IRs*	NR	NR	
Zwart (2011) (The Netherlands)29	Quasi experimental (NEG)	GP OHS (n=3)	GP OHS with intervention (n=1); GP OHS with usual procedure (n=2)	Local incident-reporting vs centralised incident reporting (usual procedure)	Increased IRs; increased IR types	NR	Time‡; costs†	
Reznek (2014) (USA)30	Quasi experimental (ITS)	ED (n=1)	IRs (n=314)	Standardised non-punitive peer review of IRs	Increased monthly frequencies of IRs*	NR	NR	
Schull (2011) (Canada)36	Non-experimental	ED (n=NR)	Candidate indicators (n=170)	Patient safety indicators	NR	Face validity	Usability‡	
Pham (2011) (USA)31	Non-experimental	ED (n=1)	Patients seen in the ED within 72 h of prior visit (n=6858) and patients not seen in the ED within 72 h (n=211 321)	Patient safety indicator	NR	NR	Usability†	
Jones (2013) (USA)32	Non-experimental	ED (n=2)	Care providers (n=60)	Teamwork training on patient safety (TeamSTEPPS)	Positive change in safety culture perception	NR	NR	
Patterson (2013) (USA)33	Quasi experimental (ITS)	Paediatric ED (n=1)	Care providers (n=151)	Multidisciplinary simulation-based training	Increased staff safety knowledge*; increased staff safety attitude*	NR	Time‡	
Shaw (2006) (USA)34	Non-experimental	Paediatric ED (n=1)	Staff (n=99)	Unit-based Patient Safety Walk-rounds	Increased IRs; increased hand hygiene compliance	NR	NR	
*Statistical significant effect (p<0.05).

†Negative finding with regard to the feasibility of the intervention.

‡Positive finding with regard to the feasibility of the intervention.

AE, adverse event; BA, before–after; ED, emergency department; EMS, emergency medical services; EMS-SQA, EMS-Safety Attitudes Questionnaire; EMT, emergency medical technician; GP OHS, general practitioner out-of-hours services; HEMS, helicopter EMS; IR, incident report; ITS, interrupted time series; NEG, non-equivalent group; NR, not reported; PRISMA, Prevention and Recovery Information System for Monitoring and Analysis.

Of the 18 included studies, 12 (67%) evaluated a safety governance intervention within EDs,22–25
28
30–34
36
38 4 (22%) within EMS organisations,26
27
35
39 1 within an HEMS37 and 1 (6%) within GP OHS.29 One study focused on monitoring the quality and safety of ambulance and HEMS collaboration.39 The sample size ranged from 60 to 1595 studied care providers, 6858–211 321 studied patients and 47–20 050 studied files (eg, incident reports, medical records, claim files). One study (6%) described a study panel of 10 expert clinicians as the study sample.33

Four studies (22%) reported statistically significant effects.22
28
30
33 Nine studies (50%) reported data on the reliability and/or validity of the intervention.23
25–27
35–39 Eight studies (44%) reported on the feasibility of the intervention.23–26
29
31
33
36

Intervention characteristics and findings
Six studies (33%) examined methods for screening and assessing AEs, incidents and patient deaths.22–25
35
37 Four studies (22%) evaluated safety culture and care provider behaviour measures.26
27
38
39 Three studies (17%) evaluated incident reporting systems.28–30 Two studies (11%) evaluated patient safety indicators.31
36 Two studies (11%) evaluated training methods for improving care provider safety skills and attitudes.32
33 One study (6%) evaluated the effectiveness of Patient Safety Walk-rounds (PSWs).34

Screening and assessment methods
Four studies described methods to screen and assess AEs. Wolff and Bourke22 described retrospective screening of medical records in the ED with the use of an AE severity scale to assess AEs. A clinical risk manager performed the screening and assessment of AEs, and created weekly reports for the ED management, describing the type and severity of identified AEs and improvement actions. Aggregated quarterly reports detailing actions taken and AE rates were presented to the hospital's main quality improvement committee. In addition, uniform reporting of incidents by ED staff was stimulated with the use of one definition of a clinical incident and a standardised incident report form. Over 2 years, the number of AEs reduced—a relative risk reduction of 85.3% (95% CI 62.7% to 100%). Hendrie et al23 evaluated an AE screening and assessment method of case records. AEs were identified using a validated data collection instrument and classified on management causation, outcome and preventability. Inter-rater agreement on the classification of AEs (ƙ=0.15), on judgements about management causation (ƙ=0.50) and on preventability (ƙ=0.58) was poor. Furthermore, the researchers considered the time to detect an AE to be substantial. The study did not report any measure of effect (eg, regarding the number of detected AEs). Patterson et al35 evaluated a method for AE identification and severity rating in medical charts in ambulance EMS. A definition of an AE in EMS and an AE severity-rating index were developed in a consensus study for uniform identification of AEs in medical charts. Multirater agreement on classification of AEs was poor (ƙ=0.24). Patterson et al37 used a modified Delphi study to develop a consensus-based AE definition and a framework for AE detection in HEMS. Subsequently, the framework evaluated on content validity, using the item and scale content validity index. The framework was composed of three main components: (1) a trigger tool to operationalise AE detection, using key words or phrases contained within patient care reports that have a high probability of being linked to patient harm, (2) a method for rating AE severity, (3) a method for rating proximal cause of AEs. All three components of the framework showed content validity. The study did not report any measure of effect.

Clunas et al24 evaluated an audit of patient deaths that occurred within 48 h of ED presentation in addition to auditing all deaths that occurred in the ED itself. The authors tested the audit by reviewing 303 deaths, including 75 deaths in the ED and 228 deaths within 48 h of ED presentation. Results showed that 36% of the death cases within 48 h of ED presentation that required a major external hospital review were not identified by the standard hospital incident monitoring system.

The psychometric properties and the feasibility of the Prevention and Recovery Information System for Monitoring and Analysis (PRISMA) was evaluated by van Noord et al,25 to retrospectively analyse root causes of incidents that have led to malpractice claim files in the ED. The authors found a high inter-rater agreement on classification of root causes (ƙ=0.78). Validity of the root cause profile of claims was considered moderate. The delay between incident occurrences and their detection and reporting made it difficult to draw firm conclusions from the analyses. Finally, the PRISMA analyses were time consuming. The study did not report any measure of effect.

Safety culture and care provider behaviour measures
Patterson et al26
27 evaluated the Safety Attitudes Questionnaire (SQA). The EMS-SQA is a modified version of the validated Intensive Care Unit SAQ (ICU-SAQ). The anonymised questionnaire is administered in paper form and/or via the internet. Respondents are asked to rate 60 items on a five-point Likert scale (strongly agree to strongly disagree). The responses are used to characterise six safety domains (eg, safety climate and teamwork climate). Evaluation of the six safety domains, using Confirmatory Factor Analysis (CFA), revealed acceptable internal consistency and model fit validity of the EMS-SQA. Patterson et al26 confirmed feasibility of the EMS-SQA based on the high response rate and positive feedback on instrument utility from EMS chief administrators. In contrast, the authors stated that some chief administrators raised concerns about the respondent burden and the face validity of several questionnaire items. The study did not report any measure of effect.

Flowerdew et al38 evaluated a method to assess care provider non-technical skills in the ED. A behavioural marker system was developed for the observational assessment of 12 specific non-technical skills required by physicians, for example, maintaining standards, managing workload and resolving conflict. Skills were assessed on a nine-point rating scale and divided into ‘unacceptable’, ‘acceptable’ and ‘exemplary’. The tool was considered to be valid based on the input of evidence-based literature, and the input of interviews with staff and observations, to determine whether, in practice, the skill list contained any significant omissions and whether skills were observable. A survey among experts proved content validity of the developed list of skills and behavioural markers. The study did not report any measure of effect.

Jaynes et al39 evaluated an instrument to assess the working relationship between ambulance and HEMS care providers. The questionnaire consisted of 22 items that were rated on a five-point Likert scale (never/very poor to always/very good). The questionnaire was developed based on the input of providers, medical directors and administrators (n=12), who defined the activities involved in the EMS–HEMS working relationship and generated items (eg, We have the information we need for making transport decisions). HEMS and EMS personnel reviewed the questionnaire and determined content validity based on consensus. The measure had good internal reliability, with a Cronbach's α for each domain varying between 0.85 and 0.88. Explanatory factor analysis showed that a single underlying factor could best account for all questionnaire items. The study did not report any measure of effect.

Incident reporting systems
Evans et al28 evaluated an incident reporting programme in the ED. The programme included the display of posters and manuals for staff describing the importance of reporting, the possibility of anonymous reporting, the use of a one-page report form, a 24 h/7 days open telephone reporting service, and feedback on statistics and root-cause analysis findings to all ED staff. A patient safety manager initially assessed incident reports. Also, anonymous reports were validated and managed without the involvement of unit heads. The intervention resulted in a statistically significant improvement in reporting by the ED staff; an overall increase of 39.5 incident reports per 10 000 ED attendances (95% CI 17.0 to 62.0; p<0.001). Zwart et al29 compared a local incident reporting procedure (LIRP) with a centralised incident reporting procedure (CIRP) in Dutch GP OHS. In the LIRP, a local multidisciplinary committee is trained to screen and analyse incident reports, whereas in the CIRP, incident analysis is performed by an advisory committee of the board of directors of the GP OHS collaboration. The local committee was responsible for feedback to reporters and for follow-up measures when appropriate. Furthermore, reported incidents were analysed within 2 weeks instead of the usual every 2 months. The number of incidents in the GP OHS, using the LIRP, increased 16-fold compared with the GP OHSs using the CIRP. The implementation of a LIRP was associated with extra costs for administration and analysis. Reznek and Barton30 evaluated the effectiveness of a standardised, non-punitive peer review process of incident reports in one ED compared to analysis of incident reports by a single reviewer. Relevant reports were peer reviewed each month by a committee of board certified physicians, and involved structured analysis and discussion of incidents with staff that participated in open peer review proceedings. The authors stated that the monthly frequency of reporting increased over time compared with that of a control group of practitioners from outside the hospital (p=0.0019; p<0.0001).

Patient safety indicators
Pham et al31 evaluated the usability of one indicator: patient ED returns within 72 h of prior visit. Findings did not support the use of 72 h returns as a safety indicator: patients who return to the ED within 72 h do not use more resources, are not more severely ill and do not have a higher hospital admission rate than those who had not been previously seen. Schull et al36 sought to develop a set of evidence-based quality of care indicators for EDs. An expert panel reached consensus on a set of 48 indicators of which six focused on the measurement of patient safety. Of these six patient safety indicators, four were classified as feasible based on the use of current national administrative databases (eg, Percentage of patients with headache discharged home from the ED who were admitted to hospital with subarachnoid haemorrhage in the subsequent 14 days). The two other indicators (ie, ‘Percentage of central lines inserted in the ED that developed catheter-related bloodstream infections’ and ‘Percentage of intubated patients for whom end-tidal carbon dioxide was monitored’), could be feasibly measured with enhanced quality and completeness of data (eg, coding of injuries, medical interventions and time registrations) in existing database fields.

Training of safety attitudes and skills
Jones et al32 evaluated the effect of a teamwork training method (TeamSTEPPS) on improved staff perception of safety culture within the ED. The training was given in a period of 4 weeks, educating staff on how to communicate safety concerns, and report errors and system failures. Video vignettes were used illustrating good communication—as well as barriers to communication—to facilitate group discussion. Participants used hand-outs with communication techniques for practice, both in class and after the training sessions. Findings showed no statistical difference of perceived safety culture before and after the training. Patterson et al33 evaluated the effectiveness of multidisciplinary simulation-based training. Care providers learned techniques to prevent medical errors, develop resilience, and to improve situation awareness and closed loop communication. Via debriefing of video-based simulations and a videotaped clinical scenario, ED personnel were trained to recognise high risk situations and to use the acquired skills to prevent or decrease the impact of unexpected events and errors. The training resulted in a statistically significant increase of patient safety knowledge and attitudes of personnel. The time required to conduct the training reduced over time from 12 to 4 h.

Safety walk-rounds
Shaw et al34 evaluated the effectiveness of PSWs in one ED. PSWs were performed by a physician and two staff nurses, and lasted approximately 30 min. Each PSW was conducted in the clinical area of the ED and included data collection on two of the following clinical quality improvement topics: (1) accuracy of weight and allergy documentation; (2) compliance with hand washing; (3) accuracy of medication orders, administration and documentation; (4) appropriateness of patient monitoring and alarm parameters/central monitoring; (5) reasons for prolonged length of stay (>3 h) and (6) patient/family communication. Rounds were followed by a general discussion with ED staff on, for example, staff near-miss experiences and suggestions for improvement. Subsequently, the ED Patient Safety Committee (ie, directors, managers) reviewed results and incident reports. An email was sent to all staff regularly, to inform on positive outcomes and needs for improvement. Study findings showed 44% increase of medication near-miss incident reports and 23% overall increase in hand hygiene compliance within the ED.

Discussion
To the best of our knowledge, this is the first systematic review of studies evaluating the effects, reliability, validity and feasibility of interventions to improve the governance of patient safety in emergency care. Our review highlights the lack of evidence on effective safety governance strategies in emergency care settings, particularly in the field of prehospital emergency care. Only four studies examining an intervention in EDs and GP OHS reported statistically significant effects on reduced AEs, an increase of reported incidents, and an increase of patient safety attitudes and knowledge among care providers. The validity, reliability and feasibility of interventions varied greatly. Moreover, the information provided in terms of time investment, costs and usability, was limited.

We identified two types of interventions that showed to be effective in improving the governance of patient safety within organisations. First of all, simulation-based patient safety training proved to be an effective intervention for improving the patient safety culture and safe medical practice in the ED. These findings correspond with the literature on medical education and training. Simulation-based training is increasingly valued as an effective method to enhance safety knowledge and behaviour of providers and healthcare teams, in addition to didactic education methods.40
41 In a controlled setting, care providers can experience infrequent and unexpected events, and learn to practice resilient behaviour.42 This is especially important in a high-risk sector such as emergency care. Second, the use of well-designed incident reporting systems leads to an increase of incidents reported by GP OHS and ED staff, which is an important source of data for executives to use for monitoring safety risks. Effective incident reporting systems shared the following components: (1) education of staff on the importance and the learning purpose of reporting; (2) multiple and constantly available reporting options for staff; (3) a short reporting form to minimise the burden of reporting and (4) structural feedback by presenting descriptive statistics, findings of incident root-cause analyses and improvement actions. These findings are supported by other publications on successful incident reporting systems.43–46 In a setting such as emergency care, where providers constantly have to deal with time pressure, it is important that sufficient resources for effective and efficient reporting are available. Additionally, a non-punitive reporting system is imperative for a culture of self-reporting to thrive.47 Interestingly, the effective incident reporting systems had different approaches towards anonymous reporting and the management of reports. One system had the ability for care providers to report anonymously, and anonymous reports were validated and followed-up only by the patient safety manager. This is consistent with previous studies suggesting that anonymous reporting and validation of reports by an independent party can increase the quality of reporting by care providers.48
49 In contrast, the other system invited care providers to participate in a non-anonymous peer review process that involved analysis and structured discussion of incident reports submitted to ED physician leadership. This suggests that anonymity of reporting and management of incident reports by an independent party may not be necessary if an incident reporting and review process is perceived to be safe.

No effective interventions were found that aim to monitor or improve patient safety in the chain of emergency care. This is a disturbing finding considering the high number of patient transitions and the unique challenges to safe handoffs between EMS organisations.5–7

Our hope is that this systematic review will act as a stimulus to gather more evidence on safety governance improvements in the field of emergency care. Characteristics of the interventions included in this review (eg, anonymous reporting and validation of reports by an independent party) could provide useful input for the design of an effective tool to govern patient safety in EMS organisations and hospital-based EDs. However, at the moment, executives cannot rely on several evidence-based strategies to govern patient safety within their organisation and in the chain of emergency care. A variety of established and effective tools are used in other healthcare domains and high-reliability sectors, such as the aviation and chemical industry. For example, safety indicators,50 patient safety dashboards and checklists,51
52 prospective risk analysis techniques (eg, Bow-tie, Failure Mode Effect Analysis)53 and safety audits.54
55 These strategies need to be evaluated on effectiveness and feasibility in studies with multiple (types of) EMS organisations as study sample, a control group, and uniform and valid outcome measures. Executives, quality officers and researchers should therefore keep in mind that these interventions need to correspond with the organisation's current patient safety stage.56 For example, the use of risk surveillance and educational interventions are doomed to fail without a culture of openness about errors among staff, and a proactive attitude towards safety improvement.

Review limitations
Our review has several limitations. First, the heterogeneity in the selected studies in terms of design, aims, intervention activities, sample, outcome measurements and presented outcomes prevented us from performing quantitative meta-analyses. Second, we experienced difficulties with including relevant studies, because most studies did not explicitly address if interventions were meant to improve safety governance at the executive level (ie, board of directors), or at the middle or lower management level (ie, heads of department, unit leaders) or both. Third, the outcome measures used by the studies may not reflect the impact of safety governance activities. For example, a reduced AE rate may be caused by factors other than an improved reporting system. Moreover, an increase of incident reports may also be an indicator of over-reporting by care providers. There are no uniform and clear criteria for measuring effective governance of patient safety in healthcare organisations. Therefore, the effects found need to be interpreted with caution. Fourth, evaluations with an observational design dominated the studies we identified. The design of these studies limits the ability to draw firm conclusions on the effectiveness of individual interventions. Fifth, the effectiveness and feasibility of reviewed interventions may relate to a specific medical or demographical setting. Two-thirds of the studies included in this review were performed in one or more EDs. More than a third of the included studies were conducted in a single organisation. Sixth, restricting the literature search to studies published in the English and Dutch languages may have introduced a study selection bias based on language. However, we did not find non-English publications that met our inclusion criteria.

Conclusion
Simulation-based training and incident reporting systems with a focus on reducing the fear of reporting, reporting burden, and structural and systematic feedback, are promising interventions to improve the governance of patient safety in emergency care. However, the weak study designs, the lack of valid outcome measures and information on feasibility hinder the demonstration of robust evidence to support these interventions. Promising interventions for the governance of patient safety in the chain of emergency care are absent. Further research evaluating established governance tools on effectiveness and feasibility from other sectors within emergency care organisations is warranted.

Contributors: GH, SB and LS were involved in conception and design of the study. GH and SB were responsible for data acquisition. GH, SB and TB analysed and interpreted the data. GH, SB and LS drafted the manuscript, which was critically revised for important intellectual content by all the authors.

Funding: This study was funded (grant number 80-83200-98-037) by the Netherlands Organisation for Health Research and Development (ZonMw).

Competing interests: None declared.

Provenance and peer review: Not commissioned; externally peer reviewed.

Data sharing statement: No additional data are available.
==== Refs
References
1 Callender AN , Hastings DA , Hemsley MC  
Corporate Responsibility and Health Care Quality: A Resource for Health Care Boards of Directors 
2007 
https://oig.hhs.gov/fraud/docs/complianceguidance/CorporateResponsibilityFinal%209-4-07.pdf (accessed 23 Feb 2015 ).
2 Goeschel C , Wachter R , Pronovost P  
Responsibility for quality improvement and patient safety: hospital boards and medical staff leadership challenges . Chest 
2010 ;138 :171 –8 . doi:10.1378/chest.09-205120605815 
3 Millar R , Mannion R , Freeman T  
Hospital board oversight of quality and patient safety: a narrative review and synthesis of recent empirical research . Milbank Q 
2013 ;91 :738 –70 . doi:10.1111/1468-0009.1203224320168 
4 Patterson PD , Arnold RM , Abebe K  
Variation in emergency medical technician partner familiarity . Health Serv Res 
2011 ;46 :1319 –31 . doi:10.1111/j.1475-6773.2011.01241.x21306367 
5 Owen C , Hemmings T , Brown T  
Lost in translation: maximizing handover effectiveness between paramedics and receiving staff in the emergency department . Emerg Med Australas 
2009 ;21 :102 –7 . doi:10.1111/j.1742-6723.2009.01168.x19422406 
6 van Leijen-Zeelenberg JE , van Raak AJ , Duimel-Peeters IG  
Interprofessional communication failures in acute care chains: how can we identify the causes? 
J Interprof Care 
2015 ;29 :320 –30 . doi:10.3109/13561820.2014.100380225614228 
7 Meisel ZF , Shea JA , Peacock NJ  
Optimizing the patient handoff between emergency medical services and the emergency department . Ann Emerg Med 
2015 ;65 :310 –17 . doi:10.1016/j.annemergmed.2014.07.00325109535 
8 Forster AJ , Rose NG , van Walraven C  
Adverse events following an emergency department visit . Qual Saf Health Care 
2007 ;16 :17 –22 . doi:10.1136/qshc.2005.01738417301197 
9 Calder LA , Forster A , Nelson M  
Adverse events among patients registered in high-acuity areas of the emergency department: a prospective cohort study . CJEM 
2010 ;12 :421 –30 .20880432 
10 Stang AS , Wingert AS , Hartling L  
Adverse events related to emergency department care: a systematic review . PLoS ONE 
2013 ;8 :e74214 
doi:10.1371/journal.pone.007421424069281 
11 Bigham BL , Buick JE , Brooks SC  
Patient safety in emergency medical services: a systematic review of the literature . Prehosp Emerg Care 
2012 ;16 :20 –35 . doi:10.3109/10903127.2011.62104522128905 
12 MacDonald RD , Banks BA , Morrison M  
Epidemiology of adverse events in air medical transport . Acad Emerg Med 
2008 ;15 :923 –31 . doi:10.1111/j.1553-2712.2008.00241.x18785942 
13 Huibers L , Smits M , Renaud V  
Safety of telephone triage in out-of-hours care: a systematic review . Scand J Prim Health Care 
2011 ;29 :198 –209 . doi:10.3109/02813432.2011.62915022126218 
14 Cushman JT , Fairbanks RJ , O'Gara KG  
Ambulance personnel perceptions of near misses and adverse events in pediatric patients . Prehosp Emerg Care 
2010 ;14 :477 –84 . doi:10.3109/10903127.2010.49790120662679 
15 Smits M , Groenewegen PP , Timmermans DR  
The nature and causes of unintended events reported at ten emergency departments . BMC Emerg Med 
2009 ;9 :16 
doi:10.1186/1471-227X-9-1619765275 
16 Bismark MM , Studdert DM  
Governance of quality of care: a qualitative study of health service boards in Victoria, Australia . BMJ Qual Saf 
2014 ;23 :474 –82 . doi:10.1136/bmjqs-2013-002193
17 Parand A , Dopson S , Renz A  
The role of hospital managers in quality and patient safety: a systematic review . BMJ Open 
2014 ;4 :e005055 
doi:10.1136/bmjopen-2014-005055
18 Hastings SE , Armitage GD , Mallinson S  
Exploring the relationship between governance mechanisms in healthcare and health workforce outcomes: a systematic review . BMC Health Serv Res 
2014 ;14 :479 
doi:10.1186/1472-6963-14-47925280467 
19 Phillips CB , Pearce CM , Hall S  
Can clinical governance deliver quality improvement in Australian general practice and primary care? A systematic review of the evidence . Med J Aust 
2010 ;193 :602 –7 .21077818 
20 Moher D , Liberati A , Tetzlaff J  
Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement . Ann Intern Med 
2009 ;151 :264 –9 . doi:10.7326/0003-4819-151-4-200908180-0013519622511 
21 Kmet LM , Lee RC , Cook LS  
Standard quality assessment criteria for evaluating primary research papers from a variety of fields . Edmonton : Alberta Heritage Foundation for Medical Research , 2004 .
22 Wolff A , Bourke J  
Detecting and reducing adverse events in an Australian rural base hospital emergency department using medical record screening and review . Emerg Med J 
2002 ;19 :35 –40 . doi:10.1136/emj.19.1.3511777869 
23 Hendrie J , Sammartino L , Silvapulle MJ  
Experience in adverse events detection in an emergency department: incidence and outcome of events . Emerg Med Australas 
2007 ;19 :16 –24 . doi:10.1111/j.1742-6723.2006.00896.x17305656 
24 Clunas S , Whitaker R , Ritchie N  
Reviewing deaths in the emergency department: deaths in the department or deaths within 48 h . Emerg Med Australas 
2009 ;21 :117 –23 . doi:10.1111/j.1742-6723.2009.01166.x19422408 
25 van Noord I , Eikens MP , Hamersma AM  
Application of root cause analysis on malpractice claim files related to diagnostic failures . Qual Saf Health Care 
2010 ;19 :e21 
doi:10.1136/qshc.2008.02980120630930 
26 Patterson PD , Huang DT , Fairbanks RJ  
The emergency medical services safety attitudes questionnaire . Am J Med Qual 
2010 ;25 :109 –15 . doi:10.1177/106286060935210620133519 
27 Patterson PD , Huang DT , Fairbanks RJ  
Variation in emergency medical services workplace safety culture . Prehosp Emerg Care 
2010 ;14 :448 –60 . doi:10.3109/10903127.2010.49790020809688 
28 Evans SM , Smith BJ , Esterman A  
Evaluation of an intervention aimed at improving voluntary incident reporting in hospitals . Qual Saf Health Care 
2007 ;16 :169 –75 . doi:10.1136/qshc.2006.01934917545341 
29 Zwart DL , Van Rensen EL , Kalkman CJ  
Central or local incident reporting? A comparative study in Dutch GP out-of-hours services . Br J Gen Pract 
2011 ;61 :183 –7 . doi:10.3399/bjgp11X56116821375902 
30 Reznek MA , Barton BA  
Improved incident reporting following the implementation of a standardized emergency department peer review process . Int J Qual Health Care 
2014 ;26 :278 –86 . doi:10.1093/intqhc/mzu04524771402 
31 Pham JC , Kirsch TD , Hill PM  
Seventy-two-hour returns may not be a good indicator of safety in the emergency department: a national study . Acad Emerg Med 
2011 ;18 :390 –7 . doi:10.1111/j.1553-2712.2011.01042.x21496142 
32 Jones F , Podila P , Powers C  
Creating a culture of safety in the emergency department: the value of teamwork training . J Nurs Adm 
2013 ;43 :194 –200 . doi:10.1097/NNA.0b013e31828958cd23528684 
33 Patterson MD , Geis GL , LeMaster T  
Impact of multidisciplinary simulation-based training on patient safety in a paediatric emergency department . BMJ Qual Saf 
2013 ;22 :383 –93 . doi:10.1136/bmjqs-2012-000951
34 Shaw KN , Lavelle J , Crescenzo K  
Creating Unit-Based Patient Safety Walk-Rounds in a Pediatric Emergency Department . Clin Ped Emerg Med 
2006 ;7 :231 –7 . doi:10.1016/j.cpem.2006.08.012
35 Patterson PD , Weaver MD , Abebe K  
Identification of adverse events in ground transport emergency medical services . Am J Med Qual 
2012 ;27 :139 –46 . doi:10.1177/106286061141551521816967 
36 Schull MJ , Guttmann A , Leaver CA  
Prioritizing performance measurement for emergency department care: consensus on evidence-based quality of care indicators . CJEM 
2011 ;13 :300 –9 , E28-43 .21955411 
37 Patterson PD , Lave JR , Martin-Gill C  
Measuring adverse events in helicopter emergency medical services: establishing content validity . Prehosp Emerg Care 
2014 ;18 :35 –45 . doi:10.3109/10903127.2013.81817924003951 
38 Flowerdew L , Brown R , Vincent C  
Development and validation of a tool to assess emergency physicians’ nontechnical skills . Ann Emerg Med 
2012 ;59 :376 –85 . doi:10.1016/j.annemergmed.2011.11.02222424654 
39 Jaynes CL , Cook P , Farmer R  
Assessing satisfaction and quality in the EMS/HEMS working relationship . Air Med J 
2013 ;32 :338 –42 . doi:10.1016/j.amj.2013.05.00724182883 
40 Harvey A , Nathens AB , Bandiera G  
Threat and challenge: cognitive appraisal and stress responses in simulated trauma resuscitations . Med Educ 
2010 ;44 :587 –94 . doi:10.1111/j.1365-2923.2010.03634.x20604855 
41 Bong CL , Lightdale JR , Fredette ME  
Effects of simulation versus traditional tutorial-based training on physiologic stress levels among clinicians: a pilot study . Simul Healthc 
2010 ;5 :272 –8 . doi:10.1097/SIH.0b013e3181e98b2921330809 
42 Lateef F  
Simulation-based learning: Just like the real thing . J Emerg Trauma Shock 
2010 ;3 :348 –52 . doi:10.4103/0974-2700.7074321063557 
43 Stump LS  
Re-engineering the medication error-reporting process: removing the blame and improving the system . Am J Health System Pharm 
2000 ;57 (Suppl 4) :S10 –17 .11148939 
44 Benn J , Koutantji M , Wallace L  
Feedback from incident reporting: information and action to improve patient safety . Qual Saf Health Care 
2009 ;18 :11 –21 . doi:10.1136/qshc.2007.02416619204126 
45 Gandhi TK , Graydon-Baker E , Huber CN  
Closing the loop: follow-up and feedback in a patient safety program . Jt Comm J Qual Patient Saf 
2005 ;31 :614 –21 .16335062 
46 Hartnell N , MacKinnon N , Sketris I  
Identifying, understanding and overcoming barriers to medication error reporting in hospitals: a focus group study . BMJ Qual Saf 
2012 ;21 :361 –8 . doi:10.1136/bmjqs-2011-000299
47 Snijders C , Kollen BJ , van Lingen RA  , NEOSAFE Study Group . Which aspects of safety culture predict incident reporting behavior in neonatal intensive care units? A multilevel analysis . Crit Care Med 
2009 ;37 :61 –7 . doi:10.1097/CCM.0b013e31819300e419050606 
48 Leape LL  
Reporting of adverse events . N Engl J Med 
2002 ;347 :1633 –8 . doi:10.1056/NEJMNEJMhpr01149312432059 
49 Clarke JR  
How a system for reporting medical errors can and cannot improve patient safety . Am Surg 
2006 ;72 :1088 –91 ; discussion 1126–48 .17120952 
50 Rosen AK , Zhao S , Rivard P  
Tracking rates of patient safety indicators over time: lessons from the Veterans Administration . Med Care 
2006 ;44 :850 –61 . doi:10.1097/01.mlr.0000220686.82472.9c16932137 
51 Pugh M , Reinertsen J  
Reducing harm to patients: using patient safety dashboards at the board level . Healthc Exec 
2007 ;22 :64 –5 .17378476 
52 Goeschel CA , Holzmueller CG , Pronovost PJ  
Hospital Board Checklist to improve culture and reduce central line associated bloodstream infections . Jt Comm J Qual Patient Saf 
2010 ;36 :525 –8 .21090024 
53 Hover AR , Sistrunk WW , Cavagnol RM  
Effectiveness and cost of failure mode and effects analysis methodology to reduce neurosurgical site infections . Am J Med Qual 
2014 ;29 :517 –21 . doi:10.1177/106286061350568024101683 
54 Ursprung R , Gray JE , Edwards WH  
Real time patient safety audits: improving safety every day . Qual Saf Health Care 
2005 ;14 :284 –9 . doi:10.1136/qshc.2004.01254216076794 
55 Ivers N , Jamtvedt G , Flottorp S  
Audit and feedback: effects on professional practice and healthcare outcomes . Cochrane Database Syst Rev 
2012 ;6 :CD000259 
doi:10.1002/14651858.CD000259.pub322696318 
56 Volpp KG , Grande D  
Residents’ suggestions for reducing errors in teaching hospitals . N Engl J Med 
2003 ;348 :851 –5 . doi:10.1056/NEJMsb02166712606742


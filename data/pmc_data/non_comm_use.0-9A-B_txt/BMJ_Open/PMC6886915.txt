
==== Front
BMJ OpenBMJ OpenbmjopenbmjopenBMJ Open2044-6055BMJ Publishing Group BMA House, Tavistock Square, London, WC1H 9JR bmjopen-2018-02880010.1136/bmjopen-2018-028800Medical Education and TrainingOriginal Research15061709Is computer-assisted instruction more effective than other educational methods in achieving ECG competence amongst medical students and residents? A systematic review and meta-analysis http://orcid.org/0000-0001-7246-4136Viljoen Charle André 1Scott Millar Rob 1Engel Mark E 2Shelton Mary 3Burch Vanessa 2
1 
Cardiology, University of Cape Town, Cape Town, South Africa

2 
Medicine, Unversity of Cape Town, Cape Town, South Africa

3 
Health Sciences Library, University of Cape Town, Cape Town, South Africa
Correspondence to  Dr Charle André Viljoen; charle.viljoen@uct.ac.za2019 18 11 2019 9 11 e02880027 12 2018 09 9 2019 11 9 2019 © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.2019This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.Objectives
It remains unclear whether computer-assisted instruction (CAI) is more effective than other teaching methods in acquiring and retaining ECG competence among medical students and residents.

Design
This systematic review and meta-analysis followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines.

Data sources
Electronic literature searches of PubMed, databases via EBSCOhost, Scopus, Web of Science, Google Scholar and grey literature were conducted on 28 November 2017. We subsequently reviewed the citation indexes for articles identified by the search.

Eligibility criteria
Studies were included if a comparative research design was used to evaluate the efficacy of CAI versus other methods of ECG instruction, as determined by the acquisition and/or retention of ECG competence of medical students and/or residents.

Data extraction and synthesis
Two reviewers independently extracted data from all eligible studies and assessed the risk of bias. After duplicates were removed, 559 papers were screened. Thirteen studies met the eligibility criteria. Eight studies reported sufficient data to be included in the meta-analysis.

Results
In all studies, CAI was compared with face-to-face ECG instruction. There was a wide range of computer-assisted and face-to-face teaching methods. Overall, the meta-analysis found no significant difference in acquired ECG competence between those who received computer-assisted or face-to-face instruction. However, subanalyses showed that CAI in a blended learning context was better than face-to-face teaching alone, especially if trainees had unlimited access to teaching materials and/or deliberate practice with feedback. There was no conclusive evidence that CAI was better than face-to-face teaching for longer-term retention of ECG competence.

Conclusion
CAI was not better than face-to-face ECG teaching. However, this meta-analysis was constrained by significant heterogeneity amongst studies. Nevertheless, the finding that blended learning is more effective than face-to-face ECG teaching is important in the era of increased implementation of e-learning.

PROSPERO registration number
CRD42017067054.

ECGcomputer-assisted instructionweb-based learninge-learningsystematic reviewspecial-featureunlocked
==== Body
Strengths and limitations of this study
To the best of our knowledge, this is the first systematic review and meta-analysis comparing the efficacy of computer-assisted instruction to other methods of ECG instruction among medical students and residents.

Systematic reviews provide robust evidence because they follow a rigorous method of search, selection and appraisal of articles.

We used the Medical Education Research Study Quality Instrument (MERSQI) to assess the quality of studies included in this systematic review.

The interpretation of the meta-analysis results is constrained by significant heterogeneity among the studies.

This systematic review with its meta-analysis and subanalyses identified valuable information about the educational approaches and types of computer-assisted learning material that were beneficial in acquiring ECG competence.

Introduction
The ECG is an indispensable diagnostic modality in cardiac disease.1 2 Although knowledge of, and skills in ECG analysis and interpretation, hereafter referred to as ECG competence, are desired learning outcomes of undergraduate and postgraduate medical training programmes, there is ongoing concern that graduating medical trainees lack adequate ECG competence.3–12 Many reasons account for this observation. First, electrocardiography is a difficult subject to teach and to learn.13 14 Second, although clinical exposure is important to gain experience in ECG analysis and interpretation,15 experiential learning alone does not guarantee ECG competence unless it is supplemented by structured teaching.16 Third, medical knowledge is ever-expanding,17 and there is limited time allocated to the teaching of electrocardiography in medical curricula.18–22 Alternative methods of instruction are therefore being sought to improve ECG training.

Technology-enhanced methods of instruction are increasingly being implemented in the training of healthcare professionals.23–25 It remains important to review whether these novel teaching and learning methods are effective.26 Previous studies have shown that students’ knowledge of, and skills in the analysis and interpretation of ECGs improve with computer-assisted instruction (CAI).27–34 However, these studies did not compare CAI to other methods of instruction and thus it cannot be concluded that CAI is better than traditional methods of ECG teaching.

To the best of our knowledge, there is no published systematic review comparing the efficacy of CAI with other methods of ECG instruction for training medical students and residents. Systematic reviews are important in the era of best evidence health professions education,35 because they follow a rigorous process of searching, selecting and appraising eligible articles.36 37 Reviewer bias is limited by applying strict criteria when appraising the articles and summarising the strengths and weaknesses of the studies evaluated.36–38


Objectives
The objectives of this systematic review were to:

establish whether CAI (on its own or in a blended learning setting) achieves better acquisition of ECG competence among medical students and residents than other methods of ECG instruction do;

establish whether CAI (on its own or in a blended learning setting) achieves better retention of ECG competence among medical students and residents than other methods of ECG instruction do;

establish whether there is a difference in the effectiveness of computer-assisted ECG instruction between medical students and residents enrolled for specialty training;

identify the types of learning material and/or activities that are used in computer-assisted ECG instruction, and to establish which CAI material and/or activities are associated with better outcomes;

identify the educational approaches used in computer-assisted ECG instruction, and to establish which of these are associated with better outcomes;

identify learning theories that may underpin computer-assisted ECG instruction.

Methods
A protocol was developed in accordance with the Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols (PRISMA-P) guidelines39 and registered with the International Prospective Register of Systematic Reviews (PROSPERO) on 6 July 2017 with registration number CRD42017067054.40


Search strategy
By using the search strategy described in the protocol,40 and shown in online supplementary file 1, we searched for relevant studies on 28 November 2017 using the following electronic databases: PubMed, EBSCOhost (which searched Academic Search Premier, CINAHL, PsycINFO, Education Resources Information Center, Africa-Wide Information, Teacher Reference Center), Scopus, Web of Science and Google Scholar. Citation indexes and reference lists were reviewed, and a grey literature search was also conducted.

10.1136/bmjopen-2018-028800.supp1Supplementary data 



 Eligibility criteria
As summarised in table 1, all studies that compared the efficacy of CAI with other methods of ECG instruction were eligible for inclusion in this review. Studies were excluded if the teaching methods were not exclusively used to teach ECGs, or if the subject of teaching was not the conventional 12-lead ECG. We included studies in which the participants were medical students and/or residents enrolled for specialty training. Studies were excluded if the data for medical students or residents could not be separately identified from students other than medical students, healthcare professionals who were not medical doctors or qualified doctors who were not in training. We excluded studies that did not assess ECG knowledge and analysis and interpretation skills (ECG competence). There were no language or geographical restrictions. All eligible articles published before 1 July 2017 were included.40


Table 1 Eligibility criteria

Inclusion criteria	Exclusion criteria	

Population
	

Medical students; or

Residents enrolled for specialty training in for example, cardiology, internal medicine, emergency medicine, family medicine, anaesthetics or paediatrics


	
Students other than medical students; or

Healthcare professionals who are not medical doctors


	

Intervention
	

Online or offline computer-assisted instruction used to teach the analysis and interpretation of ECGs


	
Computer-assisted instruction not included as teaching modality in study

Teaching modalities were not primarily and solely used to teach ECGs

The subject of teaching was not the conventional 12-lead ECG


	

Comparator
	

Any comparative ECG teaching method, not making use of computer-assisted instruction


	
Absent or inadequately described comparator or control group


	

Outcome
	
Educational intervention’s effectiveness:Acquisition of ECG competence, or

Retention of ECG competence, or

Level of Kirkpatrick outcomes


	
There is no objective outcome measured (ie, no testing of ECG competence)


	

Study
	
Any comparative research design:Randomised controlled trial, or

Cohort study, or

Case-control study, or

Before-and-after study, or

Cross-sectional research


	Any non-comparative research design:Audit, or

Case-series, or

Historical narrative, or

Survey based


	
Study selection
Two reviewers (CAV and RSM) independently screened all the articles identified by the search. All titles and abstracts were screened for eligibility and full-text articles of all studies potentially meeting inclusion criteria were retrieved. Both reviewers (CAV and RSM) individually evaluated the full text articles using a predesigned form evaluating each study’s eligibility. Where there was no consensus, the reviewers (CAV and RSM) discussed uncertainties pertaining to inclusion eligibility and a third reviewer (VCB) acted as an adjudicator.

Data abstraction
Two reviewers (CAV and RSM) independently extracted data from all eligible studies using a standardised electronic data abstraction form hosted on Research Electronic Data Capture (REDCap),41 which was subsequently crosschecked (CAV and RSM). Data extraction included study design, study duration, study population, ECGs used during teaching, teaching methods (CAI and non-CAI methods), type of digital learning material, educational approaches, learning theories underpinning instructional methods (using a classification proposed by Taylor).42 ECG competencies measured, testing times and results, as well as the validity and reliability of results with psychometric properties of the assessment tools (eg, Cronbach’s α coefficient) where reported.

In the event of missing or unreported data, corresponding authors were contacted. Following two email messages, a delay of 6 weeks was allowed to receive a response.

Quality of included studies and risk of bias assessment
The Medical Education Research Study Quality Instrument (MERSQI) was used to assess the quality of studies included in this systematic review. The MERSQI is a validated quality assessment tool used in health professions education to evaluate the quality of experimental, quasi-experimental and observational studies.36 43


As recommended by the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA),44 two reviewers (CAV and RSM) independently assessed each included study for risk of selection, performance, attrition, detection and/or reporting bias.

Data synthesis
Tests scores (pre-intervention test, post-intervention test and delayed post-intervention test) reported in the studies were used as objective measures of teaching method effectiveness.34 40 45 Where the mean or SD results were not reported, these were requested from the authors or, in the absence of a reply, calculated using the formula of Wan et al.46 The mean and SD results for the CAI and non-CAI groups in each study were converted to a standardised mean difference (effect size, Cohen’s d).47–49 Random-effects models were used to pool weighted effect sizes for all studies, as well as for the planned subanalyses. Planned subanalyses were conducted based on the level of training of participants (students or residents), the different educational approaches reported in the studies (eg, blended learning or not, massed or distributed instruction, restricted or unrestricted access to CAI, online or offline use of CAI), as well as learning materials (eg, real patient ECGs, case scenarios, images, animations) and learning activities (eg, online chat rooms, self-administered quizzes with automated feedback) used with CAI. The consistency in results was determined by visualising the forest plots and calculating the I2 statistic.50Statistical analyses were performed on Stata (V.14.2, StataCorp, College Station, Texas, USA) and Review Manager (RevMan, V.5.3.5, Copenhagen: The Nordic Cochrane Centre, The Cochrane Collaboration, 2014).

We analysed studies for their educational impact using the modified version of the Kirkpatrick framework.35 51–53 The modified Kirkpatrick model is a widely used method of appraising the outcome of educational interventions by measuring participants’ perceptions of (reactions to) the learning experience (level 1), modification of participants’ perceptions of the intervention (level 2a), modification of their knowledge and/or skills (level 2b), transfer of learning to the workplace (level 3), change in organisational practice (level 4a) and benefits to patients (level 4b).

Patient and public involvement
There were no patients or public involved in this systematic review and meta-analysis.

Results
Trial flow
Our search strategy identified 592 papers, that is, 129 articles in PubMed, 349 in EBSCOhost, 65 in Scopus and 49 in Web of Science. We identified an additional 32 papers by reviewing the citation indexes and reference lists of the identified articles and grey literature. After 65 duplicate publications were removed, another 437 articles were excluded by screening their titles and abstracts. From the remaining 122 articles that were assessed in full text, thirteen articles met the predefined eligibility criteria for this systematic review. The reasons for exclusion are shown in figure 1. Eight studies contained sufficient data (mean scores, SD and number of participants reported for each cohort) to be included in the meta-analysis.

Figure 1 Trial flow. CAI, computer-assisted instruction.

Study characteristics

Table 2 summarises the characteristics of the nine randomised control trials and four prospective cohort studies that were included in this systematic review. Nine studies were conducted at a single centre, three studies at two centres and one study at more than two centres. Four studies were conducted in the USA,54–57 three in the UK,58–60 two in France61 62 and one each in China,63 Iran,64 India65 and Sweden.66 All the studies were published in English and included 1242 students and 86 residents in total. Of the thirteen studies, eleven focused on undergraduate students,54–58 60 61 63–66 one on residents62 and one on both students and residents.59


Table 2 Characteristics of included studies in this systematic review

Study characteristic	All	Students	Residents	
N studies	N participants	N studies	N participants	N studies	N participants	

All studies that met eligibility criteria
			
 All studies included	13	1328	12	1242	2	86	

Study design
			
 Randomised control trial	9	950	8	864	2	86	
 Prospective cohort study	4	378	4	378	0	0	

Face-to-face teaching
compared with
	
 Blended learning (CAI with face-to-face teaching)	4	457	4	457	0	0	
 CAI alone	9	871	8	785	2	86	

Frequency of exposure to teaching method
	
 Massed instruction	3	267	3	220	1	47	
 Distributed instruction	9	861	8	822	1	39	
 Unknown	1	200	1	200	0	0	

Computer-assisted instruction
			
 Online	7	658	6	619	1	39	
 Offline	5	470	5	423	1	47	
 Not specified	1	200	1	200	0	0	

Learning material as presented by CAI
	
 Real patient 12-lead ECGs	10	982	9	896	2	86	
 Case scenarios	4	378	3	339	1	39	
 Text	8	908	8	861	1	47	
 Images	2	110	2	110	0	0	
 Animations	3	253	3	206	1	47	
 Self-administered assessment with feedback	8	637	7	598	1	39	
 Chat rooms	2	279	2	279	0	0	
 Unspecified	2	307	2	307	0	0	

ECGs taught
	
 Basic principles	8	718	7	632	2	86	
 Normal ECG	5	707	5	660	1	47	
 Bradyarrhythmias	5	579	4	493	2	86	
 Tachyarrhythmias	5	579	4	493	2	86	
 Arrhythmias (unspecified)	2	288	2	288	0	0	
 Chamber enlargement	5	637	5	590	1	47	
 Acute coronary syndromes	7	867	6	781	2	86	
 Pericarditis	3	288	3	288	0	0	
 Metabolic abnormalities	7	867	6	781	2	86	
 Drug effects	2	264	2	264	0	0	
 Not specified	4	362	4	362	0	0	

Testing ECG knowledge and/or competence
			
 Pre-test*	6	718	5	679	1	39	
 Post-test†	13	1328	12	1242	2	86	
 Delayed post-test‡	1	168	1	121	1	47	

Method of testing
			
 Multiple choice questions	5	544	4	458	2	86	
 Short answer questions	5	639	5	639	0	0	
 Not specified	3	310	3	310	0	0	

The modified Kirkpatrick’s framework for the evaluation of educational interventions
			
 Level 1§	8	864	8	817	1	47	
 Level 2a¶	3	398	3	351	1	47	
 Level 2b**	13	1328	12	1242	2	86	
*Assessment of the baseline ECG knowledge and/or competence before the educational intervention has taken place;

†Assessment of the acquisition of ECG knowledge and/or competence after the educational intervention has taken place;

‡Assessment of the retention of ECG knowledge and/or competence by means of a repeat assessment after the educational intervention, without any further instruction since the acquisition of knowledge was assessed;

§Level 1: Participants reactions;

¶Level 2a: Changes in attitudes and perceptions;

**Level 2b: Acquisition of knowledge and skills

CAI, computer-assisted instruction; N, number.

As shown in online supplementary file 2, the earliest study on the use of computer-assisted ECG instruction was published in 1965,60 followed by two studies in the mid 80s.55 56 Most of the studies were published in the last decade,54 57–59 61–66 the majority of which used online CAI (web-based instruction).54 58 61–64 66


10.1136/bmjopen-2018-028800.supp2Supplementary data 



 Study quality
A detailed summary of the quality of the included studies as measured by the MERSQI tool is contained in online supplementary file 3. The mean MERSQI total score of all included studies was 12.73 (SD 1.76). The studies scored well in the domains that assessed the type of data and data analysis. All studies had objective outcome assessments and twelve of the thirteen studies reported appropriate analyses, which extended beyond descriptive analysis. Studies scored poorly in the sampling domain: more than two-thirds of studies were conducted at a single centre and a third had a response rate of either less than 50% or did not report their response rate.

10.1136/bmjopen-2018-028800.supp3Supplementary data 



 Risk of bias
As elaborated in table 3, and summarised in online supplementary file 3, there was selection bias and/or performance bias in nine studies. Three studies had attrition bias and one had reporting bias.

Table 3 Summary of the study design, assessment of knowledge and outcomes of the included studies

Author (country)

Journal
Year	Study design, participants, response rate	Prior ECG exposure / training	Assessment of ECG knowledge	Quality assessmentMERSQI score

Risk of bias

Validity and reliability where reported by authors


	OutcomesFindings summarised

Kirkpatrick’s framework for evaluation of educational intervention


	
CAIScore of assessment(s)

When assessment(s) took place


	Comparator methodScore of assessment(s)

When assessment(s) took place, not assessed


	

Barthelemy
et al

62

(France)

Eur J Emerg Med
2017	Randomised control trial on residents rotating in the emergency department of four university hospitals
randomised to eitherfour months access to an ‘e-learning course’ (19 residents), or

two ‘lectures’ of 180 min each (20 residents)



100% response rate	Not reported	
Pre-test (
b
aseline knowledge)
	MERSQI score 15.5




Risk of bias: comparison group had last lecture three months prior to acquisition of knowledge test, whereas CAI group had access to e-learning up to two weeks prior to acquisition of knowledge test	Significant improvement from pre-test to post-test in both groups. However, no statistically significant difference between CAI and lectures. Benefits of e-learning are that it allows for practice with feedback and asynchronous learning.




KirkpatrickLevel 2b


	

Median
42.1
%
(IQR
34.8
–
49.4)
	
Median 37.5% (IQR 30.7–
44.2
)

(p=0.42 compared with CAI)	
Assessed before CAI	Assessed before lectures	

Post-test (
a
cquisition of knowledge)
	

Median
59.5
%
(IQR
51.8
–
67.1)
	
Median 51% (IQR 42.4–
59.6
)

(p=0.12 compared with CAI)	
Assessed four months after baseline test, two weeks after last CAI	Assessed four months after baseline test, three months after last lecture	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Rui
et al

63

(China)

BMC Med Educ
2017	Randomised control trial with 181 junior medical students from a single centre.
Randomised to either
‘Flipped classroom method’ (prior to lecture students watched online video, read a textbook and PowerPoint courseware, and completed a pre-assignment) exposure time of 42.33±22.19 min before lectures, three lectures of 135 min and 56.5±46.8 min after lectures (90 students)


‘Lecture-based learning’, with exposure time of 30.55±10.15 min before lectures, three lectures of 125 min and 54.62±31.77 min after lectures (91 students)



100% response rate	None	
Pre-test (
b
aseline knowledge)
	MERSQI score 14.5




Though no pre-test was done, groups were similar with regards to scores in core course grade point averages. It needs to be pointed out that it may be the method of flipped classroom that is more effective, not necessarily the CAI itself. However, the flipped classroom method does use an online platform for study material prior to lectures.	Flipped classroom (including online learning) was more effective than lecture-based learning alone. However, the flipped classroom method requires more time for preparation for both lecturer and student.




KirkpatrickLevel 1

Level 2b


	
Not assessed	Not assessed	

Post-test (
a
cquisition of knowledge)
	

Mean
87.2
%
(
SD
10.1)
	
Mean
80.3
%
(
SD
10.1)

(p<0.001 compared with flipped classroom)	
Assessed 1 week after last instruction	Assessed 1 week after last instruction	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Chudgar
etal54

(USA)

J Electrocardiol
2016	Prospective cohort study with second year medical students from a single centre during their internal medicine clerkship.



The group exposed to CAI had access to an online ‘ECG teaching module’ (ECGTM) for full academic year (101 students)

The comparator group only attended face-to-face teaching that forms part of medical clerkship (90 students)



83% response rate in CAI group, response rate in comparator group not reported.	All students attended an interactive ‘workshop’ on how to perform and interpret an ECG and ‘didactic lecture’ with ECGs and clinical scenarios a week prior to the clerkship.	
Pre-test (
b
aseline knowledge)
	MERSQI score 11.5




There was continued use of the CAI after the clerkship, which could have impacted on the end of year results. Also, the summative assessment at the end of the academic year might have had an impact on end of year results being better than post-clerkship results.	CAI group performed significantly better in end of year test, as compared with comparator group.




CAI demonstrated a significant improvement from the start to the end of clerkship (p<0.001). However, no comparison with control group for these measurements.




KirkpatrickLevel 1

Level 2a

Level 2b


	

Median
57.5
%
(IQR
40
–
60)
	Not reported	
Assessed at start of clerkship	

Post-test (
a
cquisition of knowledge)
	

Median
70
%
(IQR
60
–
80)
	Not reported	
Assessed at end of clerkship	

Delayed post-test (
r
etention of knowledge)
	

Median
92
%
(IQR
80
–
96)
	
Median 76% (IQR 68–
84
)

(p<0.001 compared with CAI)	
Assessed at end of academic year	Assessed at end of academic year	

Davies
et al58

(UK)

Clin Teach
2016	Randomised control trial with second year medical students from one centre.
Randomised to either‘E-learning module’, exposure time not reported (18 students), or

‘Near-peer teaching’, two immediately consecutive 30 min ‘face-to-face tutorials’ (21 students)



Of the 55 medical students invited, 39 consented to take part in study. 100% response rate of consented students.	Not reported	
Pre-test (
b
aseline knowledge)
	MERSQI score 15.5




Risk of selection bias (ECG knowledge not assessed at study entry to determine whether to groups had similar baseline knowledge)




Assessment was based on curriculum, and was compared with previous examinations for validity and reliability.	Both e-learning and near-pear teaching effective, but near-pear teaching reported as more effective. However, since no pre-test was done to prove that groups were equal, it cannot be concluded that near-pear teaching is superior.




KirkpatrickLevel 1

Level 2a

Level 2b


	
Not assessed	Not assessed	

Post-test (
a
cquisition of knowledge)
	

Mean 74% (SD 11.6
)
	
Mean 84% (SD 6.6
)

(p=0.002 compared with CAI)	
Assessed 2 hours after e-learning	Assessed 2 hours after near-peer teaching	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Fent
et al

59

(UK)

J Electrocardiol
2016	Randomised control trial with third, fourth and fifth year medical students, as well as first year residents from two centres.
Randomised to either45 min CAI, ‘ECG simulator teaching’ (67 students, 18 residents),

45 min ‘tutorial’ in ‘small group teaching’ format (54 students, 29 residents)



100% response rate for acquisition of knowledge test, but only 14% response rate for retention of knowledge test	Students had no formal ECG training in the same academic year of study; residents had variable prior ECG experience.	
Pre-test (
b
aseline knowledge)
	MERSQI score 13, up to acquisition of knowledge test (but 12 if considering drop-out rate for retention of knowledge test)




Ratio of student to resident not the same in the two groups; more residents in the comparator group. Retention of knowledge test only written by 14% of participants.	No difference between CAI and small group teaching for acquisition or retention of ECG competence. However, the ratio of students to residents was not the same for the two groups. Only 14% of participants completed the retention of knowledge assessment.
KirkpatrickLevel 1

Level 2a

Level 2b


	
Not assessed	Not assessed	

Post-test (
a
cquisition of knowledge)
	

Mean
66.2
%
(
SD
17.3)
	
Mean 70.7% (SD 18.8
)

(p=0.12 compared with CAI)	
Assessed on same day as CAI	Assessed on same day as small group teaching	

Delayed post-test (
r
etention of knowledge)
	

Mean 53.0% (SD 17.7
)
	
Mean 57.9% (SD 21.5
)

(p=0.55 compared with CAI)	
Assessed 3 months later	Assessed 3 months later	

Montassier
et al61

(France)

Eur J Emerg Med
2016	Prospective, randomised, controlled, non-inferiority study, with fifth year medical students from one centre.
Randomised to either6 weeks access to ‘e-learning course’, median 180 min (49 students), or

Single ‘lecture’ of 180 min (49 students)



Response rate not reported.	Students attended ECG lectures in their second and fourth year of study	
Pre-test (
b
aseline knowledge)
	MERSQI score 13.5




Though response rate not reported, groups were equal in size. CAI group had access to e-learning up to two weeks before assessment, whereas lecture group had single lecture three weeks prior to assessment.	Web-based learning non-inferior to lectures.




KirkpatrickLevel 1

Level 2b


	

Median 45% (IQR 30–
60
)
	
Median 45% (IQR 30–
60
)

(p=0.9 compared with CAI)	
Assessed at start of study	Assessed at start of study	

Post-test (
a
cquisition of knowledge)
	

Mean 76% (SD not reported
)
	
Mean 75% (SD not reported
)
	
Assessed 2 weeks after last CAI exposure	Assessed 2 weeks after last CAI exposure	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Sonali
et al65

(India)

Res J Pharm Biol Chem Sci
2014	Randomised control trial with second year medical students from a single centre.
Randomised to either
‘computer-assisted learning’ (100 students)


‘traditional blackboard teaching’ (100 students)



Response rate not reported	Not reported	
Pre-test (
b
aseline knowledge)
	MERSQI score 11.5




Exposure times, learning material, topics and response rate not reported.	Both CAI and lecture are effective ways of teaching. In this study, CAI was more effective than blackboard teaching.




KirkpatrickLevel 2b


	

Mean 41.44% (SD 10.9
)
	
Mean 35.91% (SD 13.95
)
	
Not reported when assessed	Not reported when assessed	

Post-test (
a
cquisition of knowledge)
	

Mean 70.81% (SD 13.95
)
	
Mean 62.15% (SD 14.75
)
	
Not reported when assessed	Not reported when assessed	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Akbarzadeh
etal64

(Iran)

Research & Development in Medical Education
2012	Prospective cohort study with medical students, at a single centre.
Exposed to either1 hour ‘web-based multimedia education’ (30 students, of which 15 were junior and 15 were senior), or

1 hour ‘classroom-based learning’ (30 students, of which 15 were junior and 15 were senior)



Response rate not reported.	Not reported	
Pre-test (
b
aseline knowledge)
	MERSQI score 9.5




Baseline knowledge not reported for comparator group. Acquisition of knowledge test on same day as tuition.	Web-based learning as effective as small group teaching.




KirkpatrickLevel 1

Level 2b


	

Mean 18% (SD not reported) in junior students


Mean 25% (SD not reported) in senior students
	Not reported	
Not reported when assessed	

Post-test (
a
cquisition of knowledge)
	

Mean 72% (SD not reported) overall
	
Mean 71% (SD not reported) overall
	
Assessed on same day as CAI	Assessed on same day as lectures	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Nilsson
et al66

(Sweden)

BMC Med Educ
2008	Prospective cohort study with medical students from the sixth semester from two centres.
Participants were exposed to either5 months’ access to ‘web-based programme’ (20 students)

3.5 days of ‘conventional teaching’ during the physiology course, which included ECG training (30 students)



85% response rate in CAI group and 83% in the comparator group.	All participants had a 15 hours ECG course in semester prior to study	
Pre-test (
b
aseline knowledge)
	MERSQI score 12




Risk of selection bias (no baseline knowledge test to compare groups).




Risk of performance bias (not specified whether CAI and face-to-face teaching groups were taught same curriculum).	CAI in combination of lecture is better than lectures alone.




Students had positive attitude towards web-based learning.




KirkpatrickLevel 1

Level 2b


	
Not assessed	Not assessed	

Post-test (
a
cquisition of knowledge)
	

Mean
60.63
%
(
SD
13.69)
	
Mean 50.63% (SD 15.44
)

(p=0.03 compared with CAI)	
Assessed at the end of the semester	Assessed at the end of the semester	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Patuwo
et al57

(USA)

Comput Cardiol
2007	Randomised control trial with 35 medical students from one centre during a summer medical education programme.
All participants received 30 min ‘oral instruction’ prior to be randomised to either15 min using ECGSIM software, or

No further instruction



The number of participants in each group and response rate are not reported.	No prior ECG training	
Pre-test (
b
aseline knowledge)
	MERSQI 11.5




The study only assessed participants’ ability to calculate the QRS axis. Reporting bias (number of participants not reported). Risk of selection bias (no pre-test or other measure to compare the two groups prior to exposure to intervention).	Blended learning superior to lecture alone.
However, exposure to CAI was only 15 min.




KirkpatrickLevel 2b


	
Not assessed	Not assessed	

Post-test (
a
cquisition of knowledge)
	

Mean 19.4% (SD 4.2
)
	
Mean 6.4% (SD 3.6
)

(p=0.002 compared with CAI)	
Assessed on same day as CAI	Assessed on same day as teaching	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Fincher
etal56

(USA)

South Med J
1988	Randomised control trial with junior medical students from one centre during their Internal Medicine Clerkship.
Randomised to either
‘computer-assisted learning’ with workbook, exposure time not reported (42 students)

6-weekly 1 hour ‘seminars’, without workbook (41 students)



55% response rate for CAI group, 80% response rate for small group teaching group	Not reported	
Pre-test (
b
aseline knowledge)
	MERSQI score 14




Higher dropout rate in CAI group could imply that more dedicated student remained in study, which could affect results.




Validity of tests were verified. Reliability of second test reported as 0.84.	CAI had better results than tutorials, however, risk of attrition bias must be considered. Better attendance of lectures than CAI (students might feel obliged to attend lectures, whereas less so when doing CAI on their own).




KirkpatrickLevel 2b


	

Mean 8.5% (SD not reported
)
	
Mean 4.8% (SD not reported
)

(P value reported as NS compared with CAI group)	
Assessed at start of study	Assessed at start of study	

Post-test (
a
cquisition of knowledge)
	

Mean 65.8% (SD not reported
)
	
Mean 49.1% (SD not reported
)

(p<0.05 as compared with CAI group)	
Assessed at end of 6 week rotation	Assessed at end of 6 week rotation	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Fincher
et al

55

(USA)

J Med Educ
1987	Randomised control trial with third year medical students from one centre during their Internal Medicine Clerkship.
Randomised to eitherHaving access to an ‘interactive computer programme’, exposure time not reported (55 students)

6 weekly 1 hour ‘seminars’ (52 students)



67% response rate for CAI group, 65% response rate for small group teaching group	Not reported	
Pre-test (
b
aseline knowledge)
	MERSQI score 12.5




Risk of performance bias (most of the students did not complete the CAI modules).	Seminars are not more effective than CAI, however most of the students did not complete the CAI modules.




KirkpatrickLevel 2b


	

Mean 17.6% (SD not reported
)
	
Mean 14.2% (SD not reported
)

(P value not reported)	
Assessed at start of study	Assessed at start of study	

Post-test (
a
cquisition of knowledge)
	

Mean 46.1% (SD not reported
)
	
Mean 39.2% (SD not reported
)

(p=0.79 compared with CAI group)	
Assessed at end of 6 week rotation	Assessed at end of 6 week rotation	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	

Owen
et al

60

(UK)

Postgrad Med J
1965	Prospective cohort study with fifth year medical students from a single centre
Randomised to eitherCAI, with ‘Grundytutor teaching machine’ at medical school), mean exposure time of 14.3 hours (SD 5.82), (36 students)


‘Lectures’, total lecture time 11.7 hours, (41 students)



100% response rate	The authors report that none of participants had much ECG training prior to study	
Pre-test (
b
aseline knowledge)
	MERSQI score 12




Although no pre-test, students in both groups had equal graded performance assessments
The exact topics that were taught were not reported, but it was said to be the same in both groups.




Tests were validated by qualified doctors.	Overall CAI was as effective as lectures
However, subgroup analyses favoured CAI over lectures in academically weaker students and foreign students (who were not necessarily native English speakers).




KirkpatrickLevel 1

Level 2b


	
Not assessed	Not assessed	

Post-test (
a
cquisition of knowledge)
	

Mean 86% (SD 19.1
)
	
Mean 84.2% (SD 23.3
)
	
1 week after completing course	1 week after completing course	

Delayed post-test (
r
etention of knowledge)
	
Not assessed	Not assessed	
CAI, computer-assisted instruction; MERSQI, Medical Education Research Study Quality Instrument.

Educational approaches
In all studies, CAI was compared with face-to-face teaching (refer to glossary for definitions). However, CAI and face-to-face teaching were delivered in variable formats. CAI formed part of a blended learning strategy in four studies (online supplementary file 4).54 57 63 66 In one of these studies, blended learning was applied in a ‘flipped classroom’ approach, where CAI took place before classroom teaching.63 Face-to-face teaching was facilitated by experienced lecturers or specialists in all the studies,54–57 59–66 with the exception of one study in which near-peer teaching was used.58


10.1136/bmjopen-2018-028800.supp4Supplementary data 



 The frequency of instruction in the studies was variable. In three of the thirteen studies, participants were exposed to a single learning event (massed instruction), whether assigned to CAI or face-to-face teaching, before ECG competence was assessed.58 59 64


Learning materials and activities
A range of learning materials were used in CAI (table 2). In most studies, the digital learning material consisted of ECG tracings with accompanying text. In addition, in some studies CAI also included the use of multimedia in the form of diagrams and images64 or animations.57 59 66 As summarised in table 2, the curricular content varied across the studies and a wide range of ECG diagnoses were included.

Active learning (during which learners deliberately engaged with learning material)67 formed an integral part of CAI, which used ‘interactive software’ in all the studies included in this review. In addition to engaging with the learning material, some studies also reported on the use of self-administered assessments with automated feedback,54 56 58 60–62 64 66 online chat rooms61 63 and interaction with lecturers and peers during ‘flipped classroom’ activities.63 Six of the thirteen studies reported interaction between students and lecturers in the non-CAI group, for example, lecturers quizzed students or students asked questions during the face-to-face teaching activities (online supplementary file 5).54 58 59 61 62 64 In the study where CAI was compared with near-peer face-to-face teaching, there was a strong emphasis on interaction between students and tutors in the face-to-face teaching group.58


10.1136/bmjopen-2018-028800.supp5Supplementary data 



 Educational outcomes
The outcomes of the studies are summarised in table 3. Baseline ECG competence was assessed in six of the thirteen studies.54–56 61 62 65 All studies tested ECG competence acquired after the educational intervention; only one study assessed the retention of ECG competence after a period of three months without further instruction since the acquisition of knowledge was tested.59 Five studies used multiple choice questions to assess study participants’ knowledge,58 59 61 62 65 whereas another five used short answer questions marked by the course convenors.54–56 60 63 Three studies did not report how ECG competence was assessed.

Using the Kirkpatrick model of evaluation of educational interventions, it was found that eight studies reported participants’ reactions to CAI (Kirkpatrick level 1)54 58–61 63 64 66 and three studies reported a change in trainees’ attitudes and perceptions after exposure to CAI (Kirkpatrick level 2a).54 58 59 All the studies reported on the acquisition and/or retention of ECG competence (Kirkpatrick level 2b) since this was one of the eligibility criteria of this systematic review. None of the studies reported on outcomes at Kirkpatrick level 3 or 4.

Kirkpatrick level 1 and 2a outcomes were variable. Though some studies reported that students had a positive attitude towards web-based learning,54 60 63 64 66 others reported less favourable attitudes towards CAI than lectures.58 59 61 In one study, all the potential participants did not want to use the e-learning platform and so some potential participants were excluded from the particular study.66 While three studies reported on students who felt that an improvement in their confidence was no better with CAI as compared with lectures,58 59 61 other studies identified students who thought that CAI improved their confidence in ECG interpretation.54 58 66 In general, students valued CAI approaches that included multimedia learning material,59 64 and self-assessment tools.66 In some studies they requested more visually-oriented learning material59 64 and applications that had a facility or method for asking questions.59 Kirkpatrick level 2b outcomes of the studies are summarised in table 3 and have already been described.

Learning theories
Learning theories that underpin education were infrequently mentioned or discussed in any detail. The most frequent reference to learning theories was to self-directed learning in CAI.54 59 62 63 66 One study66 referenced Kolb’s description of experiential learning,68 and another study mentioned ‘cognitive learning’ and ‘collaborative learning’.63 However, careful review of the papers included in this systematic review identified multiple examples of teaching and learning activities that were aligned with contemporary theories of learning. These are shown in table 4 using a simplified classification of learning theories described by Taylor.42


Table 4 Learning theories, based on a classification by Taylor42 that underpinned computer-assisted and face-to-face ECG instruction in the included studies

Learning theories	Examples of instructional methods demonstrating the application of contemporary learning theories	
CAI	Face-to-face teaching	

Instrumental learning theories
	


Cognitivism (ie, acquiring knowledge, learning with demonstrations and explanations, understanding concepts)42 96 106



	
Used multimedia, including animations, audio and video clips used to demonstrate and explain difficult concepts.59 64 66



	
Face-to-face teaching allowed for demonstrations and explanations.65



	


Constructivism* (ie, creating meaning by building personal interpretations of the world based on individual experiences and interactions)


	
Application of knowledge to interpret an ECG and make a diagnosis.

Used a flipped classroom method that allowed for studying material by means of CAI before applying new knowledge in classroom teaching activities.63



	
Application of knowledge to interpret an ECG and make a diagnosis.


	

Humanistic learning theories
	


Andragogy (ie, adult learning driven by internal and external motivation)107 108



	
Used a summative assessment after learning intervention (external motivation).54


Used reminder e-mails used to encourage use of e-learning modules (external motivation).54



	
Used a summative assessment after learning intervention (external motivation).54



	


Self-directed learning (ie, independent, self-regulated learning, learner plans and monitors own learning)109 110



	
Facilitated independent study.55


Provided unlimited access; studying can occur at any place at any time54 58 59 62 64


Allowed for repetition and revision of learning material, at student’s own pace.54 60 64 65



	
Note-taking in lectures and self-study of notes afterwards.59



	

Social learning theories
	


Collaborative learning (ie, interaction with peers and tutors)111 112



	
Chat rooms allowed for interaction with the lecturer and/or other participants.61 63


Blended learning strategies allowed for interaction with lecturer during face-to-face teaching sessions in addition to CAI.54 57 63 66



	
Responding directly to learners’ questions during lecture or tutorial.55 58 59 61 62



	


Contextual learning (ie, case scenarios, multiple examples with different perspectives)113 114



	
Provided case scenarios, making learning relevant and placing the learning in context.54 61 62 66


Provided different examples of same diagnosis.54



	
Provided case scenarios, made learning relevant and placed the learning in context.54 61 62 66


Provided different examples of same diagnosis.54



	

Reflective models
	


Reflection (ie, deliberate practice with feedback)


	
Self-administered quizzes with feedback (self-evaluation) help to enhance learning by highlighting areas that the student needs to focus on.54 61 62 66



	 	
*Constructivism is considered a branch of cognitive learning, but is distinguished by a focus on actively creating meaning rather than merely acquiring knowledge.96


CAI, computer-assisted instruction.

Quantitative data synthesis
Overall, we found that CAI was not better than face-to-face teaching for acquiring ECG competence (standardised mean difference (SMD)=0.32 (95% CI −0.09 to 0.74); eight studies, n=945; I2=88.9%) (figure 2). However, there was inconsistency among the studies and effect sizes ranged from −1.08 to 1.09 (table 5). A positive effect size (ie, CAI was better than face-to-face teaching) was found in most studies, one of which showed a large effect size (>0.8)54 and four a moderate effect size (>0.5).62 63 65 66 However, in two studies59 60 there was no significant difference between CAI and face-to-face teaching and one study showed that face-to-face teaching was better than CAI.58


Figure 2 Overall effect of teaching methods on the acquisition of ECG knowledge and analysis and interpretation skills. CAI, computer-assisted instruction; SMD, standardised mean difference.

Table 5 Acquired and retained ECG competence according to educational approaches used in the included studies

Author	Year	Educational approaches/CAI strategies	Outcome (SMD (95% CI))	
Blended learning*	Massed instruction†	Unrestricted access‡	Deliberate practice§	Acquisition of knowledge	Retention of knowledge	
Studies favouring CAI	
Chudgar54
	2016	X	 	X	X	1.09 (0.79 to 1.4)	 	
Nilsson66
	2008	X	 	X	X	0.68 (0.1 to 1.26)	 	
Rui63
	2017	X	 	X	 	0.68 (0.38 to 0.98)	 	
Barthelemy62
	2017	 	 	X	X	0.65 (0.01 to 1.3)	 	
Sonali65
	2014	 	 	 	 	0.52 (0.24 to 0.80)	 	
No statistical difference	
Owen60
	1965	 	 	 	X	0.08 (−0.36 to 0.53)	 	
Fent59
	2016	 	X	 	 	−0.25 (−0.55 to 0.05)	−0.24 (−1.05 to 0.58)	
Study favouring face-to-face teaching	
Davies58
	2016	 	X	 	 	−1.08 (−1.76 to −0.41)	 	
*CAI formed part of a blended learning strategy (CAI combined with face-to-face teaching)

†Learners were exposed to a single teaching opportunity

‡Unrestricted access to CAI during study period

§CAI facilitated self-administered assessments with feedback

CAI, computer-assisted instruction; SMD, standardised mean difference.

Only one study assessed the effect of CAI on the retention of ECG competence.59 While this study showed that there was no significant difference between the CAI and face-to-face teaching (SMD=−0.24 (95% CI −1.05 to 0.58)), the response rate was only 14% for the retention of knowledge test which was conducted three months after the educational intervention.

Medical students compared to residents
In the subanalysis comparing the acquisition of ECG competence with CAI and face-to-face teaching in undergraduate and postgraduate trainees separately (figure 3), there was a tendency to favour CAI over face-to-face teaching among both medical students (SMD=0.41 (95% CI −0.03 to 0.84); six studies, n=738; I2=87%) and residents (SMD=0.64 (95% CI 0 to 1.28); one study, n=19). The single study assessed the retention of ECG competence combined medical students and residents.59


Figure 3 Pooled effect sizes according to level of training of participants, educational approaches and CAI learning materials used in the studies. CAI, computer-assisted instruction.

Educational approaches
A subanalysis found a large positive effect size when CAI formed part of a blended learning strategy as compared with face-to-face teaching (SMD=0.84 (95% CI 0.54 to 1.14); three studies, n=422; I2=50%) (figure 3). This systematic review did not identify any studies that evaluated the retention of ECG analysis and interpretation skills after exposure to CAI in a blended learning programme.

In another subanalysis, studies using a distributed approach to ECG instruction (ie, more than one ECG training opportunity) showed that CAI was better than face-to-face teaching (SMD=0.65 (95% CI 0.31 to 1.00); five studies, n=538; I2=70%). Review of these studies showed that the benefit of distributed instruction was only present in studies where CAI was part of a blended learning approach (SMD=0.84 (95% CI 0.54 to 1.14); three studies, n=422; I2=50%; vs SMD=0.31 (95% CI −0.21 to 0.84); two studies, n=116; I2=46%). There was no statistically significant difference between CAI and face-to-face teaching when massed instruction strategies were used (ie, a single session of ECG teaching) (figure 3).

Although there was no difference between online and offline CAI, four studies showed that CAI was better than face-to-face teaching when students had unlimited access (ie, 24 hours a day, 7 days a week) to CAI learning materials (SMD=0.82 (95% CI 0.57 to 1.07); four studies, n=461; I2=32%). This benefit, as shown in a subanalysis, was not apparent when access to CAI learning materials was limited (SMD=−0.34 (95% CI −0.86 to 0.18); three studies, n=284; I2=74%).

In the study that used reminder emails to encourage the use of CAI, there was a large effect size in favour of CAI (1.09 (95% CI 0.79 to 1.4)).54


Learning activities and materials used in CAI
Subanalyses showed that CAI was better than face-to-face teaching when ECGs were accompanied by case scenarios (SMD=0.90 (95% CI 0.59 to 1.21); three studies, n=280; I2=24%) and if images were used to explain impulse conduction (SMD=1.09 (95% CI 0.79 to 1.40); one study, n=191). Studies in which CAI included self-administered assessments with automated feedback showed better ECG knowledge acquisition than face-to-face teaching (SMD=0.64 (95% CI 0.14 to 1.13); four studies, n=357; I2=77%) (figure 3). This effect size was larger in studies where self-administered assessment with automated feedback formed part of a blended learning approach (SMD=0.95 (95% CI 0.57 to 1.34); two studies, n=241; I2=38%). CAI was better than face-to-face teaching when students had access to online chat rooms to discuss the study material (SMD=0.68 (95% CI 0.38 to 0.98); one study, n=181) (figure 3).

Discussion
This systematic review and meta-analysis set out to determine whether CAI is more effective than other methods of teaching electrocardiography knowledge and analysis and interpretation skills to undergraduate and postgraduate medical trainees. All the studies included in this systematic review and meta-analysis compared CAI to face-to-face teaching. Based on the overall results of the review there is currently insufficient evidence to favour CAI over face-to-face ECG instruction. Though there was significant heterogeneity in the studies included in the meta-analysis, subanalyses of the different learning materials and educational approaches were less heterogenous. We found that CAI was better than face-to-face teaching when used in a blended learning approach. Studies also favoured computer-assisted distributed instruction with unrestricted access to learning materials; the use of case scenarios to contextualise ECG interpretation with images to explain concepts and interactive learning activities, including chat rooms, and self-assessment with automated feedback. While contemporary learning theories were not explicitly articulated in most studies, there were many examples of computer-assisted instruction strategies and activities that were aligned with these theories.

Although self-directed, computer-assisted learning may seem attractive to busy clinicians with limited time for teaching,55 61 our systematic review and meta-analysis did not find sufficient evidence to recommend that computer-assisted ECG instruction should replace face-to-face teaching. Rather, we found that computer-assisted ECG instruction was more effective than face-to-face teaching when it formed part of a blended learning strategy. This is in keeping with the literature which shows that CAI should be used as an adjunct to face-to-face teaching in order to enhance ECG training.56 61 69 Our findings are also in keeping with the results of a recent meta-analysis published in the health professions education literature, which showed that blended learning was better than face-to-face teaching alone.70 However, as with other systematic reviews and meta-analyses that assessed the efficacy of blended learning in the training of healthcare professionals,71 72 our analyses were also limited by a small number of studies, incomplete reporting of results and significant heterogeneity among the studies.

One of the studies included in this review demonstrated the successful use of CAI in a flipped classroom strategy for teaching ECG analysis and interpretation skills.63 Although the flipped classroom method required more preparation time, for both lecturers and students, trainees were more proactive in discussions with their peers and their lecturers during the face-to-face teaching time, resulting in better post-intervention test scores than traditional face-to-face teaching.73 Since it is accepted that ECG competence is difficult to acquire,13 14 the successful use of a flipped classroom approach is encouraging because this method allows for engagement with the learning material prior to face-to-face interaction with teachers when difficult concepts can be discussed and misunderstandings resolved.

When evaluating the educational effect of teaching and learning methods, it is critical to review access and frequency of exposure to the learning materials. In a subanalysis, students did not benefit from computer-assisted or face-to-face massed instruction (single educational event). As has been previously found,74 CAI was only beneficial if students had multiple exposures to the learning activities and study materials (distributed instruction). In the setting of blended learning, CAI facilitates distributed instruction, because it can be used asynchronously, allowing for consolidation of knowledge acquired during face-to-face teaching.24 34 61 75


This review found that there was a significant benefit to students when they had unrestricted access to CAI learning materials. Although we did not show a difference in outcomes between online and offline CAI, the benefit of web-based learning is that it can be accessed whenever and wherever convenient.24 34 61 75 However, the high cost of, and/or lack of access to computers with Internet facilities may be a barrier to web-based learning, particularly in developing countries.24 64 76 Health professions educators, especially in resource-limited settings should therefore be cognisant of the availability of computers and students’ access to the Internet when planning CAI with online requirements.

A key aspect of any method of instruction is the nature of the learning materials and activities included in the programme. CAI has been shown to enhance the learning experience by using multimedia and interactive learning materials.69 In this study we confirmed that visual material was highly valued by participants and a subanalysis showed specific benefit when using images in combination with the 12-lead ECG, for example to explain cardiac impulse conduction. The value of using images in medical education is that it helps to embed knowledge in long-term memory.25 Although images are widely used to demonstrate concepts in medical education,77 it has previously been shown to be of most value when accompanied by good explanations,78 79 as was the case in the study by Nilsson et al.66 In this study we also found that there were additional educational gains when computer-assisted ECG instruction made use of clinical scenarios.54 61 62 66 This is in line with previous studies which have shown more accurate ECG analysis and interpretation when the clinical context was known.80 81


In this systematic review we found evidence that CAI was better than face-to-face teaching in studies in which the CAI included exercises of ECG analysis and interpretation that required deliberate practice with automated feedback. This finding is in keeping with studies which have shown that practice exercises followed by feedback facilitate high levels of interactivity with educational materials and significantly enhance learning.61 82–84 In CAI there are opportunities for both self-reflection85 and repetitive practice86 because students can repeat the self-assessments, correct their errors and further improve their performance.54 60–62 66 84


The studies included in this review demonstrated variable outcomes using the Kirkpatrick framework of evaluation. Improvement of trainees’ ECG knowledge and analysis and interpretation skills using either CAI and face-to-face instruction was an eligibility criterion for inclusion in the study. A few studies reported on the responses of participants to the methods of instruction used with no consistent preference for CAI. None of the studies evaluated CAI at the level of behavioural change (Kirkpatrick level 3), change in organisational practice (Kirkpatrick level 4a) or improved patient care (Kirkpatrick level 4b). This is consistent with studies showing that health professions education interventions rarely show impact at Kirkpatrick level 3 or 4.87 88 Indeed it is a widely recognised ongoing shortcoming of health professions education research. This systematic review endorses a plea in the literature for the evaluation of educational interventions at the level of impact on physician behaviour,89 90 organisational practice91 92 and patient care.93–95


While learning theories were not explicitly discussed in most of the studies in this review, there were multiple examples of educational strategies that are aligned with contemporary learning theories.96 However, as this review shows, studies describing and evaluating educational interventions continue to be conducted without a firm rationale imbedded in contemporary learning theories. This highlights a significant ongoing shortcoming of health professions education research.97–99


CAI serves as a good example of self-directed learning, whereby students plan and conduct their own learning.42 While face-to-face teaching time is limited,100 CAI allows for flexibility in learning – students can adjust the pace of their learning and spend as much time as they need to assimilate new knowledge. While face-to-face teaching is ideal for promoting collaborative learning by allowing interaction between peers and tutors,55 58 59 61 62 it is also possible in CAI when chat rooms were available61 63 or when CAI forms part of a blended learning programme.54 57 63 66


In this review we found that participants valued learning with demonstrations and explanations (cognitivism).96 CAI-based learning opportunities had the advantage of offering multimedia learning resources, which enrich the educational content by means of animations, audio and video clips.69


The flipped classroom method of teaching ECGs, as described in one study included in this review,63 serves as an excellent example of a learning process which focuses on actively creating meaning rather than merely acquiring knowledge (constructivism).96 In a flipped classroom approach, students used CAI to familiarise themselves with educational content, and expand their learning by using the time in class to discuss concepts that they did not understand.101 It seems that this could be a useful approach for electrocardiography, which is considered a difficult subject to teach and to learn.13 14


Because CAI does not require attendance of class, external motivation in the form of reminder emails or summative assessments might be needed to encourage students to use the e-learning modules. In the study that made use of such external motivation strategies, CAI showed a large positive effect size.54


Though variably applied in the studies in this review, contextualisation was possible in both CAI and face-to-face teaching settings.54 61 62 66 Where CAI made use of patient scenarios, there was a larger benefit in acquiring ECG competence.

Reflective learning is possible with CAI when self-administered quizzes with automated feedback are used. Learning is facilitated because knowledge and/or skills gaps are highlighted.54 61 62 66


Strengths and limitations
The strength of this study is that it was conducted as a systematic review using a comprehensive search strategy and detailed data extraction method. However, the inferences that can be made from this systematic review and its meta-analysis are limited by high levels of bias and the heterogeneity of the included studies. There was significant variability in study design, the format, delivery and exposure time of the teaching intervention (CAI) and control (face-to-face teaching) and the topics taught and assessed.57 Many studies also did not include a baseline test of ECG knowledge and/or analysis and interpretation skills prior to the educational intervention and did not report all their data. Nevertheless, the mean MERSQI score of the studies included in this review was similar to MERSQI scores reported in other systematic reviews in medical education.23 102–104 In fact, 9 of the 13 studies in this review had a high MERSQI score (ie ≥12).105 Furthermore, most of the studies included in this systematic review were performed in well-resourced countries and the generalisability of these findings to resource-constrained settings is therefore not known.

Implications for practice and future research
Owing to the heterogenous nature of the studies included in this review it was not possible to provide conclusive evidence that CAI is better than face-to-face teaching of ECG knowledge and analysis and interpretation skills. However, CAI was better than face-to-face teaching in a blended learning setting where students had unrestricted access to the learning materials and opportunities for self-assessment with automated feedback.

There are currently many aspects of CAI that need to be further explored. These include a more detailed evaluation of the efficacy of this medium of instruction in postgraduate education and its impact on the long-term retention of ECG competence in both undergraduate and postgraduate trainees. Studies are also needed to better understand the impact of CAI on clinician behaviour (ECG analysis and interpretation practices in clinical settings), changes in organisational practice and patient care.

Conclusion
Owing to the mixed findings of the studies included in this systematic review, there is currently insufficient evidence to favour the use of computer-assisted ECG instruction. However, CAI can be used to enhance face-to-face teaching in a blended learning setting. CAI was found to be more beneficial than face-to-face teaching when students had unrestricted access to learning materials and opportunities for self-assessment with automated feedback.

Supplementary Material
Reviewer comments
 Author's manuscript
 The authors wish to thank Ms Sylvia Dennis, Dr Nicholas Simpson, Ms Kathryn Manning and Professsor Ike Okpechi from the University of Cape Town for their valuable support and input.

Twitter: @charleviljoen

Contributors: CAV is a PhD student. RSM and VB are his supervisors. CAV conceived of the review and undertook the drafting of the manuscript. CAV and MS undertook a scoping search and developed the search strategy. CAV and RSM screened all the articles. CAV, RSM and VB were involved in data acquisition. CAV and MEE analysed the data. The results were interpreted by CAV, RSM, VB and MEE. All authors read the manuscript and gave their approval for publication.

Funding: The authors have not declared a specific grant for this research from any funding agency in the public, commercial or not-for-profit sectors.

Competing interests: RSM is a lecturer and host of the AO Memorial Advanced ECG and Arrhythmia Course and receives an honorarium from Medtronic Africa.

Patient consent for publication: Not required.

Provenance and peer review: Not commissioned; externally peer reviewed.

Data availability statement: Data are available via the Dryad data repository at https://datadryad.org/stash/dataset/doi:10.5061/dryad.2dt037b
==== Refs
References
1 
Okreglicki A , Scott Millar R  
ECG: PQRST morphology – clues and tips. A guide to practical pattern recognition . SA Heart Journal 
2006 ;3 :27 –36 .
2 
Auseon AJ , Schaal SF , Kolibash AJ , et al 
Methods of teaching and evaluating electrocardiogram interpretation skills among cardiology fellowship programs in the United States . J Electrocardiol 
2009 ;42 :339 –44 . 10.1016/j.jelectrocard.2009.01.004 
19268967 
3 
Novotny T , Bond RR , Andrsova I , et al 
Data analysis of diagnostic accuracies in 12-lead electrocardiogram interpretation by junior medical fellows . J Electrocardiol 
2015 ;48 :988 –94 . 10.1016/j.jelectrocard.2015.08.023 
26381796 
4 
Kopeć G , Magoń W , Hołda M , et al 
Competency in ECG interpretation among medical students . Med Sci Monit 
2015 ;21 :3386 –94 . 10.12659/MSM.895129 
26541993 
5 
Jablonover RS , Lundberg E , Zhang Y , et al 
Competency in electrocardiogram interpretation among graduating medical students . Teach Learn Med 
2014 ;26 :279 –84 . 10.1080/10401334.2014.918882 
25010240 
6 
McAloon C , Leach H , Gill S , et al 
Improving ECG competence in medical trainees in a UK district general hospital . Cardiol Res 
2014 ;5 :51 –7 . 10.14740/cr333e 
28392875 
7 
de Jager J , Wallis L , Maritz D  
ECG interpretation skills of South African emergency medicine residents . Int J Emerg Med 
2010 ;3 :309 –14 . 10.1007/s12245-010-0227-3 
21373298 
8 
Eslava D , Dhillon S , Berger J , et al 
Interpretation of electrocardiograms by first-year residents: the need for change . J Electrocardiol 
2009 ;42 :693 –7 . 10.1016/j.jelectrocard.2009.07.020 
19740482 
9 
Lever NA , Larsen PD , Dawes M , et al 
Are our medical graduates in New Zealand safe and accurate in ECG interpretation? 
N Z Med J 
2009 ;122 :9 –15 .
10 
Berger JS , Eisen L , Nozad V , et al 
Competency in electrocardiogram interpretation among internal medicine and emergency medicine residents . Am J Med 
2005 ;118 :873 –80 . 10.1016/j.amjmed.2004.12.004 
16084180 
11 
Salerno SM , Alguire PC , Waxman HS  
Competency in interpretation of 12-lead electrocardiograms: a summary and appraisal of published evidence . Ann Intern Med 
2003 ;138 :751 –60 . 10.7326/0003-4819-138-9-200305060-00013 
12729431 
12 
Little B , Mainie I , Ho KJ , et al 
Electrocardiogram and rhythm strip interpretation by final year medical students . Ulster Med J 
2001 ;70 :108 –10 .11795759 
13 
Hurst JW  
Current status of clinical electrocardiography with suggestions for the improvement of the interpretive process . Am J Cardiol 
2003 ;92 :1072 –9 . 10.1016/j.amjcard.2003.07.006 
14583358 
14 
Hurst JW  
Methods used to interpret the 12-lead electrocardiogram: pattern memorization versus the use of vector concepts . Clin Cardiol 
2000 ;23 :4 –13 . 10.1002/clc.4960230103 
10680023 
15 
Alinier G , Gordon R , Harwood C , et al 
12-Lead ECG training: the way forward . Nurse Educ Today 
2006 ;26 :87 –92 . 10.1016/j.nedt.2005.08.004 
16182413 
16 
Devitt P , Worthley S , Palmer E , et al 
Evaluation of a computer based package on electrocardiography . Aust N Z J Med 
1998 ;28 :432 –5 . 10.1111/j.1445-5994.1998.tb02076.x 
9777109 
17 
Nilsson M , Östergren J , Fors U , et al 
Does individual learning styles influence the choice to use a web-based ECG learning programme in a blended learning setting? 
BMC Med Educ 
2012 ;12 :5
10.1186/1472-6920-12-5 
22248183 
18 
Raupach T , Harendza S , Anders S , et al 
How can we improve teaching of ECG interpretation skills? Findings from a prospective randomised trial . J Electrocardiol 
2016 ;49 :7 –12 . 10.1016/j.jelectrocard.2015.10.004 
26615874 
19 
Moura FS , Carvalho FVde , Martins MdoCdeCe , et al 
Knowledge of guidelines for cardiopulmonary resuscitation among Brazilian medical students . Rev Bras Educ Med 
2016 ;40 :77 –85 . 10.1590/1981-52712015v40n1e01772015 

20 
Dong R , Yang X , Xing B , et al 
Use of concept maps to promote electrocardiogram diagnosis learning in undergraduate medical students . Int J Clin Exp Med 
2015 ;8 :7794 –801 .26221331 
21 
Goy J-J , Schlaepfer J , Stauffer J-C  
Competency in interpretation of 12-lead electrocardiogram among Swiss doctors . Swiss Med Wkly 
2013 ;143 :w13806
10.4414/smw.2013.13806 
23740141 
22 
Hurst JW  
The interpretation of electrocardiograms: pretense or a well-developed skill? 
Cardiol Clin 
2006 ;24 :vii:305 –7 . 10.1016/j.ccl.2006.03.001 

23 
Taveira-Gomes T , Ferreira P , Taveira-Gomes I , et al 
What are we looking for in computer-based learning interventions in medical education? A systematic review . J Med Internet Res 
2016 ;18 :e204
10.2196/jmir.5461 
27480053 
24 
Greenhalgh T  
Computer assisted learning in undergraduate medical education . BMJ 
2001 ;322 :40 –4 . 10.1136/bmj.322.7277.40 
11141156 
25 
Swanwick T  
Understanding medical education: evidence, theory and practice . 2nd edn 
Wiley Blackwell , 2013 .
26 
Cook DA , West CP  
Conducting systematic reviews in medical education: a stepwise approach . Med Educ 
2012 ;46 :943 –52 . 10.1111/j.1365-2923.2012.04328.x 
22989128 
27 
Burke JF , Gnall E , Umrudden Z , et al 
Critical analysis of a computer-assisted tutorial on ECG interpretation and its ability to determine competency . Med Teach 
2008 ;30 :e41 –8 . 10.1080/01421590801972471 
18464131 
28 
DeBonis K , Blair TR , Payne ST , et al 
Viability of a web-based module for teaching electrocardiogram reading skills to psychiatry residents: learning outcomes and trainee interest . Academic Psychiatry 
2015 ;39 :645 –8 . 10.1007/s40596-014-0249-x 
25391493 
29 
Jheeta JS , Narayan O , Krasemann T  
Republished: accuracy in interpreting the paediatric ECG: a UK-wide study and the need for improvement . Postgrad Med J 
2015 ;91 :436 –8 . 10.1136/postgradmedj-2013-305788rep 
26304985 
30 
Liu SS , Zakaria S , Vaidya D , et al 
Electrocardiogram training for residents: a curriculum based on Facebook and Twitter . J Electrocardiol 
2017 ;50 :646 –51 . 10.1016/j.jelectrocard.2017.04.010 
28479090 
31 
Porras L , Drezner J , Dotson A , et al 
Novice interpretation of screening electrocardiograms and impact of online training . J Electrocardiol 
2016 ;49 :462 –6 . 10.1016/j.jelectrocard.2016.02.004 
27055937 
32 
Pourmand A , Yadav K , Shokoohi H , et al 
191 can lecture capture technology affects accuracy of EKG interpretation among emergency medicine residents? 
Ann Emerg Med 
2012 ;60 :S68 –9 . 10.1016/j.annemergmed.2012.06.168 

33 
Pourmand A , Tanski M , Davis S , et al 
Educational technology improves ECG interpretation of acute myocardial infarction among medical students and emergency medicine residents . West J Emerg Med 
2015 ;16 :133 –7 . 10.5811/westjem.2014.12.23706 
25671022 
34 
Rolskov Bojsen S , Räder SBEW , Holst AG , et al 
The acquisition and retention of ECG interpretation skills after a standardized web-based ECG tutorial – a randomised study . BMC Med Educ 
2015 ;15 :36
10.1186/s12909-015-0319-0 
25889642 
35 
Harden RM , Grant J , Buckley G , et al 
BEME guide No. 1: best evidence medical education . Med Teach 
1999 ;21 :553 –62 . 10.1080/01421599978960 
21281174 
36 
Sharma R , Gordon M , Dharamsi S , et al 
Systematic reviews in medical education: a practical approach: AMEE guide 94 . Med Teach 
2015 ;37 :108 –24 . 10.3109/0142159X.2014.970996 
25314376 
37 
Yuan Y , Hunt RH  
Systematic reviews: the good, the bad, and the ugly . Am J Gastroenterol 
2009 ;104 :1086 –92 . 10.1038/ajg.2009.118 
19417748 
38 
Cook DJ , Mulrow CD , Haynes RB  
Systematic reviews: synthesis of best evidence for clinical decisions . Ann Intern Med 
1997 ;126 :376 –80 . 10.7326/0003-4819-126-5-199703010-00006 
9054282 
39 
Shamseer L , Moher D , Clarke M , et al 
Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015: elaboration and explanation . BMJ 
2015 ;350 :g7647
10.1136/bmj.g7647 
25555855 
40 
Viljoen CA , Scott Millar R , Engel ME , et al 
Is computer-assisted instruction more effective than other educational methods in achieving ECG competence among medical students and residents? Protocol for a systematic review and meta-analysis . BMJ Open 
2017 ;7 :e018811
10.1136/bmjopen-2017-018811 

41 
Harris PA , Taylor R , Thielke R , et al 
Research electronic data capture (REDCap) – A metadata-driven methodology and workflow process for providing translational research informatics support . J Biomed Inform 
2009 ;42 :377 –81 . 10.1016/j.jbi.2008.08.010 
18929686 
42 
Taylor DCM , Hamdy H  
Adult learning theories: implications for learning and teaching in medical education: AMEE guide No. 83 . Med Teach 
2013 ;35 :e1561 –72 . 10.3109/0142159X.2013.828153 
24004029 
43 
Reed DA , Cook DA , Beckman TJ , et al 
Association between funding and quality of published medical education research . JAMA 
2007 ;298 :1002 –9 . 10.1001/jama.298.9.1002 
17785645 
44 
Moher D , Liberati A , Tetzlaff J , et al 
Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement . Ann Intern Med 
2009 ;151 :W64.:264 –9 . 10.7326/0003-4819-151-4-200908180-00135 

45 
Losco CD , Grant WD , Armson A , et al 
Effective methods of teaching and learning in anatomy as a basic science: a BEME systematic review: BEME guide No. 44 . Med Teach 
2017 ;39 :234 –43 . 10.1080/0142159X.2016.1271944 
28129720 
46 
Wan X , Wang W , Liu J , et al 
Estimating the sample mean and standard deviation from the sample size, median, range and/or interquartile range . BMC Med Res Methodol 
2014 ;14 :135
10.1186/1471-2288-14-135 
25524443 
47 
Sullivan GM , Feinn R  
Using effect Size – or why the P value is not enough . J Grad Med Educ 
2012 ;4 :279 –82 . 10.4300/JGME-D-12-00156.1 
23997866 
48 
Hojat M , Xu G  
A visitor's guide to effect sizes: statistical significance versus practical (clinical) importance of research findings . Adv Health Sci Educ Theory Pract 
2004 ;9 :241 –9 . 10.1023/B:AHSE.0000038173.00909.f6 
15316274 
49 
Faraone SV  
Interpreting estimates of treatment effects: implications for managed care . P T 
2008 ;33 :700 –11 .19750051 
50 
Higgins JPT , Thompson SG , Deeks JJ , et al 
Measuring inconsistency in meta-analyses . BMJ 
2003 ;327 :557 –60 . 10.1136/bmj.327.7414.557 
12958120 
51 
Lameris AL , Hoenderop JGJ , Bindels RJM , et al 
The impact of formative testing on study behaviour and study performance of (bio)medical students: a smartphone application intervention study . BMC Med Educ 
2015 ;15 :72
10.1186/s12909-015-0351-0 
25889923 
52 
Hammick M , Dornan T , Steinert Y  
Conducting a best evidence systematic review. Part 1: from idea to data coding. BEME guide No. 13 . Med Teach 
2010 ;32 :3 –15 . 10.3109/01421590903414245 
20095769 
53 
Curran VR , Fleet L  
A review of evaluation outcomes of web-based continuing medical education . Med Educ 
2005 ;39 :561 –7 . 10.1111/j.1365-2929.2005.02173.x 
15910431 
54 
Chudgar SM , Engle DL , Grochowski CO , et al 
Teaching crucial skills: an electrocardiogram teaching module for medical students . J Electrocardiol 
2016 ;49 :490 –5 . 10.1016/j.jelectrocard.2016.03.021 
27083329 
55 
Fincher RM , Abdulla AM , Sridharan MR , et al 
Comparison of computer-assisted and seminar learning of electrocardiogram interpretation by third-year students . J Med Educ 
1987 ;62 :693 –5 . 10.1097/00001888-198708000-00015 
3302261 
56 
Fincher RE , Abdulla AM , Sridharan MR , et al 
Computer-assisted learning compared with weekly seminars for teaching fundamental electrocardiography to junior medical students . South Med J 
1988 ;81 :1291 –4 . 10.1097/00007611-198810000-00020 
3051432 
57 
Patuwo T , Wagner G , Ajijola O  
Comparison of teaching basic electrocardiographic concepts with and without ECGSIM, an interactive program for electrocardiography : Computer cardiology . IEEE , 2007 .
58 
Davies A , Macleod R , Bennett-Britton I , et al 
E-learning and near-peer teaching in electrocardiogram education: a randomised trial . Clin Teach 
2016 ;13 :227 –30 . 10.1111/tct.12421 
26135499 
59 
Fent G , Gosai J , Purva M  
A randomized control trial comparing use of a novel electrocardiogram simulator with traditional teaching in the acquisition of electrocardiogram interpretation skill . J Electrocardiol 
2016 ;49 :112 –6 . 10.1016/j.jelectrocard.2015.11.005 
26709105 
60 
Owen SG , Hall R , Anderson J , et al 
Programmed learning in medical education. An experimental comparison of programmed instruction by teaching machine with conventional lecturing in the teaching of electrocardiography to final year medical students . Postgrad Med J 
1965 ;41 :201 –5 . 10.1136/pgmj.41.474.201 
4951206 
61 
Montassier E , Hardouin J-B , Segard J , et al 
E-Learning versus lecture-based courses in ECG interpretation for undergraduate medical students: a randomized noninferiority study . Eur J Emerg Med 
2016 ;23 :108 –13 . 10.1097/MEJ.0000000000000215 
25386694 
62 
Barthelemy FX , Segard J , Fradin P , et al 
ECG interpretation in emergency department residents: an update and e-learning as a resource to improve skills . Eur J Emerg Med 
2017 ;24 :149 –56 . 10.1097/MEJ.0000000000000312 
26287803 
63 
Rui Z , Lian-Rui X , Rong-Zheng Y , et al 
Friend or foe? Flipped classroom for undergraduate electrocardiogram learning: a randomized controlled study . BMC Med Educ 
2017 ;17 :53
10.1186/s12909-017-0881-8 
28270204 
64 
Akbarzadeh F , Arbat BK , Alizadeh A , et al 
The efficacy of web-based multimedia education of normal electrocardiogram in junior and senior medical students . Res Develop Med Educ 
2012 ;1 :77 –9 .
65 
Sonali N , Limaye RP , Madhushree K , et al 
Assessing impact of computer assisted learning (CAL) on cognitive perception – a study in medical college students . Res J Pharm Biol Chem Sci 
2014 ;5 :600 –4 .
66 
Nilsson M , Bolinder G , Held C , et al 
Evaluation of a web-based ECG-interpretation programme for undergraduate medical students . BMC Med Educ 
2008 ;8 :25
10.1186/1472-6920-8-25 
18430256 
67 
Gleason BL , Peeters MJ , Resman-Targoff BH , et al 
An active-learning strategies primer for achieving ability-based educational outcomes . Am J Pharm Educ 
2011 ;75 :186
10.5688/ajpe759186 
22171114 
68 
Kolb D  
Experiential learning . Englewood cliffs : Prentice Hall , 1984 .
69 
Choules AP  
The use of elearning in medical education: a review of the current situation . Postgrad Med J 
2007 ;83 :212 –6 . 10.1136/pgmj.2006.054189 
17403945 
70 
Liu Q , Peng W , Zhang F , et al 
The effectiveness of blended learning in health professions: systematic review and meta-analysis . J Med Internet Res 
2016 ;18 :e2
10.2196/jmir.4807 
26729058 
71 
Rowe M , Frantz J , Bozalek V  
The role of blended learning in the clinical education of healthcare students: a systematic review . Med Teach 
2012 ;34 :e216 –21 . 10.3109/0142159X.2012.642831 
22455712 
72 
McCutcheon K , Lohan M , Traynor M , et al 
A systematic review evaluating the impact of online or blended learning vs. face-to-face learning of clinical skills in undergraduate nurse education . J Adv Nurs 
2015 ;71 :255 –70 . 10.1111/jan.12509 
25134985 
73 
Chen KS , Monrouxe L , YH L , et al 
Academic outcomes of flipped classroom learning: a meta-analysis . Med Educ 
2018 .
74 
Monteiro S , Melvin L , Manolakos J , et al 
Evaluating the effect of instruction and practice schedule on the acquisition of ECG interpretation skills . Perspect Med Educ 
2017 ;6 :237 –45 . 10.1007/s40037-017-0365-x 
28744821 
75 
Cook DA  
Web-based learning: pros, cons and controversies . Clin Med 
2007 ;7 :37 –42 . 10.7861/clinmedicine.7-1-37 

76 
Healy DG , Fleming FJ , Gilhooley D , et al 
Electronic learning can facilitate student performance in undergraduate surgical education: a prospective observational study . BMC Med Educ 
2005 ;5 :23
10.1186/1472-6920-5-23 
15987526 
77 
Ellaway R , Masters K  
AMEE guide 32: e-learning in medical education Part 1: learning, teaching and assessment . Med Teach 
2008 ;30 :455 –73 . 10.1080/01421590802108331 
18576185 
78 
Milner RE  
Learner differences and learning outcomes in an introductory biochemistry class: attitude toward images, visual cognitive skills, and learning approach . Biochem Mol Biol Educ 
2014 ;42 :285 –98 . 10.1002/bmb.20658 
23382135 
79 
Mayer RE  
Applying the science of learning to medical education . Med Educ 
2010 ;44 :543 –9 . 10.1111/j.1365-2923.2010.03624.x 
20604850 
80 
Grum CM , Gruppen LD , Woolliscroft JO  
The influence of vignettes on EKG interpretation by third-year students . Acad Med 
1993 ;68 :S61 –3 . 10.1097/00001888-199310000-00047 

81 
Hatala R , Norman GR , Brooks LR  
Impact of a clinical scenario on accuracy of electrocardiogram interpretation . J Gen Intern Med 
1999 ;14 :126 –9 . 10.1046/j.1525-1497.1999.00298.x 
10051784 
82 
Kandasamy T , Fung K  
Interactive Internet-based cases for undergraduate otolaryngology education . Otolaryngology–Head and Neck Surgery 
2009 ;140 :398 –402 . 10.1016/j.otohns.2008.11.033 
19248951 
83 
Cook DA , Levinson AJ , Garside S , et al 
Instructional design variations in internet-based learning for health professions education: a systematic review and meta-analysis . Acad Med 
2010 ;85 :909 –22 . 10.1097/ACM.0b013e3181d6c319 
20520049 
84 
Issenberg SB , McGaghie WC , Petrusa ER , et al 
Features and uses of high-fidelity medical simulations that lead to effective learning: a BEME systematic review . Med Teach 
2005 ;27 :10 –28 . 10.1080/01421590500046924 
16147767 
85 
Moulaert V , Verwijnen MGM , Rikers R , et al 
The effects of deliberate practice in undergraduate medical education . Med Educ 
2004 ;38 :1044 –52 . 10.1111/j.1365-2929.2004.01954.x 
15461649 
86 
McGaghie WC , Issenberg SB , Cohen ER , et al 
Medical education featuring mastery learning with deliberate practice can lead to better health for individuals and populations . Acad Med 
2011 ;86 :e8 –9 . 10.1097/ACM.0b013e3182308d37 
22030671 
87 
Yardley S , Dornan T  
Kirkpatrick’s levels and education ‘evidence’ . Med Educ 
2012 ;46 :97 –106 . 10.1111/j.1365-2923.2011.04076.x 
22150201 
88 
Steinert Y , Mann K , Centeno A , et al 
A systematic review of faculty development initiatives designed to improve teaching effectiveness in medical education: BEME guide No. 8 . Med Teach 
2006 ;28 :497 –526 . 10.1080/01421590600902976 
17074699 
89 
Davis D , O’Brien MA , Freemantle N , et al 
Impact of formal continuing medical education: do conferences, workshops, rounds, and other traditional continuing education activities change physician behavior or health care outcomes? 
JAMA 
1999 ;282 :867 –74 . 10.1001/jama.282.9.867 
10478694 
90 
Sampath J , Dietze DT , Toth PP , et al 
Are continuing medical education activities effective in improving the competence and performance of clinicians? Evidence from activities for primary care clinicians who manage patients with acute coronary syndromes . Crit Pathw Cardiol 
2012 ;11 :1 –9 . 10.1097/HPC.0b013e318242e6cd 
22337214 
91 
Clausen C , Cummins K , Dionne K  
Educational interventions to enhance competencies for interprofessional collaboration among nurse and physician managers: an integrative review . J Interprof Care 
2017 ;31 :685 –95 . 10.1080/13561820.2017.1347153 
28862885 
92 
Grol R , Grimshaw J  
From best evidence to best practice: effective implementation of change in patients' care . Lancet 
2003 ;362 :1225 –30 . 10.1016/S0140-6736(03)14546-1 
14568747 
93 
Zendejas B , Brydges R , Wang AT , et al 
Patient outcomes in simulation-based medical education: a systematic review . J Gen Intern Med 
2013 ;28 :1078 –89 . 10.1007/s11606-012-2264-5 
23595919 
94 
Cheng A , Nadkarni VM , Mancini MB , et al 
Resuscitation education science: educational strategies to improve outcomes from cardiac arrest: a scientific statement from the American Heart Association . Circulation 
2018 ;138 :e82 –122 . 10.1161/CIR.0000000000000583 
29930020 
95 
Bisgaard CH , Rubak SLM , Rodt SA , et al 
The effects of graduate competency-based education and mastery learning on patient care and return on investment: a narrative review of basic anesthetic procedures . BMC Med Educ 
2018 ;18 :154
10.1186/s12909-018-1262-7 
29954376 
96 
Ertmer PA , Newby TJ  
Behaviorism, cognitivism, constructivism: comparing critical features from an instructional design perspective . Perform Improv Q 
1993 ;6 :50 –72 . 10.1111/j.1937-8327.1993.tb00605.x 

97 
Lau KHV  
Computer-based teaching module design: principles derived from learning theories . Med Educ 
2014 ;48 :247 –54 . 10.1111/medu.12357 
24528459 
98 
DeCaporale-Ryan LN , Dadiz R , Peyre SE  
Simulation-based learning: from theory to practice . Fam Syst Health 
2016 ;34 :159 –62 . 10.1037/fsh0000203 
27270248 
99 
Lau Y , Nyoe RSS , Wong SN , et al 
Effectiveness of digital resuscitation training in improving knowledge and skills: a systematic review and meta-analysis of randomised controlled trials . Resuscitation 
2018 ;131 :14 –23 . 10.1016/j.resuscitation.2018.07.033 
30071263 
100 
Moffett J , Berezowski J , Spencer D , et al 
An investigation into the factors that encourage learner participation in a large group medical classroom . Adv Med Educ Pract 
2014 ;5 :65 –71 . 10.2147/AMEP.S55323 
24648783 
101 
Eaton M  
The flipped classroom . Clin Teach 
2017 ;14 :301 –2 . 10.1111/tct.12685 
28703501 
102 
Cook DA , Hamstra SJ , Brydges R , et al 
Comparative effectiveness of instructional design features in simulation-based education: systematic review and meta-analysis . Med Teach 
2013 ;35 :e867 –98 . 10.3109/0142159X.2012.714886 
22938677 
103 
Keifenheim KE , Teufel M , Ip J , et al 
Teaching history taking to medical students: a systematic review . BMC Med Educ 
2015 ;15 :159
10.1186/s12909-015-0443-x 
26415941 
104 
Rees EL , Quinn PJ , Davies B , et al 
How does peer teaching compare to faculty teaching? A systematic review and meta-analysis . Med Teach 
2016 ;38 :829 –37 . 10.3109/0142159X.2015.1112888 
26613398 
105 
Cook DA , Hatala R , Brydges R , et al 
Technology-enhanced simulation for health professions education: a systematic review and meta-analysis . JAMA 
2011 ;306 :978 –88 . 10.1001/jama.2011.1234 
21900138 
106 
Torre DM , Daley BJ , Sebastian JL , et al 
Overview of current learning theories for medical educators . Am J Med 
2006 ;119 :903 –7 . 10.1016/j.amjmed.2006.06.037 
17000227 
107 
Kaufman DM  
Applying educational theory in practice . BMJ 
2003 ;326 :213 –6 . 10.1136/bmj.326.7382.213 
12543841 
108 
Ryan RM , Deci EL , Intrinsic DEL  
Intrinsic and extrinsic motivations: classic definitions and new directions . Contemp Educ Psychol 
2000 ;25 :54 –67 . 10.1006/ceps.1999.1020 
10620381 
109 
Young JQ , Van Merrienboer J , Durning S , et al 
Cognitive load theory: implications for medical education: AMEE guide No. 86 . Med Teach 
2014 ;36 :371 –84 . 10.3109/0142159X.2014.889290 
24593808 
110 
Neufeld VR , Barrows HS  
The ‘McMaster Philosophy’: an approach to medical education . J Med Educ 
1974 ;49 :1040 –50 .4444006 
111 
Warschauer M  
Computer-mediated collaborative learning: theory and practice . Mod Lang J 
1997 ;81 :470 –81 . 10.1111/j.1540-4781.1997.tb05514.x 

112 
Ruiz JG , Mintzer MJ , Leipzig RM  
The impact of e-learning in medical education . Acad Med 
2006 ;81 :207 –12 . 10.1097/00001888-200603000-00002 
16501260 
113 
Hatala R , Norman GR , Brooks LR  
Influence of a single example on subsequent electrocardiogram interpretation . Teach Learn Med 
1999 ;11 :110 –7 . 10.1207/S15328015TL110210 

114 
Bergman EM , Sieben JM , Smailbegovic I , et al 
Constructive, collaborative, contextual, and self-directed learning in surface anatomy education . Anat Sci Educ 
2013 ;6 :114 –24 . 10.1002/ase.1306 
22899567 
115 
Kadish AH , Buxton AE , Kennedy HL , et al 
ACC/AHA clinical competence statement on electrocardiography and ambulatory electrocardiography: a report of the ACC/AHA/ACP-ASIM Task force on clinical competence (ACC/AHA Committee to develop a clinical competence statement on electrocardiography and ambulatory electrocardiography) endorsed by the International Society for Holter and Noninvasive Electrocardiology . Circulation 
2001 ;104 :3169 –78 .11748119 
116 
Cook DA , Levinson AJ , Garside S , et al 
Internet-based learning in the health professions: a meta-analysis . JAMA 
2008 ;300 :1181 –96 . 10.1001/jama.300.10.1181 
18780847



==== Front
BMJ OpenBMJ OpenbmjopenbmjopenBMJ Open2044-6055BMJ Publishing Group BMA House, Tavistock Square, London, WC1H 9JR bmjopen-2016-01126010.1136/bmjopen-2016-011260General practice / Family practiceProtocol15061696172217041730Protocol for a process evaluation of a cluster randomised controlled trial to improve management of multimorbidity in general practice: the 3D study http://orcid.org/0000-0002-1256-1820Mann Cindy 1Shaw Alison 1Guthrie Bruce 2Wye Lesley 1http://orcid.org/0000-0003-4948-5670Man Mei-See 1http://orcid.org/0000-0003-0782-3117Hollinghurst Sandra 1Brookes Sara 3Bower Peter 4Mercer Stewart 5http://orcid.org/0000-0002-4378-3960Salisbury Chris 11 Centre for Academic Primary Care, University of Bristol, Bristol, UK2 Division of Population Health Sciences, University of Dundee, Dundee, UK3 School of Social and Community Medicine, University of Bristol, Bristol, UK4 Centre for Primary Care, University of Manchester, Manchester, UK5 Department of General Practice and Primary Care, University of Glasgow, Glasgow, UKCorrespondence to  Cindy Mann; Cindy.mann@bristol.ac.uk2016 4 5 2016 6 5 e01126022 1 2016 9 3 2016 12 4 2016 Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://www.bmj.com/company/products-services/rights-and-licensing/2016This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/Introduction
As an increasing number of people are living with more than 1 long-term condition, identifying effective interventions for the management of multimorbidity in primary care has become a matter of urgency. Interventions are challenging to evaluate due to intervention complexity and the need for adaptability to different contexts. A process evaluation can provide extra information necessary for interpreting trial results and making decisions about whether the intervention is likely to be successful in a wider context. The 3D (dimensions of health, drugs and depression) study will recruit 32 UK general practices to a cluster randomised controlled trial to evaluate effectiveness of a patient-centred intervention. Practices will be randomised to intervention or usual care.

Methods and analysis
The aim of the process evaluation is to understand how and why the intervention was effective or ineffective and the effect of context. As part of the intervention, quantitative data will be collected to provide implementation feedback to all intervention practices and will contribute to evaluation of implementation fidelity, alongside case study data. Data will be collected at the beginning and end of the trial to characterise each practice and how it provides care to patients with multimorbidity. Mixed methods will be used to collect qualitative data from 4 case study practices, purposively sampled from among intervention practices. Qualitative data will be analysed using techniques of constant comparison to develop codes integrated within a flexible framework of themes. Quantitative and qualitative data will be integrated to describe case study sites and develop possible explanations for implementation variation. Analysis will take place prior to knowing trial outcomes.

Ethics and dissemination
Study approved by South West (Frenchay) National Health Service (NHS) Research Ethics Committee (14/SW/0011). Findings will be disseminated via a final report, peer-reviewed publications and practical guidance to healthcare professionals, commissioners and policymakers.

Trial registration number
ISRCTN06180958.

Process evaluationMultimorbidityPatient-centred careProtocolFamily PracticeHealth Services and Delivery Research Programmehttp://dx.doi.org/10.13039/50110000200112/130/15
==== Body
Strengths and limitations of this study
A context-sensitive, preplanned process evaluation of a highly complex health service intervention addressing an important healthcare challenge.

The main limitation is the number of case studies and that a usual care case study is not included. However, we have planned a comprehensive survey of practice characteristics and usual care in all practices at the beginning and end of the trial to evaluate the influence of context.

A strength of this evaluation is that it has been subject to careful prioritisation based on a detailed description of the intervention and of the trial processes (figures 1 and 2).

Key decisions about focus have been made prospectively, but by committing to only four case studies initially, we have retained flexibility to respond to emerging issues and/or to investigate one usual care practice.

Depth of evaluation in the case studies has been balanced with breadth by collection of quantitative implementation data from all intervention practices to contribute to assessment of fidelity of adoption, delivery and maintenance.

Introduction
Multimorbidity presents considerable challenges for the organisation and delivery of healthcare because of the increased complexity of managing several coexisting conditions and the increased demand on time and resources.1
2 It is now a common situation in primary care1 and the need to find efficient and effective approaches to this challenge is becoming more urgent as multimorbidity becomes more prevalent.3 However, there is a current lack of evidence about which interventions may be effective.4 Successful interventions are likely to be complex and pragmatic in order to be transferable to different patient situations and different healthcare contexts and will need to be tested in large-scale multisite trials. Evaluation is therefore challenging. This paper presents the protocol for the process evaluation of a trial of one such intervention.

The 3D study
The trial that is the subject of this process evaluation is a multisite cluster randomised controlled trial of an intervention to improve the management of people with multimorbidity in general practice—the 3D (dimensions of health, drugs and depression) study. The 3D study protocol is published in full,5 so this paper will only briefly describe the 3D intervention to give context to the process evaluation design.

The 3D intervention is driven by the concept of patient-centred care, developed from previously published definitions6
7 and stated in the trial protocol as:
A focus on the patient's individual disease and illness experience: exploring the main reasons for their visit, their concerns and need for information.

A biopsychosocial perspective: seeking an integrated understanding of the whole person, including their emotional needs and life issues.

Finding common ground on what the problem is and mutually agreeing management plans.

Enhancing the continuing relationship between the patient and doctor (the therapeutic alliance).



The intervention aims to address known problems for people with multimorbidity. These include high illness burden, high treatment burden, poorly coordinated care, low quality of life, increased risk of depression and polypharmacy.8–10 The intervention consists of strategies to address these problems (figure 1) implemented at general practice level and individual clinician level, which include improved continuity, coordination and integration of care combined with a more holistic approach to achieve patient-centred delivery of care. Each patient will be allocated a specific general practitioner (GP), and nurse if appropriate, who will review all of the patient's long-term conditions (LTCs) in a single, longer, holistic, two-part review (3D review), repeated six monthly. The review is intended to balance the patient's agenda and quality of life issues with disease control and will replace separate disease-focused reviews. Each review addresses the 3Ds of dimensions of health, drugs and depression.

Figure 1 3D logic model including theoretical mechanisms of action. 3D, dimensions of health, drugs and depression; GP, general practitioner; LTC, long-term condition; QOL, quality of life.

General practices (GP practices) in two areas of England and in one part of Scotland will be recruited. The research team will train those randomised to deliver the intervention, and will discuss with them how they will fit the intervention to their own context in a way that maintains fidelity of function.11 The clinical staff (GPs and nurses) will be trained to implement certain strategies that fall within a patient-centred approach when reviewing those patients and to use a new consultation template that automatically adapts to the individual's conditions and supports the intervention. Reception staff in the GP practices will receive training to arrange the reviews and other appointments of the identified patients with their usual nurse or GP in extended time slots.

An external pilot took place prior to the main trial and influenced the final trial design. It was subject to a formative process evaluation, the aim of which was to support optimisation of the intervention by identifying processes that could be improved and factors that might threaten implementation of the intervention. It also provided the opportunity to test the process evaluation design for the main trial. Findings from this stage that resulted in changes to the intervention design are reported in the linked paper by Man et al.5

Process evaluation
A process evaluation accompanying a randomised controlled trial aids evaluation of the effectiveness of an intervention by investigating how it was implemented, the mechanisms by which it achieved its effect and how the intervention interacted with the context in which it was implemented.12–15 Researchers conducting process evaluations typically investigate the extent to which the intervention is reaching the participants for whom it is intended (reach), whether all the intervention components are being delivered as intended by the research team (delivery and fidelity), participants’ experiences of receiving an intervention (response), the extent to which an intervention is maintained over time (maintenance), and contextual factors that may influence maintenance and the precise form of the intervention delivered.12
16–18 Process evaluations can help researchers to distinguish between intervention failure (where the intervention concept is flawed), and implementation failure (where the intervention is poorly delivered).13
19 Theory may be used to focus the evaluation and provide additional insight into causal mechanisms affecting outcomes.14
20
21

Arguably, process evaluations are particularly necessary in multisite, pragmatic trials, where there is likely to be variation in the way the ‘same’ intervention is implemented.13 In cluster trials, outcomes are often measured at the individual level but the intervention is applied by the research team to the cluster, which implements it and applies it at the individual level. There may therefore be processes operating at both cluster and individual level, which are candidates for evaluation.22 Evaluation of processes within control clusters may also be important, for example, to understand the ‘usual care’ comparator.22

Process evaluations may employ mixed methods, both quantitative and qualitative, and apply these at different stages of the trial depending on the purpose of the evaluation.16–18
21 They may be used to optimise the design of the intervention and/or to provide insight into outcomes following its implementation.13
14
22
23

Until recently, there has been a lack of guidance for the design of process evaluations of complex interventions of healthcare trials and protocols are not commonly published. However, the recently published Medical Research Council (MRC) guidance on the process evaluation of complex interventions provides a comprehensive set of recommendations.12 Among these are recommendations that process evaluation researchers should prospectively state the aim of the evaluation and the research objectives, identify the processes they plan to study, the methods they will use and how they plan to integrate process and outcome data when analysing the results. This paper aims to fulfil those recommendations.

Process evaluation methods
Process evaluation design considerations
Variation in implementation of the 3D intervention is likely, due to multiple intervention components and diverse contexts and participants, both clinicians and patients. Practices’ differing characteristics influence their care arrangements for patients with LTCs and will affect the roles and expectations of clinical and administrative staff as well as patients' baseline experience and expectations of care. These differences, together with diverse local healthcare environments, policies and priorities may affect the ease with which the intervention integrates with existing practice and the extent of the change from usual practice. In addition, during the period of the trial, policy initiatives around health and social care integration and avoiding emergency hospital admission are likely to increase and other new incentivised services addressing the needs of those with LTCs may be introduced. These may differ across areas and will at least partly target the trial patient population, potentially affecting both the intervention and usual care. All of these factors may impact outcomes and constitute the context to be evaluated.

Contextual differences mean that assessment of fidelity must allow for local adaptation. Controlling the form of the intervention too tightly may undermine, rather than enhance, its effectiveness11 and local adaptation may actually result in more successful implementation of the principles of the intervention. The intervention description has therefore been framed in terms of strategies and principles, with additional detail where this is considered essential to implementation (figure 1). This will form the basis for evaluation—fidelity of function, rather than fidelity of form.11 Modifications made to the intervention to facilitate implementation within the local context can be assessed as to whether they are consistent with the definition of the intervention and fulfil fidelity criteria.24 A thorough record of varying contexts and corresponding adaptations will facilitate replication in other settings.24

The design of the main trial process evaluation was informed by the external pilot and is primarily based on a recently published framework for process evaluation of cluster randomised controlled trials.22 The framework, which describes the various trial stages as potential targets for evaluation, has been used to guide selection of the most relevant targets in this case. The intervention diagram (figure 1) serves also as a logic model for identifying assumed mechanisms of action, as recommended by the recently published MRC guidance on process evaluation of complex interventions.12 The mechanisms of action provide the focus of the process evaluation within the selected stages. Many of these can be grouped under the concept of patient-centred care but, in common with many complex interventions, there is no single intervention theory that explains them all.12 Normalisation process theory (NPT)25 is relevant to the implementation and maintenance of the intervention and has helped to inform the process evaluation design, for example, in considering the effect of practice context and existing organisation of care on how the intervention may integrate with usual practice.

To make best use of limited evaluation resources, it is necessary to focus on factors that may have the greatest impact on implementation and/or on areas that are considered critical to the success of the intervention and which may be vulnerable to poor implementation.12
22 Since the external pilot confirmed that there are significant differences in practice size and organisation and that these drive variation in how the intervention is adopted, delivered and maintained, context is a key focus. Variation in adoption, delivery and maintenance as well as patients' responses to the intervention, affecting both reach and fidelity, are likely to be important factors in outcome differences. Therefore, these trial stages, in addition to context, will form the scope of the evaluation. The concept of patient-centred care will inform the evaluation since this is the core concept underlying the intervention. The dimensions of the evaluation for the main trial are illustrated in figure 2 and are as follows:
Context of each practice, including the practice's structure and organisation of care and its local context;

Practices’ adoption of the intervention, including necessary organisational changes;

Practice health professionals’ delivery of the intervention to patients;

Response of patients to the intervention;

Maintenance and unanticipated effects, including impact of expected incentives and other measures intended to support implementation and maintenance.



Figure 2 Conceptual diagram showing focus of 3D process evaluation. 3D, dimensions of health, drugs and depression; GP, general practitioner.

Recruitment of practices and patients will be evaluated as part of the main trial. Although research team activity in training the practices is arguably an important part of the intervention, this was evaluated and optimised during the external pilot and it is not included in the scope of the main trial evaluation.

Aims and objectives
The overall aim of the process evaluation is to better understand how and why the intervention was effective or ineffective, and to identify contextually relevant strategies for successful implementation as well as practical difficulties in adoption, delivery and maintenance to inform wider implementation.

Objectives are:
To establish practice and local health area context in all intervention and usual care practices at the beginning and end of the trial period to:
Identify differences in usual care and how this might have affected adoption, delivery and maintenance;

Identify changes in the care of patients with multimorbidity occurring in intervention and usual care practices during the trial period which might affect outcomes.



To explore how and why organisational aspects of the 3D intervention were implemented (or not).

To explore how health professionals in case study practices delivered the intervention to patients, whether all components were included, how and why it varied, and to what extent they changed their practice to make it more patient centred.

To explore how patients responded to the 3D intervention and to what extent they experienced care as patient centred.

To explore how and why practices maintained (or did not maintain) reach and delivery of the intervention.



Figure 2 illustrates the design of the process evaluation, the trial stages that have been prioritised and how the objectives relate to the stages.

Overall design
The overall design is a mixed-methods study using quantitative and some qualitative data from all practices, and observation, interview and focus group data from four purposively selected case study practices.

Data from all practices
Mixed quantitative and qualitative data will be collected from all trial practices, including those in the usual care arm, using a purpose-designed practice profile form. Practices will be profiled, including size and organisational characteristics and how they manage LTC reviews. This will facilitate assessment of practice context and effects of contextual variation. In intervention practices only, collection of quantitative data via the EMIS web electronic patient record system will contribute to the evaluation of fidelity by showing whether or not each component of the intervention was delivered in each intervention practice. Some of these data will be used as part of the intervention to provide monthly feedback to practices to support maintenance, as well as in the process evaluation. The data will provide information about continuity of care and appointments as well as clinician delivery of 3D review components and the reach of the intervention.

Case studies
Sampling and recruitment
A minimum of four intervention practices will be purposively sampled as case studies.26 The aim will be to achieve a sample that encompasses variety in intervention implementation and maintenance, using information available shortly after practices are randomised. A judgement will be made on the basis of information available from the researchers training the practices about how the practices plan to implement the intervention and any difficulties they have identified, supplemented by information about differences in size of practice, and assessed similarity of usual care at baseline to the 3D intervention. This is based on the assumptions that: (1) practices that are already organised in a way that is more consistent with 3D may adopt it more readily and (2) that larger practices may have lower continuity of care and a lower proportion of their clinicians taking part in 3D which may affect implementation, maintenance and outcomes. Data that would allow us to sample directly for variation in adoption, delivery and maintenance will not be available prospectively. However, we anticipate that the above criteria will result in sufficient heterogeneity to provide examples of relatively poor and relatively good adoption, delivery and maintenance, and will allow us to identify barriers and facilitators to implementation and to generate hypotheses about factors that may be associated with differing outcomes. Adoption includes the steps described in figure 1 under ‘Practices organisation of care’, such as allocating a usual GP, and delivery includes the components listed in figure 1 under ‘Clinicians conduct of reviews’, for example, provision of a health plan.

The practices will be sampled and enrolled into the process evaluation as case studies before or soon after they have received their training and begun implementation because not all the information on which sampling is based will be available before then. Data will be collected from that point and continue throughout the delivery of the intervention, which will allow us to observe the whole process of their participation in the trial from set-up through to completion. Although only four case study practices will be followed through the entire process, some flexibility over the number of practices investigated and the number of interviews conducted will be retained to allow for ‘responsive’ qualitative data collection in additional practices to investigate emerging issues.12 For example, a practice that has organisational challenges, such as staff shortages, or nursing skill mixes that may affect set-up or fails to adopt as expected, or one that fails to deliver an element of the intervention (see figure 1), will potentially be sampled later on. This will depend on findings that emerge from ongoing concurrent analysis. If resources allow, a usual care practice may also be recruited as a case study to provide a comparison to care provided in intervention practices and to check whether findings from case study practices are reflective of the intervention, and not simply due to evolving usual care.

Health professionals participating in 3D in the case study practices will be purposively sampled to achieve maximum diversity of role and experience, for example, inclusion of healthcare assistants as well as research nurses and practice nurses in the nurse sample. The lead GP, practice manager or other practice staff may be interviewed depending on implementation or delivery issues uncovered in the course of data collection. Patients of case study practices who have received 3D reviews will be sampled for variation taking into account age, gender, combination of health conditions and usual GP/nurse.

When practices and clinicians are approached to participate in the main trial, they will be informed that a process evaluation will be conducted and that participation in the process evaluation is optional. Additional written information will be provided to individual staff invited to participate in interviews and/or observation and recording of consultations and their informed consent secured. Patients consenting to participate in the trial will be informed that they may be invited to take part in an interview, focus group or observation of consultations for the process evaluation. If they are sampled for inclusion, they will receive detailed information and their consent will be obtained, prior to their involvement in the process evaluation.

Case study data collection
The qualitative data collected from the case study practices will provide more in-depth understanding of the context of each practice, how the practices implement, experience and maintain the intervention, and how their patients experience receiving it, for example, whether a patient-centred approach was achieved. The case studies will also shed light on whether, how and why variation occurs in delivery of each of the intervention components and how context and implementation interact. A variety of qualitative methods will be used in the case studies, including focus groups with patients, interviews with staff and patients, observation and/or recording of 3D review consultations and field notes. In the course of repeated visits to the practice, informal observation together with field notes will contribute to understanding the practice context. Interviews with reception staff and observation of reception functions will clarify how 3D appointments are being arranged.

To add to case study data into the effect of local context on implementation, broader contextual data will be obtained from interviews with healthcare commissioners in each trial site. This will enable assessment of differences between health areas and co-occurring changes in the wider healthcare environment and indicate how the intervention might be received in different healthcare environments.

Qualitative data will be collected using an encrypted digital audio-recording device. Field notes will be made at each practice visit. Audio data will be transcribed verbatim and anonymised prior to analysis.

Methods for each of the five objectives are described in tables 1–5.

Table 1 Methods for objective 1

Objective	Sample	Data collection	

To characterise usual care in all GP practices at the beginning and end of the trial period to identify variation in usual care and how this might have affected adoption and to identify changes in the care of patients with multimorbidity occurring in intervention and usual care practices during that time which might affect outcomes

	All trial practices	
Completion of practice profile form for every practice at baseline and at the end of the trial to characterise practice organisation and usual care for LTCs. Data will include list size, number of nurses and GPs, management of chronic disease review, and local healthcare commissioning initiatives to which the practice has responded. Informal interviews with the lead administrator and/or lead nurse will be conducted at the beginning and end of the intervention period in all practices to clarify practice organisational systems and whether and how they change in response to the intervention and to changing healthcare commissioning requirements

Quality and Outcomes Framework27 data from each practice will capture variation in care provision and outcomes for the included diseases

The COC measure28 will be used to assess to what extent patients in each practice receive longitudinal continuity of care

	
COC, continuity of care; GP, general practitioner; LTC, long-term condition.

Table 2 Methods for objective 2

Objective	Sample	Data collection	

To explore how and why organisational aspects of the 3D intervention were implemented (or not)

	Case study practices	Quantitative data:Using EMIS compatible software the trial team will collect information about
Number of recruited patients flagged on EMIS and given a 3D card.

When each practice begins to deliver 3D reviews

The practice profile form will provide additional information about the number of participating clinicians and nurses and usual care at baseline.

Qualitative data:

The process evaluation researcher will attend the training of some intervention practices in each area to observe how the training is delivered, how the practice staff respond and what difficulties they anticipate.

Informal interview with the research associate working with each case study practice to obtain their impression of the practice and ease of study set-up, for example, whether they have experienced difficulty in arranging meetings or training sessions with practice staff, whether any difficulties have been identified and whether there are any staff who particularly support or oppose the intervention.

Semistructured interviews in each case study practice with the lead administrator responsible for arranging reviews, the lead nurse and the lead GP to be conducted when the practice has completed training. Questions will be asked about current care arrangements for patients with LTCs, their opinion of the training received from the research team, and the intervention and its requirements. They will also be asked how the practice has organised appointments to accommodate 3D patients and what barriers and facilitators they are aware of that may affect implementation.

Observation and informal interviews of reception staff to understand how care is being organised for participating patients and how they actually go about arranging appointments.

	
3D, dimensions of health, drugs and depression; GP, general practitioner; LTC, long-term condition.

Table 3 Methods for objective 3

Objective	Sample	Data collection	

To explore how health professionals in case study practices delivered the intervention to patients, whether all components were included, how and why it varied, and to what extent they changed their practice to make it more patient-centred

	Health professionals in case study practices	Quantitative data:
Proportion of pharmacy reviews completed

Proportion of 3D patients screened for depression

Proportion of 3D patients who receive a printed agenda to take to part 2 of the review

Proportion of 3D patients receiving a health plan and provided with a printed copy

Qualitative data:

Non-participant observation and recording of consultations to assess fidelity of delivery of the 3D intervention to patients. With consent from both patient and clinician, the researcher will video-record or observe and/or audio record up to 20 consultations conducted by GPs and by nurses with patients participating in the trial. Observation will cover the extent to which all components of the reviews are included, how the consultation template is used and responses of patients and health professionals to the reviews. Observation of consultation style and techniques will inform evaluation of patient centredness.

De-briefing following consultation observation. A sample of 2 nurses and 2 GPs from each case study practice who have consented to having a consultation observed and/or audio recorded will if possible be de-briefed afterwards to gain more insight into their management of the consultation, where possible using extracts from the consultation to prompt recall.

Semistructured interviews with a sample of nurses and GPs to obtain views of the intervention, and explore experiences of delivering the intervention to patients. At least 1 nurse and 1 GP and up to 2 others from each case study practice will be asked to consent to interviews during the course of intervention delivery to assess whether there are barriers or facilitators affecting delivery, whether roles and practice are significantly changed by the intervention, and the response of the health professionals to the intervention.

A selection of electronic patient records will be reviewed at the end of the trial to assess the content of pharmacist recommendations and whether they were acted on by the GP, and to assess how the agenda compiled by the nurse was reflected in the GP's subsequent consultation and health plan.

	
3D, dimensions of health, drugs and depression; GP, general practitioner.

Table 4 Methods for objective 4

Objective	Sample	Data collection	

To explore how patients responded to the 3D intervention and to what extent they experienced care as patient-centred

	Patients of case study practices	Semistructured interviews/focus groups with patients to assess patients' views of care and response to the intervention.
A sample of patients will be asked to consent to a focus group to compare their experience of usual care with their experience of 3D care and to comment on organisation of care and degree of support in management of their LTC. Focus groups will be used because this is likely to generate richer data through discussion of diverse experiences.

Up to 4 patients from each case study practice will be asked to consent to interviews after the intervention has been implemented to assess their response to the intervention and opinion of its impact. Individual interviews rather than focus groups will be used for this because patients will be asked about their individual consultations and condition-specific care. Some of these patients will be those who have consented to having one of their 3D reviews recorded and/or observed and will be invited to interview soon after one of their consultations has been recorded in order to discuss the consultation, using extracts from the recording to prompt recall and facilitate discussion of the consultation. Questions to be discussed will depend on preliminary analysis, considering interaction, such as agreement or disagreement, and content, such as the patient's agenda. The questions will aim to elucidate the observed interaction between patient and clinician.

	
3D, dimensions of health, drugs and depression; LTC, long-term condition.

Table 5 Methods for objective 5

Objective	Sample	Data collection	

To explore how and why practices maintained (or did not maintain) reach and delivery of the intervention

	Case study practices	Quantitative data:
Number of reviews delivered month by month over the course of the intervention

Proportion of participating patients given a 3D review every 6 months

Proportion of 3D patients’ appointments that are with designated nurse or GP

Proportion of pharmacy reviews completed

Proportion of 3D patients screened for depression

Proportion of 3D patients receiving an agenda completed with their problems to take to part 2 of the review

Proportion of 3D patients receiving a health plan and provided with a printed copy

Number of practice champion meetings attended

Qualitative data:

Semistructured interview towards the end of the trial period with the 3D lead GP and lead administrator in each case study practice to explore how the practice accommodated 3D, what problems were encountered and what facilitated or hindered maintenance of the intervention

Semistructured interview with at least 1 nurse and GP from each case study practice who have delivered the intervention (same sample as in 3G) to explore their perceptions of how well the intervention was accommodated within the practice structures and how it affected their role and practice

Informal interview with research associate for each site. This may be undertaken at more than 1 time point to obtain their views about the implementation and maintenance of the intervention in each case study practice and any particular difficulties or facilitating factors they have identified.

	
3D, dimensions of health, drugs and depression; GP, general practitioner.

Analysis
Data about usual care from all practices
Quantitative and qualitative data about usual care in all trial practices will be used to assess similarity of care at baseline to the intervention and to assess whether this changes over the course of the trial. A baseline description of the practice and of its usual care for patients with multimorbidity will allow comparison of care across practices and across areas. By repeating this at the end of the trial, it will also allow us to assess whether usual care has changed over the course of the trial, and feed into interpretation of results by facilitating comparison of care provided by intervention and usual care practices. If there is a clear trend towards initiatives that are very similar to 3D, any improvements in care resulting from 3D may be matched by those that occur as a result of ‘secular trends’.29 It is also expected that the various components of the intervention may not be uniformly implemented across practices, in part due to differences in context, for example, nurse roles, baseline arrangements for LTC care and whether the practice has their own pharmacist, and that this may be reflected in differences in outcomes. Therefore, variation in outcomes by practice will be compared with variation in practice characteristics to generate hypotheses about any associations observed.

Quantitative data from all intervention practices
The quantitative data collected from all intervention practices will be subject to descriptive statistical analysis to provide information about the differential implementation rates of the intervention components. This will be related to trial outcomes and will facilitate comparison of case study practices with all intervention practices regarding implementation fidelity.

Case study data
The qualitative data will be analysed in parallel with ongoing data collection, so that exploration of emerging issues can be incorporated into future data collection and further sampling of practices or individuals can take place subject to resource availability. NVivo V.10 software (QSR International) will be used to facilitate development of a coding matrix following framework principles,30 with built in flexibility to allow identification of anticipated and emergent themes. A flexible framework analysis is an appropriate method to use, in addition to detailed case study descriptions, since we are interested in specific problems to do with multimorbidity, specific intervention components and implementation issues that may run across practices, while also being concerned to capture new unexpected issues that arise during the course of the process evaluation. The field notes from training observation and practice visits will help to generate rich descriptions of the individual case study sites while the consultation observations will give detailed insight into the conduct of reviews. Evaluation of the patient centredness of the interactions will be based on an analysis of the interactions, informed by a conversation analytic approach.31 The transcripts of these will be coded alongside transcripts from the interviews and focus groups to provide different perspectives on the implementation of the intervention and contribute to fidelity assessment along with the quantitative data from all intervention practices. Detailed understanding of the context of the case study sites, for example, availability of nurses with appropriate skills, will contribute to understanding how different contexts may influence intervention implementation and to what extent findings can be transferred between sites. Techniques of constant comparison32 will be used to generate initial codes that will be built into higher level categories and themes, both within and across the case studies. Themes relating to the key components of the intervention and how they were implemented, maintained and received will help to interpret trial results and generate hypotheses about factors influencing effectiveness. In particular, we will examine the data for insights into whether patient-centred care has been delivered, experienced and maintained, as this is the concept underpinning the intervention and a main focus of the evaluation. Emerging themes and the relationship of the data to the conceptual literature underpinning the intervention and relevant theories, such as NPT,25 will be discussed and refined at team meetings throughout the research. Analysis will be strengthened by the involvement of more than one person in the analysis, including a member of the patient public involvement group, to check trustworthiness and credibility of interpretation of the qualitative data. This group will also provide the patient perspective on indicators of patient-centred behaviour to inform analysis of interactions in the consultation recordings.

Integration of the qualitative and quantitative case study data regarding implementation of different components of the intervention will allow detailed evaluation of the quality of intervention implementation in each case study site. For example, quantitative data relating to the number and type of patient problems identified for the agenda and included in the health plan can be integrated with observational data about how clinicians addressed agenda setting and health planning. The additional integration of interview data about patients’ and clinicians’ experiences of reviews will provide in-depth insight into those processes.

Integrating results of analysis
The process evaluation data will be analysed before knowing the trial results and the main trial will be analysed independently of the process evaluation findings. Once both analyses are complete, combined analysis of qualitative and quantitative data across the cases may help to develop explanatory hypotheses about why the intervention appeared to be implemented more successfully in one site than another and some components were implemented whereas others were not. This may lead us to identify factors which are plausibly and/or consistently related to successful or unsuccessful delivery of the components of the intervention and changes to patients’ experience of care.13
26 Analysis of the differential implementation of various components may also help to elucidate causal mechanisms and suggest which components of the intervention were more effective and how and why. Following statistical analysis of trial outcomes, the qualitative data may be re-examined in the light of the trial results to help explain them. If appropriate, the trial statistician may carry out additional analysis to test hypotheses generated from integration of the process evaluation data with the trial outcomes.

The final stage of analysis will be to draw together the findings from the broader quantitative analysis and the in-depth case studies to create an understanding of why the intervention did (or did not) work in all or some contexts, and identify implications for longer term implementation if appropriate.

Ethics and dissemination
The design of this process evaluation is covered within the ethics application and overall protocol of the 3D study (protocol v6.0 05-01-16). A favourable ethical opinion of the 3D study was given by the Southwest (Frenchay) NHS Research Ethics Committee: ref 14/SW/0011 on 20 March 2014.

Findings will be disseminated via peer-reviewed journals, conferences and seminars with health services commissioners and other interested stakeholders. Social media and newsletters will be used to disseminate headline outcomes. Reports will be provided to bodies with influence in primary care provision such as the Royal College of General Practitioners and the National Health Service (NHS) England, as well as to the funding body and participants.

Conclusion
This paper reports the design and methods for the planned mixed-methods process evaluation of the 3D trial. The process evaluation protocol and results will contribute to the developing understanding and overall body of work on the value of process evaluation in complex health service delivery and clinical trials. The process evaluation protocol conforms to recommendations intended to facilitate standardisation of process evaluation design and reporting12
16
22 in order that synthesis of results of similar trials may become possible in future.

Twitter: Follow @CAPCBristol

Contributors: All authors except LW contributed to the conception and design of the 3D study. CM, AS, BG, LW and CS developed the detail of the process evaluation protocol. CM drafted the manuscript and all authors reviewed it critically for intellectual content and approved the final version submitted for publication.

Funding: This project was funded by the National Institute for Health Research Health Services and Delivery Research Programme (project number 12/130/15).

Disclaimer: The views and opinions expressed therein are those of the authors and do not necessarily reflect those of the HS&DR Programme, NIHR, NHS or the Department of Health.

Competing interests: None declared.

Ethics approval: South West (Frenchay) NHS Research Ethics Committee (ethics approval number 14/SW/0011).

Provenance and peer review: Not commissioned; externally peer reviewed.
==== Refs
References
1 Salisbury C , Johnson L , Purdy S  
Epidemiology and impact of multimorbidity in primary care: a retrospective cohort study . Br J Gen Pract 
2011 ;61 :e12 –21 . doi:10.3399/bjgp11X54892921401985 
2 Smith SM , O'Kelly S , O'Dowd T  
GPs’ and pharmacists’ experiences of managing multimorbidity: a ‘Pandora's box ’. Br J Gen Pract 
2010 ;60 :285 –94 . doi:10.3399/bjgp10X51475620594430 
3 Pefoyo AJ , Bronskill SE , Gruneir A  
The increasing burden and complexity of multimorbidity . BMC Public Health 
2015 ;15 :415 
doi:10.1186/s12889-015-1733-225903064 
4 Smith SM , Soubhi H , Fortin M  
Managing patients with multimorbidity: systematic review of interventions in primary care and community settings . BMJ 
2012 ;345 :e5205 
doi:10.1136/bmj.e520522945950 
5 Man M-S , Chaplin K , Mann C  
Improving the management of multimorbidity in general practice: protocol of a cluster randomised controlled trial (The 3D Study) . BMJ Open 
2016 ;6 :e011261 .
6 Stewart M  
Towards a global definition of patient centred care . BMJ 
2001 ;322 :444 –5 . doi:10.1136/bmj.322.7284.44411222407 
7 Mead N , Bower P  
Patient-centredness: a conceptual framework and review of the empirical literature . Soc Sci Med 
2000 ;51 :1087 –110 . doi:10.1016/S0277-9536(00)00098-811005395 
8 Fortin M , Bravo G , Hudon C  
Relationship between multimorbidity and health-related quality of life of patients in primary care . Qual Life Res 
2006 ;15 :83 –91 . doi:10.1007/s11136-005-8661-z16411033 
9 O'Brien R , Wyke S , Guthrie B  
An ‘endless struggle’: a qualitative study of general practitioners’ and practice nurses’ experiences of managing multimorbidity in socio-economically deprived areas of Scotland . Chronic Illn 
2011 ;7 :45 –59 . doi:10.1177/174239531038246120974642 
10 Noël PH , Frueh BC , Larme AC  
Collaborative care needs and preferences of primary care patients with multimorbidity . Health Expect 
2005 ;8 :54 –63 . doi:10.1111/j.1369-7625.2004.00312.x15713171 
11 Hawe P , Shiell A , Riley T  
Complex interventions: how “out of control” can a randomised controlled trial be? 
BMJ 
2004 ;328 :1561 –3 . doi:10.1136/bmj.328.7455.156115217878 
12 Moore GF , Audrey S , Barker M  
Process evaluation of complex interventions: Medical Research Council guidance . BMJ 
2015 ;350 :h1258 
doi:10.1136/bmj.h125825791983 
13 Oakley A , Strange V , Bonell C  
Process evaluation in randomised controlled trials of complex interventions . BMJ 
2006 ;332 :413 –16 . doi:10.1136/bmj.332.7538.41316484270 
14 Clarke DJ , Godfrey M , Hawkins R  
Implementing a training intervention to support caregivers after stroke: a process evaluation examining the initiation and embedding of programme change . Implement Sci 
2013 ;8 :96 
doi:10.1186/1748-5908-8-9623972027 
15 Craig P , Dieppe P , Macintyre S  
Developing and evaluating complex interventions: the new Medical Research Council guidance . BMJ 
2008 ;337 :a1655 
doi:10.1136/bmj.a165518824488 
16 Linnan L , Steckler A  
Process evaluation for public health interventions and research. An overview . In: Steckler A , Linnan L  , eds. Process evaluation for public health interventions and research . 1st edn 
San Francisco : Josset-Bass , 2002 :1 –23 .
17 Griffin TL , Pallan MJ , Clarke JL  
Process evaluation design in a cluster randomised controlled childhood obesity prevention trial: the WAVES study . Int J Behav Nutr Phys Act 
2014 ;11 :112 
doi:10.1186/s12966-014-0112-125212062 
18 Berendsen BA , Kremers SP , Savelberg HH  
The implementation and sustainability of a combined lifestyle intervention in primary care: mixed method process evaluation . BMC Fam Pract 
2015 ;16 :37 
doi:10.1186/s12875-015-0254-525880376 
19 Rychetnik L , Frommer M , Hawe P  
Criteria for evaluating evidence on public health interventions . J Epidemiol Community Health 
2002 ;56 :119 –27 . doi:10.1136/jech.56.2.11911812811 
20 Byng R , Norman I , Redfern S  
Exposing the key functions of a complex intervention for shared care in mental health: case study of a process evaluation . BMC Health Serv Res 
2008 ;8 :274 
doi:10.1186/1472-6963-8-27419105823 
21 Francis JJ , Eccles MP , Johnston M  
Explaining the effects of an intervention designed to promote evidence-based diabetes care: a theory-based process evaluation of a pragmatic cluster randomised controlled trial . Implement Sci 
2008 ;3 :50 
doi:10.1186/1748-5908-3-5019019242 
22 Grant A , Treweek S , Dreischulte T  
Process evaluations for cluster-randomised trials of complex interventions: a proposed framework for design and reporting . Trials 
2013 ;14 :15 
doi:10.1186/1745-6215-14-1523311722 
23 Gask L , Bower P , Lovell K  
What work has to be done to implement collaborative care for depression? Process evaluation of a trial utilizing the Normalization Process Model . Implement Sci 
2010 ;5 :15 
doi:doi:10.1186/1748-5908-5-1520181163 
24 Wells M , Williams B , Treweek S  
Intervention description is not enough: evidence from an in-depth multiple case study on the untold role and impact of context in randomised controlled trials of seven complex interventions . Trials 
2012 ;13 :95 
doi:10.1186/1745-6215-13-9522742939 
25 Murray E , Treweek S , Pope C  
Normalisation process theory: a framework for developing, evaluating and implementing complex interventions . BMC Med 
2010 ;8 :63 
doi:10.1186/1741-7015-8-6320961442 
26 Yin RK  
Case study research: design and methods . London : Sage , 2003 .
27 Health and Social Care Information Centre . Quality and Outcomes Framework. Secondary Quality and Outcomes Framework 
2015 
http://www.hscic.gov.uk/qof 
28 Bice TW , Boxerman SB  
A quantitative measure of continuity of care . Med Care 
1977 ;15 :347 –9 . doi:10.1097/00005650-197704000-00010859364 
29 Dixon-Woods M , Leslie M , Tarrant C  
Explaining Matching Michigan: an ethnographic study of a patient safety program . Implement Sci 
2013 ;8 :70 
doi:10.1186/1748-5908-8-7023786847 
30 Ritchie J , Spencer L  
Qualitative data analysis for applied policy research . In: Bryman A , Burgess RG  , eds. Analyzing qualitative data . London; New York : Routledge , 1994 :173 –94 .
31 Sidnell J  
Talk. Conversation analysis. An introduction . Wiley-Blackwell , 2010 :1 –19 .
32 Boeije H  
A purposeful approach to the constant comparative method in the analysis of qualitative interviews . Qual Quantity 
2003 ;36 :391 –409 . doi:10.1023/A:1020909529486



==== Front
BMJ OpenBMJ OpenbmjopenbmjopenBMJ Open2044-6055BMJ Publishing Group BMA House, Tavistock Square, London, WC1H 9JR bmjopen-2017-02018810.1136/bmjopen-2017-020188Emergency MedicineResearch15061691655Derivation and validation of a chief complaint shortlist for unscheduled acute and emergency care in Uganda http://orcid.org/0000-0002-9093-1831Rice Brian Travis 12Bisanzo Mark 3Maling Samuel 4Joseph Ryan 5Mowafi Hani 6Global Emergency Care Investigators Group (Study Group)
Chamberlain Stacey Dreifuss Bradley Hammerstedt Heather Langevin Mélissa Nelson Sara Periyanayagam Usha  
1 
Emergency Medicine, New York University Langone Medical Center, New York City, New York, USA

2 
Emergency Medicine, Stanford University School of Medicine, Stanford, California, USA

3 
Division of Emergency Medicine, Department of Surgery, University of Vermont, Burlington, Vermont, USA

4 
Psychiatry, Mbarara University of Science and Technology, Mbarara, Uganda

5 
Emergency Medicine, Texas A&M, Corpus Christi, Texas, USA

6 
Emergency Medicine, Yale University, New Haven, Connecticut, USA
Correspondence to  Dr Brian Travis Rice; brice@stanford.edu2018 27 6 2018 8 6 e02018824 10 2017 16 4 2018 22 5 2018 © Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use is permitted unless otherwise expressly granted.2018This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/Objectives
Derive and validate a shortlist of chief complaints to describe unscheduled acute and emergency care in Uganda.

Setting
A single, private, not-for profit hospital in rural, southwestern Uganda.

Participants
From 2009 to 2015, 26 996 patient visits produced 42 566 total chief complaints for the derivation dataset, and from 2015 to 2017, 10 068 visits produced 20 165 total chief complaints for the validation dataset.

Methods
A retrospective review of an emergency centre quality assurance database was performed. Data were abstracted, cleaned and refined using language processing in Stata to produce a longlist of chief complaints, which was collapsed via a consensus process to produce a shortlist and turned into a web-based tool. This tool was used by two local Ugandan emergency care practitioners to categorise complaints from a second longlist produced from a separate validation dataset from the same study site. Their agreement on grouping was analysed using Cohen’s kappa to determine inter-rater reliability. The chief complaints describing 80% of patient visits from automated and consensus shortlists were combined to form a candidate chief complaint shortlist.

Results
Automated data cleaning and refining recognised 95.8% of all complaints and produced a longlist of 555 chief complaints. The consensus process yielded a shortlist of 83 grouped chief complaints. The second validation dataset was reduced in Stata to a longlist of 451 complaints. Using the shortlist tool to categorise complaints produced 71.5% agreement, yielding a kappa of 0.70 showing substantial inter-rater reliability. Only one complaint did not fit into the shortlist and required a free-text amendment. The two shortlists were identical for the most common 14 complaints and combined to form a candidate list of 24 complaints that could characterise over 80% of all emergency centre chief complaints.

Conclusions
Shortlists of chief complaints can be generated to improve standardisation of data entry, facilitate research efforts and be employed for paper chart usage.

epidemiologypublic healthspecial-featureunlocked
==== Body
Strengths and limitations of this study
Largest data set of emergency care chief complaints in a low-middle income country in the literature to date.

First attempt to produce an emergency care chief complaint list with a data-driven approach.

A candidate chief complaint list appropriate for retrospective analysis and one for prospective paper chart-based data entry are both generated.

Data derived and validated in district level hospitals in Uganda. Needs further validation for broader application.

Provides a crucial step forward in standardising data collection and research capacity for emergency care in low-resource settings.

Introduction
Emergency care provided in low-income and middle-income countries (LMICs) remains poorly characterised for multiple reasons. Research to better understand emergency care needs in these settings is complicated by a frequent lack of discrete, standardised emergency care departments within health centres from which to collect such data; the conflation of emergency encounter data with either outpatient or inpatient data; and varying levels of training for those entering data.1 When captured, data on emergency care encounters are typically entered in free text without using a standard lexicon onto paper charts, making it difficult to abstract data for research, quality assurance or development efforts.

Despite the difficulty in characterising emergency care, such care is nonetheless provided daily to millions of patients in LMICs at various points of entry to the health system that we will term ‘emergency units’. Accordingly, there is an imperative to identify methods that capture emergency care data in a standard format that is useful to clinicians, researchers and policymakers seeking to improve emergency care in LMICs.

One proposed method to organise LMIC emergency care data is to develop a standardised list of chief complaints. The chief complaint serves as the entry point into diagnostic and therapeutic evaluation and is a critical step to perform a range of tasks from triage to developing differential diagnoses. Moreover, chief complaints can be captured at the moment of a patient’s presentation and provide a fundamentally different source of information about the patient (initial status, subjective experience and undifferentiated severity of illness) than do final diagnoses that may not be available at the time of the emergency care encounter.2

Regardless of how such a system is ultimately implemented, consensus has developed that establishing a list of chief complaints to adequately and accurately characterise a large percentage of emergency encounters is a needed next step in developing emergency care and research in in LMICs.3 Chief complaints have been standardised in high-income countries through the use of encoding algorithms and medical ontologies such as the Health Level 7,4 the Systematized Medical Nomenclature of Medical Disease5 and Unified Medical Language System initiatives,6 but their applicability is unclear as they have been generated from ‘top-down’ expert consensus processes that may not be relevant to LMIC settings.

To date, no comprehensive effort has been published that describes such a list of chief complaints native to an LMIC. In this study, emergency chief complaints from a low-resource setting in rural Uganda were analysed, using a data-driven approach, to generate candidate chief complaint shortlists tailored for use in retrospective data analysis and for prospective entry of emergency care data in the paper charts typically used throughout Uganda and LMICs.

Methods
The chief complaint data were collected from a quality assurance database established by Global Emergency Care (GEC), a US and Uganda-based not-for-profit organisation providing emergency care training in Uganda. The emergency unit at Karoli Lwanga ‘Nyakibale’ Hospital is set in Uganda’s rural Rukungiri district. This emergency unit sees medical and surgical emergencies—with maternal emergencies typically being triaged to a separate labour and delivery ward—and is staffed by non-physician clinicians (NPCs) trained in emergency care by GEC via a 2-year curriculum. The six-bed emergency unit sees approximately 500 patients per month with an admission rate of slightly over 60% and a 3-day mortality rate of almost 4% for admitted patients. The setting, resource availability and outcomes of this programme are described in depth in previous publications.7–9

A robust database was designed to capture demographics, details of emergency visits, disposition and 3-day outcomes for discharged and admitted patients. The derivation dataset was collected from November 2009 through the end of February 2015. The validation dataset was collected from March 2015 through February 2017. Chief complaints were written in English into a paper chart by nursing students who spoke both Ugandan English and Runyankole, the local dialect. Trained Ugandan research assistants working in the emergency unit entered this chart as free-text data into an electronic database. From 2009 to 2012, data were entered into Microsoft Excel, and from 2012 to 2017, it was entered into Microsoft Access. No limitation was put on to the number or length of chief complaints.

Derivation
Data cleaning
Cleaning and analysis of raw free text was done with Stata Statistical Software V.13 by a single unblinded researcher. Initial data cleaning was done with handwritten natural language processing rules in Stata.10 All free-text data had capitalisation and blank spaces removed to generate the initial subset. Emergency unit protocols previously encouraged research assistants to enter multiple complaints as separate entries, but many free-text entries contained compound chief complaints connected by alphanumeric character(s). Therefore, each entry was scanned for those characters and compound entries containing multiple complaints were split into distinct complaints in Stata. Usage of American and British English was standardised.

Data refining
Once these data were cleaned, they were further refined through a series of steps. First, all mention of duration was removed (stage 1). Second, description of body parts and body locations were standardised (stage 2). Third, spelling errors were corrected, and abbreviations were standardised with handwritten natural language processing rules in Stata (stage 3). All questions about abbreviations and local idioms were discussed with providers who had been working in the emergency unit at the study site for more than 5 years. Fourth, all statements of left-sidedness or right-sidedness were removed (stage 4) to produce the chief complaint ‘longlist’.

Consensus process for data grouping
Once the derivation set longlist was produced in Stata, the next steps were to group these chief complaints to produce a ‘shortlist’. This was done via a consensus process that involved two independent, unblinded, US-based, board-certified emergency medicine physician reviewers with substantial clinical experience in LMICs generally and Uganda specifically (BTR: LMIC since 2007 and Uganda since 2012; HM: LMIC since 2006 and Uganda since 2014). Each reviewer individually reviewed the longlist and either kept each complaint or grouped it to a broader category to produce two candidate shortlists that were then compared. When both reviewers agreed, the grouped complaint was added to the final derivation shortlist. In all cases of disagreement, the reviewers were able to reach consensus by discussion. A third reviewer was available in cases of intractable disagreement.

The discussions in this consensus process initially focused on grouping complaints that differed only in subtle anatomic descriptions (eg, ‘HEADACHE - FRONTAL’ and ‘HEADACHE – OCCIPITAL’ were grouped as ‘HEADACHE’ and ‘PAIN – EPIGASTRIC’ and ‘LOWER ABDOMINAL PAIN’ were grouped as ‘ABDOMINAL PAIN’). Emphasis was placed on making groups that considered the resources required for diagnosis and treatment (eg, ‘LACERATION – LEG’ and ‘LACERATION – ARM’ were grouped into ‘LACERATION’, but ‘LACERATION – SCALP’ was grouped with ‘HEAD INJURY’ because of the substantial differences in injury severity, evaluation and treatment between these complaints).

Care was taken to include only complaints in the shortlist, thus diagnoses entered as complaints such as ‘asthma’ were reclassified as ‘shortness of breath’. Mechanisms of injury, however, were deliberately kept as they reflected the context and often times severity of illness of patients presenting for care and reflected what clinicians felt was most germane to patient care.

Disagreement about how body locations was resolved by using body regions instead of very specific or very general locations (eg, ‘PAIN AND/OR SWELLING – HAND’ and ‘PAIN AND/OR SWELLING – ARM’ became ‘PAIN AND/OR SWELLING – UPPER EXTREMITY’ and ‘PAIN AND/OR SWELLING – FOOT’ and ‘PAIN AND/OR SWELLING – LEG’ became ‘PAIN AND/OR SWELLING – LOWER EXTREMITY’).

The final focus for discussion centred on the relative benefits of keeping a longer list of complaints to produce greater data resolution (eg, ‘ULCER – ORAL’ and ‘TONGUE MASS’ and ‘PAIN – TOOTH’) versus the benefits of having a more concise list (eg, ‘DENTAL/ORAL PROBLEM’). In most cases of disagreement, the authors deferred to a more concise list.

Once the final derivation shortlist was produced, the authors entered it into the electronic survey tool Qualtrics (Qualtrics, Provo, Utah, USA) to facilitate prospective use by clinicians. The shortlist was split into traumatic and medical complaints to remain consistent with the structure found in the Kampala Trauma Form (already in use at the hospital for trauma presentations) to produce a final derivation ‘shortlist’ of chief complaints.11 12

Automation of consensus process
The logic used in the consensus process described above was reproduced post hoc in Stata via additional language processing. This additional processing was applied to the derivation set longlist to produce and alternative ‘automated shortlist’.

Validation
A second set of patient complaints from the same study site was analysed using the Stata programme described above to produce a second longlist of cleaned and refined data. The performance of this cleaning and refining programme was analysed using χ2 test to see if there was a significant difference in performance between derivation and validation data sets. The threshold for significance was set at p<0.05.

The refined validation set longlist of chief complaint data was given to two Ugandan NPCs for sorting with the Qualtrics tool. These NPCs had been using the free-text chief complaints for clinical care for several years and were fluent in English and Runyankole. Using the Qualtrics version of the derivation shortlist, the NPCs were asked to categorise every longlist complaint to a corresponding derivation set shortlist complaint. If an appropriate entry could not be found, they were instructed to select ‘OTHER’ and enter a free-text complaint. The results of their categorisation were then compared using Cohen’s kappa to determine inter-rater reliability for the shortlist.13 14 The thresholds for reliability were defined as: 0.01–0.20 as none to slight agreement, 0.21–0.40 as fair agreement, 0.41–0.60 as moderate agreement, 0.61–0.80 as substantial agreement and 0.81–1.00 as almost perfect agreement.14

Patient and public involvement
The NPC training programme was originally developed in response to several years of clinical emergency medicine experience in Uganda. The positive response of patients, staff and administrators at the pilot site in Nyakibale led to the expansion of the project to Masaka. Patients and the public were not involved in the design of the study though outcome measures are explicitly patient oriented. Results will be disseminated through open access publication.

Results
Derivation
The derivation dataset included 26 996 unique emergency visits with 32 272 free-text chief complaints resolving to 42 566 discrete chief complaints (average: 1.58 complaints per visit). The demographics for these patient visits are listed in table 1 below.

Table 1 Demographics

Demographic breakdown	Per cent	Total N	
% Female	44.8	11 929	
Age group			
Children (under 5 years)	20.6	5477	
Paediatric (5–18 years)	16.3	4336	
Adult (18–65 years)	50.9	13 559	
Elderly (>65 years)	12.2	3253	
When the raw data was refined using the Stata cleaning algorithm, 40 772 complaints (95.8% of all complaints) were recognised and yielded 10 110 unique cleaned and capitalised chief complaints. After the four stages of data refining described above, the process reduced the total number of unique chief complaints to 9061 (stage 1), then to 8801 (stage 2), then to 838 (stage 3), then to 555 (stage 4) (see figure 1).

Figure 1 Data flow for chief complaint analysis.

Those 555 refined complaints (listed as online supplementary appendix 1) were then grouped via the consensus process to produce a final derivation shortlist of 83 chief complaints (stage 5) detailed below. The candidate derivation shortlist for one reviewer (BTR) contained 104 complaints, and for the other reviewer (HM) it contained 75 complaints. Agreement in the consensus process is shown in table 2 below.

10.1136/bmjopen-2017-020188.supp1Supplementary data 

 Table 2 Agreement in consensus process

Agreement in consensus process	Total complaints	Cleaned complaints	Consensus complaints	Per cent of total complaints	
Agree (total)	30 273	326	51	71.8	
 Exact wording match	19 696	46	25	46.7	
 Synonyms used	8629	57	17	20.5	
 Exact match when anatomic descriptors omitted	1948	223	8	4.6	
Disagree (total)	10 116	229	66	24.0	
 Extended discussion needed	4542	76	37	10.8	
 Disagreed on dividing broad complaint into multiple complaints	2746	48	14	6.5	
 Disagreed on location description for trauma complaints	327	19	4	0.8	
 Disagreed on location description for non-traumatic complaints	2501	86	11	5.9	
Unable to clean in Stata	1794	n/a	n/a	4.3	
Agreement was defined in three cases: both reviewers used exactly the same words; both reviewers used synonyms (‘LACERATION’ vs ‘CUT OR LACERATION’); both reviewers agreed that anatomic descriptors should be omitted for specific complaints. Disagreement was also defined in multiple ways: disagreement about how broad to make complaints (‘SWELLING – LIPS/FACE’ and ‘SWELLING – LOWER EXTREMITY’ vs ‘SWELLING – LOCALIZED’), disagreement about how to describe location for traumatic complaints (‘INJURY – PELVIC’ and ‘INJURY – LOWER EXTREMITY’ vs ‘TRAUMA/INJURY’), disagreement about how to describe location for non-traumatic complaints (‘PAIN – UPPER EXTREMITY’ and ‘PAIN – LOWER EXTREMITY’ vs ‘PAIN – MSK’) and disagreements requiring prolonged discussion (ie, should ‘UNABLE TO TALK’ fall under the category of ‘MOTOR DEFECIT’ or stand alone as ‘APHASIA’, should ‘INOXICATION – ALCOHOL’ fall under ‘ALTERED MENTAL STATUS’ or stand alone as ‘INTOXICATION WITH ALCOHOL OR DRUG’). In all cases of disagreement, consensus was arrived on through discussion, and the third reviewer (MB) was never required for breaking a deadlock.

This consensus process produced a shortlist of 83 complaints that encompass all 555 cleaned complaints and are compiled in table 3.

Table 3 Consensus derivation shortlist of chief complaints

No.	Shortlist of chief complaints	Freq.	Per cent	Cum. %	
1	Fever	3597	8.93	8.93	
2	Headache	3545	8.8	17.73	
3	Abdominal pain	3203	7.95	25.68	
4	Cough	2729	6.77	32.45	
5	Nausea/vomiting, non-bloody	2402	5.96	38.42	
6	Cut or wound	2078	5.16	43.57	
7	Diarrhoea – non-bloody	1595	3.96	47.53	
8	Shortness of breath	1519	3.77	51.3	
9	Chest pain	1263	3.14	54.44	
10	Road traffic accident	1220	3.03	57.47	
11	Generalised weakness/malaise	1215	3.02	60.48	
12	Tube/catheter problem	1107	2.75	63.23	
13	Pain and/or swelling – lower extremity	1043	2.59	65.82	
14	Wound care/dressing change	797	1.98	67.8	
15	Decreased oral intake/failure to thrive	728	1.81	69.6	
16	Dizziness	684	1.7	71.3	
17	Unresponsive	662	1.64	72.95	
18	Pain and/or swelling – upper extremity	650	1.61	74.56	
19	Assault	571	1.42	75.98	
20	Back pain	536	1.33	77.31	
21	Flu-like illness	505	1.25	78.56	
22	Urinary – pain/blood/frequency	483	1.2	79.76	
23	Altered mental status	470	1.17	80.93	
24	Pain and/or swelling – skin	470	1.17	82.09	
25	Myalgia/arthralgia	435	1.08	83.17	
26	Foreign body – eye/ear/nose	427	1.06	84.23	
27	Swelling/oedema, generalised	406	1.01	85.24	
28	Ingestion/poisoning	405	1.01	86.25	
29	Foreign body – ingested	295	0.73	86.98	
30	Burn	273	0.68	87.66	
31	Animal bite/attack	268	0.67	88.32	
32	Abdominal distension/swelling	267	0.66	88.98	
33	Chills/rigours	225	0.56	89.54	
34	Male genital – pain/swelling/discharge	221	0.55	90.09	
35	Pain and/or swelling – lips/face	217	0.54	90.63	
36	Dental/oral – Pain/swelling/mass	213	0.53	91.16	
37	Ear – redness/pain/discharge	205	0.51	91.67	
38	Hearing loss/tinnitus/hyperacuasis	205	0.51	92.18	
39	Head injury	197	0.49	92.66	
40	Fall	191	0.47	93.14	
41	Seizure	187	0.46	93.6	
42	Neck pain/stiffness	184	0.46	94.06	
43	Eye – redness/pain/discharge	140	0.35	94.41	
44	Difficulty speaking	132	0.33	94.74	
45	Suture removal	131	0.33	95.06	
46	Abrasions/contusions	120	0.3	95.36	
47	Throat pain	118	0.29	95.65	
48	Constipation	117	0.29	95.94	
49	Bloody stool	115	0.29	96.23	
50	Itching	115	0.29	96.51	
51	Rash	105	0.26	96.77	
52	Bony deformity	99	0.25	97.02	
53	Trauma/injury	98	0.24	97.26	
54	Referred for diagnostic/therapeutic procedure	86	0.21	97.48	
55	Syncope	78	0.19	97.67	
56	Epistaxis/nosebleed	76	0.19	97.86	
57	Vomiting blood	71	0.18	98.03	
58	Sensory deficit	70	0.17	98.21	
59	Intoxication with alcohol or drug	68	0.17	98.38	
60	Motor deficit	57	0.14	98.52	
61	Rectal pain/mass/swelling	54	0.13	98.65	
62	Female genital – pain/swelling/discharge	53	0.13	98.78	
63	Abnormal sweating	52	0.13	98.91	
64	Behaviour change	51	0.13	99.04	
65	Cast change/problem	51	0.13	99.17	
66	Ulcers/sore	46	0.11	99.28	
67	Abnormal blood sugar	42	0.1	99.38	
68	Rhinorrhoea/congestion	42	0.1	99.49	
69	Hiccups	31	0.08	99.57	
70	Insect bite/sting	27	0.07	99.63	
71	Sexual assault	24	0.06	99.69	
72	Electrical/lightening injury	21	0.05	99.74	
73	Palpitations	19	0.05	99.79	
74	Vision loss/blurred vision/diplopia	17	0.04	99.83	
75	Pain – skin/soft tissue	16	0.04	99.87	
76	Change in skin colour	15	0.04	99.91	
77	Abnormal test or measurement	7	0.02	99.93	
78	Medication refill	7	0.02	99.95	
79	Dead on arrival	6	0.01	99.96	
80	Drowning	6	0.01	99.98	
81	Suicide attempt/ideation	4	0.01	99.99	
82	Allergic reaction	3	0.01	99.99	
83	Pregnancy-related complaint	3	0.01	100	
	Total	40 286	100		
The processing of the longlist in Stata using the logic from the consensus process yielded an ‘automated shortlist’ of 186 entries, which is reproduced in online supplementary appendix 2.

10.1136/bmjopen-2017-020188.supp2Supplementary data 

 Validation
The validation dataset included 10 068 patient visits and 19 531 recorded complaints. Expanding those complaints when multiple complaints were written in a single field yielded 20 165 unique complaints. The Stata cleaning algorithm recognised 94.9% of the complaints to produce 19 138 cleaned complaints. This level of recognition was very similar between the derivation dataset (95.8% complaint recognition) and the validation dataset (94.9% complaint recognition) but because of the very large cohorts used, this difference of less than 1% reached statistical significance (p<0.001) (table 4).

Table 4 Comparison of automated cleaning performance for derivation and validation datasets

	Recognised	Unrecognised	Total	
Derivation	95.8% (n=40 772)	4.2% (n=1794)	42 566	
Validation	94.9% (n=19 138)	5.1% (n=1027)	20 165	
P<0.001 using χ2.

Stata refinement of the 19 138 complaints produced a longlist of 451 complaints (online supplementary appendix 3). The two NPCs grouped this longlist using the Qualtrics tool that replicated the consensus shortlist, and their choices were compared with assess inter-rater reliability. Agreement between the two NPCs was highest for the most common chief complaints. The top 10 most frequent complaints had 90.0% agreement; the top 20 had 75.0% agreement. The top 50 had 64.0% agreement, and the top 100 had 60.0% agreement.

10.1136/bmjopen-2017-020188.supp3Supplementary data 

 Overall, there was 71.5% agreement for the 19 138 complaints, yielding a kappa of 0.70 (95% CI 0.70 to 0.73) suggesting substantial inter-rater reliability of the shortlist. In only one case out of 451 longlist entries did an NPC feel the need to select ‘OTHER’ and enter free-text to describe chief complaint (‘DROWNING’). Several entries were placed on the shortlist via the author consensus process but were never selected by the NPCs. Neither NPC used ‘SYNCOPE’ or ‘MEDICATION REFILL’. One NPC never selected ‘BLOODY STOOL’, ‘FOREIGN BODY – INGESTED’, ‘VAGINAL BLEEDING’, ‘CAST CHANGE/PROBLEM’ or ‘ELECTRICAL/LIGHTNING INJURY’. The other NPC only failed to select ‘CHANGE IN SKIN COLOR’ in addition to the two shared omissions described above.

Final candidate shortlist
The chief complaints required to account for 80% of complaints overall in both the consensus and the automated shortlist were compared side by side (see table 5). The 14 most frequent complaints were identical in both lists, and the remainder were merged to form a final candidate shortlist of 25 chief complaints (the 24 listed +a free-text ‘OTHER’ field).

Table 5 Comparison of 80% inclusive shortlists (in order of decreasing frequency)

Complaint no.	Consensus list	Automated list	Final candidate shortlist	
1	Fever	Fever	Fever	
2	Headache	Headache	Headache	
3	Abdominal pain	Abdominal pain	Abdominal pain	
4	Cough	Cough	Cough	
5	Nausea/vomiting	Vomiting	Nausea/vomiting	
6	Cut or wound	Cut or wound	Cut or wound	
7	Diarrhoea	Diarrhoea	Diarrhoea	
8	Shortness of breath	Difficulty in breathing	Shortness of breath	
9	Chest pain	Chest pain	Chest pain	
10	Road traffic accident	Road traffic accident	Road traffic accident	
11	Generalised weakness/malaise	Weakness general	Generalised weakness/malaise	
12	Tube/catheter problem	Catheter change	Tube/catheter problem	
13	Pain and/or swelling – localised	Pain and/or swelling – localised	Pain and/or swelling – localised	
14	Wound care/dressing change	Dressing change	Wound care/dressing Change	
15	Decreased oral intake/failure to thrive		Decreased oral intake/failure to thrive	
16	Dizziness	Dizziness	Dizziness	
17	Unresponsive	Unresponsive	Unresponsive	
18	Assault	Assault	Assault	
19	Back pain	Back ache	Back pain	
20	Flu-like illness	Influenza	Flu-like illness	
21	Urinary – pain/blood/frequency		Urinary – pain/blood/frequency	
22	Altered mental status		Altered mental status	
23		Foreign body	Foreign body	
24		Poisoning	Posioning	
As some hospital systems (including this study site) have separate trauma forms, the authors felt that there is value in a prospective shortlist with a specific area for trauma related injuries (derived from the Ugandan trauma form currently in use at the study site), and this list is provided below as figure 2.

Figure 2 Candidate chief complaint shortlist for prospective use.

Discussion
Emergency care providers in low-resource settings are caught in a vicious cycle. They frequently work in under-resourced emergency units that are stressed past capacity in terms of acuity and clinical volume. However, little is known about what conditions present for emergency treatment or what occurs in the emergency encounter because few health systems in LMICs systematically capture data from emergency care units. It becomes difficult to argue for additional resources to improve emergency care without data, and in turn, it is difficult to capture data without resources and some system in place to systematically collect and analyse that data. Experts have called for research on emergency chief complaints as a critical step in emergency care development in LMICs.1

Overall, the goal of this project was to take a pragmatic approach that could result in a solution that:Is easily understood by any emergency care provider (physicians, NPCs, nurses and clinical officers).

Maximises speed and minimises error.

Does not rely on digital records that are uncommon in these settings.

Uses little space on standard clinical documentation forms.

Is independent of final diagnoses that are frequently unavailable at the time of the emergency clinical encounter.

Can be immediately implemented in most LMIC emergency units no matter their level of resource.

Allow for comparisons of emergency care data across facilities.



This manuscript represents the largest, most comprehensive analysis of chief complaints to be produced to date from a LMIC emergency unit. A search in PubMed yielded minimal research that dealt with emergency chief complaints within LMICs, and none involved rigorous methods or large, representative patient populations. The closest published research was a description of a year of Kenyan emergency visits, which used International Classification of Diseases, 10th Revision codes for entering presenting complaints instead of an LMIC-specific lexicon.15 A Cambodian-based study described emergency presentations in a LMIC but used a pre-existing set of chief complaints.16 The other published manuscripts from sub-Saharan Africa to date that deal even tangentially with chief complaints focus on non-emergency cases,17 small numbers of patients,18 small surveys19 20 or looked only at subsets of trauma patients.21 22

The chief complaint processing and analysis presented in this manuscript is a data-driven process that can be likely be applied to data from other LMIC emergency units and can be an appropriate tool for retrospective analysis. Additionally, this analysis informed the creation of a candidate chief complaint shortlist that can realistically further prospective data collection in low-resource settings.

The Stata algorithm performed well in separating, cleaning and refining the free-text chief complaints, with nearly 95% of free-text strings from both the derivation (95.8%) and the validation (94.9%) datasets being accurately identified and converted to a longlist complaint. The consensus process was able to reduce an unwieldy 555 complaints to 83. The reliability of this grouping schema was supported by the NPCs who used the shortlist tool generating ‘substantial’ inter-rater reliability (kappa=0.70). For both the derivation and the validation processes, the majority of the disagreement occurred with the least common complaints.

The inter-rater reliability suggests it is a reasonable grouping system according to both international researchers and local providers. This systematic grouping will form the basis for analysis to assess the epidemiology of emergency encounters to determine what defines a high-risk chief complaint in this setting and to assist with the rational development of emergency care in Uganda. The alternative automated shortlist provided in the supplementary appendix 2 was included to provide a list that more closely adheres to the language used by patients but which is therefore less compact. This preservation of language may provide individuals interested in research and additional information for future investigations.

While arguments can be made about the methods chosen to encode and validate the chief complaints and produce the candidate shortlist in figure 2, no alternative standard system exists for chief complaint data in LMICs. The struggle to balance data resolution (splitting) and providing complaints that group together similar patients (clumping) is not limited to LMIC settings and was well described in a high-income setting.23 No scientifically derived number exists to define adequate coverage for a chief complaint list, but a recent consensus process suggested a list would need to describe at least 80% of emergency patient presentations.1 3

While using a list of 83 (or 186) chief complaints may be useful for electronic retrospective data analysis, the vast majority of emergency care is delivered in settings reliant on patient charts. A pragmatic approach demands a compromise between data resolution and the limitations of a paper chart. Some advocates suggest that mobile technology will enable systems to ‘leapfrog’ forward to a digital collection of all emergency health data. While this may be the future, most emergency units in LMICs do not have that option at this point in time, and patients continue to arrive to these units daily. The final shortlist presented in this manuscript provides a tool for immediate implementation in the existing systems.

To the authors’ knowledge, the chief complaint lists generated in this manuscript represent the largest, most rigorous and most comprehensive dataset of emergency chief complaints to ever be published from an LMIC. Next steps for research should focus on external validation both within Uganda and other LMICs, on comparing the list to those employed in high-income countries, or to linking complaint data with patient outcomes to establish high-risk complaints in Uganda. As efforts continue to standardise emergency care data collection in LMICs, improving the quality of chief complaint data can be an important step in improving the quality of emergency care and research in low-resource settings worldwide.

This emergency chief complaint shortlist—derived in a typical district hospital setting in an LMIC—provides a tool to catalogue, characterise and analyse emergency care in such settings that adequately characterises 80%–90% of encounters. Implementation of such a tool will help plan for training and resource allocation to assess changes in epidemiology of emergency encounters and to provide a normalised basis on which emergency care centres may be compared. This represents an important first step in breaking the cycle of data poverty and beginning a new virtuous cycle where improved understanding of the emergency encounter can generate clinical improvements, new lines of inquiry and further elaboration of pragmatic data collection systems that realistically can be immediately implemented by users in low-resource settings.

Limitations
The study database was produced from patient visits at a single site. Recorded complaints from this region were necessarily impacted by the local dialect spoken and are highly culturally and linguistically specific. Reported complaints were also affected by the rural setting and the presence of other healthcare services (eg, more agricultural injuries and poisonings and fewer maternal complaints than may be seen elsewhere). The automated cleaning process was imperfect, and 4.2% of the complaints produced by the Stata algorithm were either unintelligible or failed to be recognised by the string filters. This small amount of data is not represented in analysis.

The consensus process used was intentionally designed to minimise the influence of existing high-income complaint systems. However, the physicians involved were American Board of Emergency Medicine certified, and their training likely somewhat biased their cognitive schema towards their current practices.

The validation process used NPCs who both use the handwritten charts and train the nursing students to fill them out. The authors discussed using the nursing students to validate the shortlist in addition to the NPCs, but their level of computer literacy was not adequate for them to meaningfully use the Qualtrics tool.

This derived list of standardised chief complaints includes a combination of signs, symptoms, events and mechanisms. This is in distinction to more sophisticated systems of classification that clearly delineate these as separate categories of information. When these data were presented at a WHO expert meeting in South Africa in April 2016, members from high-income countries raised this as an objection. However, there was consensus among the attendees from LMICs that such a list is what most accurately reflects the real-world experience of delivering emergency care in their countries, where non-clinicians often perform triage. Moreover, it was noted that in high-income countries, what clinicians encounter as a ‘chief complaint’ is often a ‘triage impression’ that reflects the complaint of the patient after cognitive filtering by a clinician with more training than that of the provider or clerk recording these data in low-resource settings.

Conclusions
Emergency care in LMICs in remains poorly characterised. Chief complaint data present one target of opportunity for standardising collection of emergency care data to improve quality of and research in emergency care in LMICs. This study presents the largest published analysis of chief complaints from any LMIC and outlines a validated consensus shortlist of chief complaints to retrospectively categorise visits and a simplified shortlist that can be immediately used in low-resource settings. Further work is needed to prospectively validate this list in other environments and to compare it with other locally derived sets of chief complaints to create a final candidate list that is robust across emergency centre types, different languages and cultures.

Supplementary Material
Reviewer comments
 Author's manuscript
 The authors would want to thank three emergency care providers—Hilary Kizza, Benifer Niwagaba and Deus Twinomugisha—for participating in the validation process. The authors also wish to thank Caleb Dresser, MD, for his assistance with data cleaning. The authors wish to acknowledge all of the emergency care providers who provided the essential care described above in addition to the programme directors and research assistants who made the data collection possible.

Contributors: BTR developed and designed the study concept, cleaned and interpreted the data, designed and performed the programming and statistical analysis, participated in the consensus process and drafted and revised the manuscript. MB assisted with study design, participated in consensus process and drafted and revised the manuscript. RJ assisted with the acquisition of the data, supervised and administered the validation tool and revised the manuscript. SM provided administrative support, local expertise and revised the draft manuscript. HM developed and designed the study concept, analysed and interpreted the data, participated in the consensus process and drafted and revised the manuscript. All members of Global Emergency Care Investigator Group designed and implemented the training program being studied, assisted with the development of the database, assisted with data collection, assisted with administrative issues related to research and development and revised the manuscript.

Funding: This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.

Competing interests: None declared.

Patient consent: Not required.

Ethics approval: The development and implementation of this database received institutional review board approval from the University of Massachusetts, and local approval was sought and received by hospital administration in conjunction with GEC from Mbarara University of Science and Technology and the Ugandan Council of Science and Technology. University of Massachusetts, Mbarara University of Science, Ugandan Council of Science and Technology.

Provenance and peer review: Not commissioned; externally peer reviewed.

Data sharing statement: Individual participant data including data dictionaries that underlie the results reported in this article will be made available after deidentification. Statistical analysis plan plus analytic code will also be made available beginning 3 months and ending 5 years after article publication to researchers who provide a methodologically sound proposal to achieve aims approved by the GEC Executive Committee and our local Ugandan partners. Proposals should be directed to brian@globalemergencycare.org and to gain access, data requestors will need to sign a data access agreement.

Collaborators: Global Emergency Care Investigator Group Members: Stacey Chamberlain; Bradley Dreifuss; Heather Hammerstedt; Mélissa Langevin; Sara Nelson; Usha Periyanayagam.
==== Refs
References
1. 
Mowafi H , Dworkis D , Bisanzo M , et al 
Making recording and analysis of chief complaint a priority for global emergency care research in low-income countries . Acad Emerg Med 
2013 ;20 :1241 –5 . doi:10.1111/acem.12262
24283813 
2. 
Begier EM , Sockwell D , Branch LM , et al 
The National Capitol Region’s Emergency Department syndromic surveillance system: do chief complaint and discharge diagnosis yield different results? 
Emerg Infect Dis 
2003 ;9 :393 –6 . doi:10.3201/eid0903.020363
12643841 
3. 
Reynolds TA , Bisanzo M , Dworkis D , et al 
Research priorities for data collection and management within global acute and emergency care systems . Acad Emerg Med 
2013 ;20 :1246 –50 . doi:10.1111/acem.12261
24341579 
4. 
Health Level 7 International . Health Level 7 standards . Ann Arbor : Health Level 7 International , 2008 .
5. 
International Health Terminology Standards Organization . SNOMED CT . Bethesda : U.S National Library of Medicine .
6. 
U.S. National Library of Medicine . Unified medical language system . Bethesda : U.S. National Library of Medicine , 1986 .
7. 
Hammerstedt H , Maling S , Kasyaba R , et al 
World health assembly resolution 60.22. [corrected] . Ann Emerg Med 
2014 ;64 :461 –8 . doi:10.1016/j.annemergmed.2014.01.035
24635990 
8. 
Periyanayagam U , Dreifuss B , Hammerstedt H , et al 
Acute care needs in a rural Sub-Saharan African Emergency Centre: A retrospective analysis . African Journal of Emergency Medicine 
2012 ;2 :151 –8 . doi:10.1016/j.afjem.2012.09.002

9. 
Rice B , Periyanayagam U , Chamberlain S , et al 
Mortality in children under five receiving nonphysician clinician emergency care in Uganda . Pediatrics 
2016 ;137 :e20153201
doi:10.1542/peds.2015-3201
26921282 
10. 
Nadkarni PM , Ohno-Machado L , Chapman WW  
Natural language processing: an introduction . J Am Med Inform Assoc 
2011 ;18 :544 –51 . doi:10.1136/amiajnl-2011-000464
21846786 
11. 
MacLeod JBA , Kobusingye O , Frost C , et al 
A Comparison of the Kampala Trauma Score (KTS) with the Revised Trauma Score (RTS), Injury Severity Score (ISS) and the TRISS Method in a Ugandan Trauma Registry . European Journal of Trauma 
2003 ;29 :392 –8 . doi:10.1007/s00068-003-1277-5

12. 
Kobusingye OC , Lett RR  
Hospital-based trauma registries in Uganda . J Trauma 
2000 ;48 :498 –502 . doi:10.1097/00005373-200003000-00022
10744292 
13. 
McHugh ML  
Interrater reliability: the kappa statistic . Biochem Med 
2012 ;22 :276 –82 . doi:10.11613/BM.2012.031

14. 
Cohen J  
A coefficient of agreement for nominal scales . Educ Psychol Meas 
1960 ;20 :37 –46 . doi:10.1177/001316446002000104

15. 
House DR , Nyabera SL , Yusi K , et al 
Descriptive study of an emergency centre in Western Kenya: challenges and opportunities . African Journal of Emergency Medicine 
2014 ;4 :19 –24 . doi:10.1016/j.afjem.2013.08.069

16. 
Yan LD , Mahadevan SV , Yore M , et al 
An observational study of adults seeking emergency care in Cambodia . Bull World Health Organ 
2015 ;93 :84 –92 . doi:10.2471/BLT.14.143917
25883401 
17. 
Masiga MA  
Presenting chief complaints and clinical characteristics among patients attending the Department of Paediatric Dentistry Clinic at the University of Nairobi Dental Hospital . East Afr Med J 
2005 ;82 :652 –5 .16619711 
18. 
Oteng RA , Whiteside LK , Rominski SD , et al 
Individual and medical characteristics of adults presenting to an urban emergency department in Ghana . Ghana Med J 
2015 ;49 :136 –41 . doi:10.4314/gmj.v49i3.2
26693187 
19. 
Weng YH , Chiou HY , Tu CC , et al 
Survey of patient perceptions towards short-term mobile medical aid for those living in a medically underserved area of Swaziland . BMC Health Serv Res 
2015 ;15 :524 
doi:10.1186/s12913-015-1186-4
26613782 
20. 
Becker J , Dell A , Jenkins L , et al 
Reasons why patients with primary health care problems access a secondary hospital emergency centre . S Afr Med J 
2012 ;102 :800 –1 . doi:10.7196/SAMJ.6059
23034209 
21. 
Osman M , Kebede Y , Anberbir S  
Magnitude and pattern of injuries in north Gondar administrative zone, northwest Ethiopia . Ethiop Med J 
2003 ;41 :213 –20 .15227886 
22. 
Muriithi HM , Masiga MA , Chindia ML  
Dental injuries in 0-15 year olds at the Kenyatta National Hospital, Nairobi . East Afr Med J 
2005 ;82 :592 –7 .16463754 
23. 
Grafstein E , Unger B , Bullard M , et al 
Canadian Emergency Department Information System (CEDIS) Presenting Complaint List (Version 1.0) . CJEM 
2003 ;5 :8–34 . doi:10.1017/S1481803500008071


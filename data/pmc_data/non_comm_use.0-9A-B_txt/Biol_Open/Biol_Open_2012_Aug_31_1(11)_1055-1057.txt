
==== Front
Biol OpenBiol OpenbiolopenbioBiology Open2046-6390The Company of Biologists Bidder Building, 140 Cowley Road, Cambridge, CB4 0DL, UK 23213384BIO2012247710.1242/bio.20122477EditorialPublishing in the biomedical sciences: if it's broken, fix it! Raff Jordan W. (Editor-in-Chief)Sir William Dunn School of Pathology, University of Oxford, South Parks Road, Oxford OX1 3RE, UKAuthor for correspondence (bio.editor@biologists.com)15 11 2012 31 8 2012 1 11 1055 1057 © 2012. Published by The Company of Biologists Ltd2012This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial Share Alike License (http://creativecommons.org/licenses/by-nc-sa/3.0/).
==== Body
During my short time as Editor-in-Chief of Biology Open (BiO), I've come to realise that publishing in the biomedical sciences is entering a period of profound change, the likes of which none of us has experienced before. The present system is under sustained attack and, although many scientists are probably unaware of this, there seems little chance that it will survive in its current form. In this Editorial, I want to share what I've learned over the past year and explain why I think change is inevitable. As in all things scientific, I will probably be wrong in detail, but I hope these thoughts will stimulate you to think about these issues and how we might influence them. I am convinced they will have an enormous impact on us all.

My assertion that the present system will inevitably change might seem the wishful thinking of a new Editor of a new journal. But I believe several factors have combined to create a perfect storm that will drive change. At the heart of the problem is that, although the public funds much of our research, we have to pay to access most of the published results. This is because we scientists usually give the copyright to our data to the publishers. Although it is true that most members of the public don't want to access these data, I'm a member of the public, and I need access because it is essential for my research. It is unacceptable that I (in my case through my institution) have to pay large amounts of money to private publishers for this privilege when the publishers do not pay anything for the research.

Many publishers argue that they impart significant ‘added value’ to the published work by organising the peer review process, editing manuscripts, and distributing the journals. This argument may have had merit in the past, but it does not today; modern web-based publishing methods mean that the costs of producing and distributing journals cannot possibly justify the exorbitant price of most journals or the high profit margins of some of the biggest publishers (http://bit.ly/jordanref1; http://bit.ly/jordanref2). Moreover, the most valuable part of the services provided by publishers is peer review, which is provided free by scientists.

Why then has the present system, so obviously flawed, survived for so long? I think the most important reason is that the impact-factor-led hierarchy of journals has provided a simple mechanism for ranking a scientist's worth, and this system is now so embedded in our culture that we believe we cannot function without it. Few scientists have the time to read and understand someone else's papers anymore, and the convenience of the journal hierarchy means we don't have to: we all understand that a paper published in a high-impact journal must be ‘better’ than one published in a lesser journal. Scientists, funding agencies, and the various bodies that hire and promote us have all adopted this simple system, even though most scientists realize that it is flawed and, ironically, often feel unfairly treated by it. Still, most of us seem to have accepted that the system generally gets things about right and ensures that modern biological science works as a meritocracy. I will argue below that the system does nothing of the sort and that, worryingly, it is now actually distorting and impeding the scientific enterprise.

The overwhelming emphasis on publishing in top journals largely explains why Open Access publishing failed to break the stranglehold of the top journals when it was first championed in the 1990s. Although several Open Access journals have been successful, they have not displaced the handful of journals, such as Nature, Cell, and Science, at the top of the hierarchy. Many life scientists understand the perverse economics of the present system, and have supported the idea and goals of Open Access, but few of us have had the courage to stop trying to publish in the top journals (or the lower ranking sister journals that they have spawned). We were simply too scared of the negative impact that it would have on our careers. And we were right to be scared. Funding agencies and employers are still obsessed with the impact factor of the journals we publish in.

So why am I convinced that the system will change? One reason is that journalists and politicians have started to notice the absurdity of the present system. There have been scathing articles in the main sections of high profile newspapers such as The Guardian (http://bit.ly/jordanreference3) and New York Times (http://bit.ly/jordanreference4), a major report on the publishing system by the UK Parliament [House of Commons Science and Technology Committee (2011). Peer Review in Scientific Publications. http://bit.ly/jordanreference5], and the US Congress has recently discussed several bills that would promote or restrict Open Access publishing. All this activity has increased general awareness of the problems with the current system, but I am not naïve enough to believe that this alone will drive meaningful change.

More important will be the growing unease with the present system from within the science community itself. The idea that the worth of a publication should be judged by the impact factor of the journal it is published in has actually long been discredited (http://bit.ly/jordanreference6) (Editorial, 2005; Seglen, 1997), mainly because the impact factor of individual papers is poorly correlated with the impact factor of the journal they are published in (http://arxiv.org/abs/1205.4328). Moreover, journals can and do artificially manipulate their impact factor, and the data on which a journal's impact factor is calculated are not freely available; independent attempts to calculate a journal's impact factor have failed (Rossner et al., 2007). Perhaps surprisingly, many politicians and bureaucrats seem to be ahead of scientists in recognising the weakness of the present system. Several funding agencies and government bodies around the world now explicitly advise against the use of journal impact factors in the assessment of an individual's research performance (http://bit.ly/jordanreference7; http://bit.ly/jordanreference8). Thus, remarkably, it is we scientists who are most responsible for maintaining the current system, and this is why it will be we scientists who ultimately have to bring about change.

The real reason that I am so confident that change will come is not often discussed but, in my view, it is the most important: our current obsession with impact factor is actually damaging science. The scientific method is well established: propose a hypothesis and design experiments to test it. Crucial to the success of this approach is that the scientist should be neutral about the outcome of the experiment. This is important because it is well known that we human beings have a strong bias toward seeing what we want to see in all sorts of contexts, and this can confound the interpretation of any experiment. This is not fraud; it is simply human nature, and it is why we try to perform experiments ‘double blind’.

In practice, it is often difficult to perform experiments blind, and I suspect that the vast majority of us usually don't do it. But the present publication system puts enormous pressure on students and postdocs to get the ‘right’ result, especially when performing the experiments demanded by referees, and particularly if the right result means acceptance of the paper in a high-impact journal, which can often mean the difference between getting a job or not. This kind of pressure is dangerous. As scientists, we readily understand how incentives can distort political, financial and many other systems, yet we seem blind to the potential dangers in our own system.

If the current system is no longer fit for purpose, how do we go about replacing it? Perhaps the most important job will be to find better ways of judging ‘good’ science. I'll discuss some possibilities and the potential role of journals such as BiO in a future Editorial. In the meantime, I would like to hear your views on any of the points I have discussed.

Changes are already underway and it is essential that we scientists act to ensure that these are the right changes. As an example, the UK Government recently announced that all Government funded research will have to be published in a fully Open Access format within the next two years. It is unclear how this will be implemented, but I believe there is a real risk that it will be done in a way that maintains the profits of the largest publishing companies without addressing the fundamental distortions of the present system. This would be a disaster. I urge you to get involved.
==== Refs
References
Editorial  (2005 ). Not-so-deep impact. Research assessment rests too heavily on the inflated status of the impact factor. 
Nature 
435 , 1003 –1004 
10.1038/4351003b 
Rossner M. Van Epps H. Hill E.   (2007 ). Show me the data. 
J. Cell Biol. 
179 , 1091 –1092 
10.1083/jcb.200711140 18086910 
Seglen P. O.   (1997 ). Why the impact factor of journals should not be used for evaluating research. 
Br. Med. J. 
314 , 497 –502 
10.1136/bmj.314.7079.497

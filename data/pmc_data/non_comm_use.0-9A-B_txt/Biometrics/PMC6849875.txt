
==== Front
BiometricsBiometrics10.1111/(ISSN)1541-0420BIOMBiometrics0006-341X1541-0420John Wiley and Sons Inc. Hoboken 10.1111/biom.13021BIOM13021Biometric MethodologyBiometric MethodologyDiscussion PapersDiscussion on “Model confidence bounds for variable selection” by Yang Li, Yuetian Luo, Davide Ferrari, Xiaonan Hu, and Yichen Qin LEEB et al.Leeb Hannes 
1
Pötscher Benedikt M. 
1
Kivaranovic Danijel 
1
benedikt.poetscher@univie.ac.at 
1 
Department of Statistics
University of Vienna
Austria
* 
Correspondence

Benedikt M. Pötscher, Department of Statistics, University of Vienna, Austria

Email: benedikt.poetscher@univie.ac.at
03 4 2019 6 2019 75 2 10.1111/biom.v75.2407 410 © 2019 The Authors. Biometrics published by Wiley Periodicals, Inc. on behalf of International Biometric SocietyThis is an open access article under the terms of the http://creativecommons.org/licenses/by-nc-nd/4.0/ License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non‐commercial and no modifications or adaptations are made. source-schema-version-number2.0cover-dateJune 2019details-of-publishers-convertorConverter:WILEY_ML3GV2_TO_JATSPMC version:5.7.1 mode:remove_FC converted:12.11.2019
==== Body
1 We congratulate the authors of Li et al. (2018) for their interesting paper, and we thank the Editor for the opportunity to comment on it. We shall offer some criticism of the proposed model confidence set in the following. Unless noted otherwise, we use the same notation as in Li et al. (2018). [Li et al. (2018) are not explicit about the nature of the regressor variables. We read their paper as considering nonstochastic regressors, and we note that similar results are possible for models with stochastic regressors. Also, a full column‐rank assumption on the regressor matrix X seems to be missing, without which the symbol m* is not well‐defined. We hence add this assumption.]

Let us first strengthen Theorem 1, the main result of Li et al. (2018), a little bit. Recall that rˆ(m1,m2)=B−1∑b=1BI(m1⊆mˆ(b)⊆m2) and define r˜(m1,m2)=Pm1⊆mˆ(b)⊆m2‖Y, where Y are the data. That is, r˜(m1,m2) is the analogue of rˆ(m1,m2), computed from the exact bootstrap distribution rather than from an approximation to it based on an i.i.d. bootstrap sample of size B (note that r˜(m1,m2)=E(rˆ(m1,m2)‖Y), and thus is the quantity that rˆ(m1,m2) is trying to approximate with the help of the bootstrap sample). Let m˜L and m˜U now be obtained from the exact bootstrap, i.e., m˜L and m˜U are defined by program (2) in Li et al. (2018), but with r˜(m1,m2) replacing rˆ(m1,m2) everywhere. To exclude trivial cases, we assume that the nominal confidence level satisfies 0<1−α<1. [Recall that mˆL and mˆU are defined by program (2) using rˆ(m1,m2) as given in the paper.] We note that inspection of the proof of Theorem 1 in Li et al. (2018) reveals that this proof actually seems to be given for m˜L and m˜U rather than for mˆL and mˆU (although the theorem also holds for the latter as will transpire from the subsequent result). We are now ready for the improved version of Theorem 1 in Li et al. (2018).
Proposition 1 Assume: (A.1) (Model selection consistency) P(mˆ≠m*)=o(1); (A.2) (Bootstrap validity) For the re‐sampled model mˆ(b), assume P(mˆ(b)≠mˆ)=o(1).

(a) Then P(m˜L⊆m*⊆m˜U)=1+o(1) and P(m˜U−m˜L=0)=1+o(1); in fact, P(m˜U=m˜L=mˆ=m*)=1+o(1) holds. Moreover, assuming (A.1) only, this statement trivially continues to hold if m˜L and m˜U are both replaced by mˆ.

(b) Part (a) also holds if we replace m˜L by mˆL and m˜U by mˆU (where the number of bootstrap replications B may depend on n).





  (a) (A.2) implies that r˜(mˆ,mˆ)=Pmˆ(b)=mˆ‖Y converges to 1 in probability as n→∞. [To see this note that (A.2) implies 1−P(mˆ(b)=mˆ)=E(1−P(mˆ(b)=mˆ‖Y))→0 as n→∞. But this shows that E(|1−P(mˆ(b)=mˆ‖Y)|) converges to zero, which even implies L1‐norm convergence of P(mˆ(b)=mˆ‖Y) to 1.] Obviously, this in turn also implies ∑m≠mˆr˜(m,m)→0 in probability. Inspection of (2) in Li et al. (2018) (with r˜(m1,m2) replacing rˆ(m1,m2) everywhere) then shows that m˜L=m˜U=mˆ holds on an event that has probability converging to 1. In view of (A.1), the event where m˜U=m˜L=mˆ=m* holds then also has probability converging to 1. This proves everything except for the last claim. For the last statement just note that the event {mˆ=m*} trivially has probability converging to one under (A.1).

(b) Consider first the case where B does not depend on n: Then, under (A.2), the event An={mˆ=mˆ(1)=⋯=mˆ(B)}, which is the finite intersection ⋂b=1Bmˆ(b)=mˆ, has probability converging to one. Note that rˆ(mˆ,mˆ)=1 and ∑m≠mˆrˆ(m,m)=0 hold on An. Inspection of (2) in Li et al. (2018) hence shows that mˆL=mˆU=mˆ holds on An, which, together with (A.1), proves the first claim in Part (b) for fixed B. Consider next the case where B=Bn diverges to infinity as n→∞: Similarly as in Part (a), it suffices to show that rˆ(mˆ,mˆ) converges to 1 in probability (noting that ∑m≠mˆrˆ(m,m)→0 in probability then follows). Note that  rˆ(mˆ,mˆ)=Bn−1∑b=1BnI(mˆ(b)=mˆ)−E(I(mˆ(b)=mˆ)‖Y)+E(I(mˆ(b)=mˆ)‖Y)=Bn−1∑b=1BnI(mˆ(b)=mˆ)−E(I(mˆ(b)=mˆ)‖Y)+P(mˆ(b)=mˆ‖Y). The final term on the right‐hand side does not depend on b and coincides with r˜(mˆ,mˆ). It converges to 1 in probability as shown in the proof of Part (a). Now, conditional on Y, the first term on the right‐hand side is the average of independent random variables that are centered versions of Bernoulli‐distributed variables. Hence, conditional on Y, this term has zero expectation and variance bounded by (4Bn )−1, which goes to zero as n→∞. An application of Chebyshev's inequality shows that this term hence converges to zero in probability. This completes the proof of the first claim in case Bn diverges to infinity. The case of a general sequence Bn now follows by a standard subsequence argument. The proof is thus complete as the last claim reduces to the last claim in Part (a). □




Proposition 1 obviously strengthens and extends Theorem 1 of Li et al. (2018). However, this result also raises some obvious concerns: In the limit, the coverage probability of the model confidence set (MCS) defined by m˜L and m˜U (mˆL and mˆU, respectively) is guaranteed to equal one (and not only to be ≥1−α), and the ‘length’ of this MCS equals zero. In particular, asymptotically this MCS coincides with the set mˆ and thus provides no more information than the point‐estimate mˆ, which the MCS was intended to improve. Interestingly, the fact that the MCS asymptotically reduces to mˆ under the assumptions of Proposition 1 seems to have informally been noticed by Li et al. (2018), at least in the context of model selection by the adaptive Lasso; see the discussion in Section 1.5 of the supplementary material of that paper. Apparently, however, this did not raise any red flags. [We also note that –in light of the proof of Part (a) given above –the proof of Theorem 1 in Li et al. (2018) seems to be much too complicated; in fact, it seems to be incorrect: For example, the final inequality in the first display in the proof of Theorem 1 appears to confuse the complement of mˆL⊆mˆ with mˆLmˆ.]

It turns out that a fixed‐parameter asymptotic analysis, as used in Proposition 1 and also in Theorem 1 of Li et al. (2018), is not appropriate here. In fixed‐parameter asymptotics, the true parameter θ is kept fixed while sample size n increases to infinity. At this point, it seems fitting to repeat a warning issued a while ago by p. 153 Hajek (1971):


“Especially misinformative can be those limit results that are not uniform. Then the limit may exhibit some features that are not even approximately true for any finite n … ”


In fact, in the presence of model selection, fixed‐parameter asymptotic results not only can, but actually often will, mislead as has been amply documented in Leeb and Pötscher (2005, 2006a,b, 2008a,b,c), Pötscher (2009), Pötscher and Leeb (2009), Pötscher and Schneider (2009, 2011). This is also the case here: We shall provide a uniform asymptotic analysis which reveals the misleading character of the pointwise asymptotic result above and in Theorem 1 of Li et al. (2018). To this end we have to amend the notation a bit: For given sample size n, true regression parameter θ∈ℝp, and variance parameter σ2∈(0,∞) we shall write Pn,θ,σ2 for P to emphasize its dependence on the quantities indicated; similarly we shall write m*(θ) to denote the smallest correct model for the parameter θ. [That is, Pn,θ,σ2 and m*(θ) replace the symbols P and m* used in Li et al. (2018).] Conditions (A.1) and (A.2) then become Pn,θ,σ2(mˆ≠m*(θ))=o(1) and Pn,θ,σ2(mˆ(b)≠mˆ)=o(1), respectively. Compared to Proposition 1 (and Theorem 1 of Li et al. (2018) we also add a mild condition on the design matrix X.


Proposition 2 Assume (A.1) and (A.2) hold (for every θ∈ℝp and every σ2∈(0,∞)), and assume that the sequence of matrices X′X/n is bounded.

(a) Then for every σ2∈(0,∞) we have  (1) infθ∈ℝpPn,θ,σ2(m˜L⊆m*(θ)⊆m˜U)=o(1) as n→∞. In other words, the minimal coverage probability of the MCS defined by m˜L and m˜U converges to zero. Moreover, assuming (A.1) only, this statement continues to hold if m˜L and m˜U are both replaced by mˆ.

(b) Part (a) also holds if we replace m˜L by mˆL and m˜U by mˆU (where the number of bootstrap replications B may depend on n).





  (a) Without loss of generality we may assume that the probability space underlying Pn,θ,σ2 is given by ℝn×Mall, where ℝn acts as the sample space for the data Y and Mall is the set of all models (and the σ‐field is the product of the Borel’σ‐field on ℝn with the power‐set of Mall). The probability measure Pn,θ,σ2 can then be viewed as given by 
 (2) Pn,θ,σ2(A)=∑m∈Mall∫ℝnIA(y,m)Kn(y,m)dQn,θ,σ2(y)  where Qn,θ,σ2 is the probability measure on ℝn defined by the N(Xθ,σ2In)‐distribution, Kn(y,m) is the bootstrap distribution on Mall (i.e., corresponds to a Markov‐kernel from ℝn to Mall), and IA is the indicator function of A. Now, choose an arbitrary constant γ>0 and a vector θ(0)∈ℝp such that at least one coordinate of θ(0) equals zero. By Proposition 1, we have Pn,θ(0),σ2(m˜L=m˜U=m*(θ(0)))=1+o(1). For each n, choose θ(n)∈ℝp so that m*(θ(n))≠m*(θ(0)) and so that ‖θ(n)−θ(0)‖≤γ/n. (E.g., obtain θ(n) from θ(0) by adding γ/n to one of the coordinates of θ(0) that are equal to zero.) Because the sequences of measures Pn,θ(0),σ2 and Pn,θ(n),σ2 are mutually contiguous (see below), it follows that Pn,θ(n),σ2(m˜L=m˜U=m*(θ(0)))=1+o(1). By construction, we have m*(θ(0))≠m*(θ(n)), and hence Pn,θ(n),σ2(m˜L⊆m*(θ(n))⊆m˜U)=o(1). [Mutual contiguity of Pn,θ(0),σ2 and Pn,θ(n),σ2 is seen as follows: Qn,θ(0),σ2 and Qn,θ(n),σ2 are well‐known to be mutually contiguous, see, e.g., Lemma A.1 in Leeb and Pötscher (2006b) and note that this lemma, while given for the case σ2=1, obviously extends to any σ2>0. The claim then follows from Lemma 3.6 in Leeb and Pötscher (2006b).]

(b) Completely analogous, where now Mall is replaced by the B‐fold Cartesian product (Mall )B, IA(y,m) and Kn(y,m) are replaced by IA(y,m1,…,mB) and Kn(y,m1,…,mB), respectively, and where the latter represents the bootstrap distribution of a bootstrap sample of size B. □




Proposition 2 shows that the proposed MCS does not perform as desired in that the worst‐case coverage probability tends to zero, and not to the nominal coverage probability 1−α. It also shows that the fixed‐parameter asymptotic setting used in Theorem 1 of Li et al. (2018) and in Proposition 1 paints a misleadingly optimistic picture of the actual performance of the MCS procedure. This is in line with similar findings in the context of inference post‐model‐selection reported earlier in Leeb and Pötscher (2005, 2006a,b, 2008a,b,c), Pötscher (2009), Pötscher and Leeb (2009), Pötscher and Schneider (2009, 2011). In fact, the final claim in Part (a) of Proposition 2 can be easily read‐off from results concerning model selection probabilities already given in these references (for a start see, e.g., Section 2.1 of Leeb and Pötscher (2005)).

The proof of Proposition 2 reveals that this result continues to hold if the infimum over θ∈ℝp in (1) is further restricted, even in a sample‐size dependent (e.g., shrinking) way, as long as the infimum at sample size n is taken over a set containing a point ϑ(n) so that the sequence ϑ(n) has the same properties as the sequence θ(n) that is used in the proof. Also, under assumptions (A.1) and (A.2), a result similar to Proposition 2 continues to hold in sufficiently smooth parametric models (as long as the contiguity argument used in the proof goes through). This, of course, also covers regression models with stochastic regressors.

Proposition 2 is an asymptotic result. To illustrate its import for finite‐sample situations we performed a small simulation study extending some of the results presented in Li et al. (2018). Data was generated as described in Section 5 of Li et al. (2018). In particular, we consider scenario (c) of Section 5.1 of that paper with the only difference that we consider not only one but several values for the parameter vector θ. More precisely, we set B=1000, n=300, p=15, p*=6, σ2=1, ρ=0.5, θ1=…,θp*−1=1, and vary θp* through the values θp*=0.05,0.1,0.2,0.3,0.4,0.5,1,2. Note that m*={1,…,p*}. The nominal confidence level was set to 90%, i.e., α=0.1. The SCAD, Lasso, minimum BIC, and minimum AIC were used as model selectors. We used the residual bootstrap for SCAD, BIC, and AIC, and the modified residual bootstrap for Lasso. Descriptions of the bootstrap algorithms are provided in Section 1.3 of the supplementary material of Li et al. (2018).

For each of the eight different values of θ listed above and for each of the four model selectors, we generated 200 response vectors Y(i), obtained (mˆL(i),mˆU(i)), and computed an estimate for the coverage probability via  CPθ=(1/200)∑i=1200I(mˆL(i)⊆m*⊆mˆU(i)). Let CP* denote the minimum of the CPθ‐values when θ varies through the eight values mentioned above. This results in an estimate of a (loose) upper bound for the worst‐case coverage probability for each of the four model selection procedures considered. [Of course, we could have searched more thoroughly over the parameter space for θ to get a smaller upper bound for the worst‐case coverage probability, but this would require a much higher investment in computational resources (including a second‐stage simulation correcting downward bias resulting from searching for the minimum). Searching only over eight values of θ, as we do here, incurs only a, for our purpose, negligible bias. The rough upper bound CP* we obtain is good enough to make our point.] We summarize the values of CP* for the four procedures in the subsequent table:
	
BIC
	
SCAD
	
AIC
	
LASSO
	

CP*
	
0.45
	
0.16
	
0.92
	
0.94
	
John Wiley & Sons, Inc.


The result for CP*, when the consistent model selection procedure minimum BIC is used, is in good agreement with Proposition 2, as CP* is much smaller than the nominal confidence level 0.9. [In additional simulations for model selection by minimum BIC using other values of θ we even have found values of CPθ as small as 0.06.] Also, for SCAD the observed CP* is much smaller than 0.9. [Following Li et al. (2018) we have chosen the tuning parameter via crossvalidation. Li et al. (2018) do not show that this results in a consistent model selection procedure, and probably it does not. However, we have not investigated this issue. If the so‐tuned SCAD is not a consistent model selection procedure, then Proposition 2 strictly speaking does not apply. Nevertheless, the simulations show that the worst‐case coverage probability can be way below the nominal one.] For the minimum AIC procedure, as well as for Lasso, the observed CP* is about right. Since minimum AIC is not a consistent, but rather a conservative, model selection procedure, Proposition 2 does not apply; probably the same is true for Lasso given the tuning used. [Again the tuning parameter for Lasso has been chosen via crossvalidation. Li et al. (2018) do not show that this results in a consistent model selection procedure, and probably it does not. We have not investigated this issue any further.] Of course, this is not to say that the worst‐case coverage probability for both of these procedures is in any way guaranteed to be close to the nominal one; it could also be that a more exhaustive search over the parameter space would have turned up a much lower worst‐case coverage probability also for these procedures.

The above discussion shows that the proposed MCS has substantial defects when used with consistent model selection procedures. It leaves open the possibility that the MCS procedure suggested by Li et al. (2018) may have merit for some conservative model selection procedures; however, as no theoretical support for this is presented in Li et al. (2018), this still needs to be investigated. Another possible route for research is to consider alternative asymptotic scenarios where, e.g., the number of parameters increases with sample size. Problems of prediction following model selection have been successfully tackled in such a framework, see Leeb (2008, 2009) and Steinberger and Leeb (2019).
==== Refs
References


Hajek , J. 

(1971 ).
Limiting properties of likelihoods and inference . 
In Godambe, V. P. and Sprott, D. A., Eds, Foundations of Statistical Inference: Proceedings of the Symposium on the Foundations of Statistical Inference, University of Waterloo, Ontario, March 31–April 9, 1970, 142–162. Toronto, Canada: Holt, Rinehard and Winston.



Leeb , H. 

(2008 ).
Evaluation and selection of models for out‐of‐sample prediction when the sample size is small relative to the complexity of the data‐generating process .
Bernoulli 
14 , 661 –690 .



Leeb , H. 

(2009 ).
Conditional predictive inference post model selection .
Ann Statist 
37 , 2838 –2876 .



Leeb , H. 
 and

Pötscher , B. M. 

(2005 ).
Model selection and inference: Facts and fiction .
Economet Theory 
21 , 21 –59 .



Leeb , H. 
 and

Pötscher , B. M. 

(2006a ).
Can one estimate the conditional distribution of post‐model‐selection estimators? 
Ann Statist 
34 , 2554 –2591 .



Leeb , H. 
 and

Pötscher , B. M. 

(2006b ).
Performance limits for estimators of the risk or distribution of shrinkage‐type estimators, and some general lower risk‐bound results .
Economet Theory 
22 , 69 –97 . Corrigendum ibid. 24, 581–583, 2008.



Leeb , H. 
 and

Pötscher , B. M. 

(2008a ).
Can one estimate the unconditional distribution of post‐model‐selection estimators? 
Economet Theory 
24 , 338 –376 .



Leeb , H. 
 and

Pötscher , B. M. 

(2008b ).
Model selection . In Andersen, T. G., Davis, R. A., Kreiß, J.‐P., and Mikosch, T., Eds, Handbook of Financial Time Series, 785–821. New York, NY: Springer.



Leeb , H. 
 and

Pötscher , B. M. 

(2008c ).
Sparse estimators and the oracle property, or the return of Hodges’ estimator .
J Econometrics 
142 , 201 –211 .



Li , Y. 
,

Luo , Y. 
,

Ferrari , D. 
,

Hu , X. 
, and

Qin , Y. 

(2018 ).
Model confidence bounds for variable selection .
Biometrics . Forthcoming.



Pötscher , B. M. 

(2009 ).
Confidence sets based on sparse estimators are necessarily large .
Sankhya 
71 , 1 –18 .



Pötscher , B. M. 
 and

Leeb , H. 

(2009 ).
On the distribution of penalized maximum likelihood estimators: The LASSO, SCAD, and thresholding .
J Multivariate Anal 
100 , 2065 –2082 .



Pötscher , B. M. 
 and

Schneider , U. 

(2009 ).
On the distribution of the adaptive LASSO estimator .
J Statist Plann Inference 
139 , 2775 –2790 .



Pötscher , B. M. 
 and

Schneider , U. 

(2011 ).
Distributional results for thresholding estimators in high‐dimensional Gaussian regression models .
Electron J Statist 
5 , 1876 –1934 .



Steinberger , L. 
 and

Leeb , H. 

(2019 ).
Prediction when fitting simple models to high‐dimensional data .
Ann Statist 
47 , 1408–1442


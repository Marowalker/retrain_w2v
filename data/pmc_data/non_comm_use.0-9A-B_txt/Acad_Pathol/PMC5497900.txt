
==== Front
Acad PatholAcad PatholAPCspapcAcademic Pathology2374-2895SAGE Publications Sage CA: Los Angeles, CA 10.1177/237428951665907910.1177_2374289516659079Regular ArticlesCommunicating Uncertainty in Surgical Pathology Reports A Survey of Staff Physicians and Residents at an Academic Medical CenterBracamonte Erika MD1Gibson Blake A. BS, BA1Klein Robert MD1Krupinski Elizabeth A. PhD, FATA, FSIIM, FSPIE2Weinstein Ronald S. MD, FCAP, FATA11 Department of Pathology, University of Arizona College of Medicine, Tucson, AZ, USA2 Department of Radiology and Imaging Sciences, Emory University, Atlanta, GA, USARonald S. Weinstein, Department of Pathology, University of Arizona College of Medicine, 1501N Campbell Ave, PO Box 245108, Tucson, AZ 85724, USA. Email: rweinstein@telemedicine.arizona.edu25 7 2016 Jan-Dec 2016 3 237428951665907904 5 2016 17 6 2016 18 6 2016 © The Author(s) 20162016SAGE Publications Inc.This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).In order to document perceptions of text comments appearing in surgical pathology reports, questionnaires were distributed to 4 groups of caregivers: university staff pathologists, resident pathologists, faculty clinicians (other than pathologists), and resident clinicians at a teaching hospital. Results of this pilot study showed a wide degree of variability existed within each group of surgical pathology report users, with respect to percent confidence assigned to various phrases, commonly used to express diagnostic uncertainty, appearing often as free-text comments in surgical pathology reports. The unavailability of immunohistochemistry tests, or ambiguous immunohistochemistry test results, was especially problematic. With respect to modes of communication between the surgical pathology laboratory and its service users, clinicians indicated they preferred to use tumor boards/interdisciplinary conferences, face-to-face meetings, and phone calls to clarify their interpretations of a pathologist’s diagnoses, as compared with simply reading free-text comments. On the other hand, surgical pathologists rely heavily on their use of the comment portion of a surgical pathology report to clarify, modify, or expand on the diagnoses they render. The majority of clinicians stated that they “always” read the free-text comment portion of a surgical pathology report, whereas some acknowledged they do not always read it. Pathology residents had significantly less confidence in the ability of a free-text comment on a surgical pathology report to clarify a diagnosis (χ2 = 46.36, P < .0001). Pathology departments should consider standardizing definitions and weighting the words and phrases they use in their free-text comment sections of surgical pathology reports.

diagnostic accuracyfree-text commentshuman performance studiesinterobserver variabilitymedical errorsquality measuressurgical pathology reportscover-dateJanuary-December 2016
==== Body
Introduction
A surgical pathologist renders both qualified and unqualified diagnoses. Tissue is taken from the patient, processed into histopathology slides, and then examined for such features as tissue architecture and cellular morphology using a light microscope. The results of the pathologist’s examination of histopathology slides are then reported to the clinicians in a written surgical pathology report. The primary goal of such reports is to communicate a diagnosis, called a “line diagnosis.”

To expand on the line diagnoses and, when appropriate, communicate uncertainty regarding a diagnosis, a pathologist can insert qualifying comments into the free-text comment (FTC) section of a surgical pathology report, for example, “we favor a diagnosis of adenocarcinoma.” This communicates some level of uncertainty in the diagnosis by the surgical pathologist to the reader of the report. Such an FTC could add value to a surgical pathology report by clarifying or amplifying the surgical pathologist’s interpretation, or if misinterpreted vis-à-vis the surgical pathologist’s intentions, potentially distort the message the surgical pathologist had intended to communicate. In teaching hospitals, training on the interpretation of surgical pathology reports by clinicians is distinctly uncommon or nonexistent.

Another use for an FTC on a surgical pathology report is to provide the pathologist with the opportunity to further discuss factors affecting a case-specific situation. For example, the comment may state, “due to the samples’ small size, we cannot confidently rule out carcinoma.” Any one of a number of factors could contribute to a pathologist being unable to render an unequivocal diagnosis including unusual histomorphology, ambiguous immunohistochemical staining results, lack of clinical information, uncertain criteria for diagnosis in the medical literature, lack of experience, or a desire to avoid encumbering legal liability from a medical error.1


Although there have been studies in radiology to examine the terminology used to convey diagnostic certainty in radiologist’s reports,2-7 to date, few studies have attempted to examine surgical pathologists’ objectives and attitudes in terms of “percent certainty” implied by specific phrases that serve as modifiers or adjuncts to common line surgical pathology diagnosis. How various diagnostic scenarios might set limitations on a surgical pathologist’s ability to have, and to communicate, various levels of certainty via FTCs remains an open question.

Methods
This study received a waiver from the institutional review board.

Phase 1
In the first phase of this study, an anonymous 10-question survey was handed out to staff surgical pathologists and pathology residents during departmental meetings. Participation was voluntary, and participants were not compensated. Participants were asked to rate their estimated “degree of certainty (percent certainty)”8,9 associated with 7 commonly used diagnostic terms at the University of Arizona Medical Center, Tucson, Arizona. The 7 diagnostic phrases queried are listed in Table 1.

Table 1. Common Surgical Pathology Phrases.

1. “… these features are diagnostic of …”	
2. “… these features are consistent with …”	
3. “… we favor …”	
4. “… features are suggestive of …”	
5. “… features are suspicious for …”	
6. “… features are compatible with …”	
7. “… features are such that we cannot rule out …”	
The questionnaire included 2 scenario questions and 1 qualitative question related to the utility of a comment in a pathology report. The 2 scenario questions were: (1) When hematoxylin and eosin (H&E) morphology is difficult to interpret, what is the maximum percent certainty in a diagnosis one can have if immunohistochemistry (IHC) is not available? and (2) When H&E morphology is difficult to interpret, what is the maximum percent certainty you can have if the IHC is performed, but the results do not conform to expectation? (eg, IHC stains are negative, when you expect it to be positive, or vice versa)?

The qualitative question was: To what extent does a comment allow you to clarify a line diagnosis that is not pathognomonic (completely characteristic of a particular disease)? The responses for this question were rated on a qualitative scale: “not at all,” “somewhat,” “well,” or “very well.”

All questions needed to be answered to be included in the analyses. Four attending pathologists and 10 pathology residents completed the questionnaire.

Phase 2
In phase 2 of the study, an anonymous questionnaire was given to clinician staff physicians (ie, attending physicians) and clinical residents at interdisciplinary tumor boards or conferences. Participation was voluntary and without compensation. Each questionnaire included the 7 diagnostic phrases used in phase 1 questionnaire. Additionally, there were 5 questions that asked respondents to rate how well tumor boards/interdisciplinary meetings, a phone call with a pathologist, a face-to-face meeting with a pathologist, an e-mail with a pathologist, or text messaging with a pathologist can clarify a diagnosis. The responses were rated on a qualitative scale: “not at all,” “somewhat,” “well,” and “very well.” The final question asked, “how often do you read the comment portion of a pathology report?” The choices were “never,” “sometimes,” or “always.”

All questions had to be answered to be included in the analyses. Only complete questionnaires, with responses to all questionnaire questions, were included in the analysis. Eighteen nonpathologist attending physicians and 16 nonpathology clinical resident physicians completed the questionnaire.

Results
The average percent certainty and range of responses to specific descriptive phrases commonly used in surgical pathology demonstrated wide ranges of responses for each of the 7 common FTC descriptive phrases, for all 4 categories of respondents (Figures 1

-4). This supports the hypothesis that there is little consensus among staff pathologists, clinicians, and residents as to percent certainty communicated by various common phrases used in FTC areas of surgical pathology reports. For phrases that tend to convey the most certainty, such as “diagnostic of,” there exists a narrower range of disagreement as to its meaning. Words, such as “favor”, or phrases, such as “suspicious for,” which communicate a greater level of uncertainty, are more variable in their implication for different individuals. The phrase “compatible with,” could mean as low “as 10 percent certainty” for 1 staff pathologist to “as high as 90 percent certainty” for a different staff pathologist. Staff clinicians and nonpathology (ie, clinical) residents (Figures 3 and 4) demonstrated a wide range of interpretations for most free-text common phrases.

Figure 1. Staff pathologists free-text comments, percent certainty assigned to specific terms (n = 4 respondents). Black vertical lines represent range of responses. Blue triangles represent means. Y-axis: percentages.

Figure 2. Pathology residents free-text comments, percent certainty assigned to specific terms (n = 10 respondents). Black vertical lines represent range of responses. Blue triangles represent means. Y-axis: percentages.

Figure 3. Clinical staff free-text comments, percent certainty assigned to specific terms (n = 18 respondents). Black vertical lines represent range of responses. Blue triangles represent means. Y-axis: percentages.

Figure 4. Clinical residents free-text comments, percent certainty assigned to specific terms (n = 16 respondents). Black vertical lines represent range of responses. Blue triangles represent means. Y-axis: percentages.

An analysis of variance (ANOVA) was carried out on each of the 7 diagnostic phrases to determine whether there were significant differences between the 4 groups of respondents. Although the sample sizes within each group limited the power to attain statistical significance, there were some interesting potential trends (Table 2) in the means.

Table 2. Analysis of Variance (ANOVA) for 7 “Uncertainty” Phrases.*

Surgical Pathology Report Phrase*	Pathology Attending	Pathology Resident	Clinical Attending	Clinical Resident	
F
	
P Value	
“… diagnostic of …”	97.50†
	95.30	97.22	94.94	0.460	.7119	
“… consistent with …”	71.25	80.00	84.33	78.75	0.998	.4029	
“… we favor …”	65.00	67.50	59.56	60.94	0.572	.6364	
“… suggestive of …”	45.00	62.50	52.50	51.56	1.222	.3129	
“… suspicious for …”	52.50	54.00	45.00	47.19	0.484	.6951	
“… compatible with …”	47.50	69.50	58.33	57.19	1.101	.3588	
“… cannot rule out …”	43.75	41.50	35.56	28.13	1.007	.3987	
*See Table 1.


†Mean values (see Table 1).

Responses to the 2 scenario questions revealed a spectrum of attitudes with respect to the effects of IHC on line diagnosis certainty (Figures 5 and 6). Staff pathologists (Figure 5) responded that if IHC was not available in a nonspecific clinical scenario, it could limit the maximal percent certainty one could have in a surgical pathology diagnosis to 20% to 98%. If IHC was performed, but with contradictory results, the range of maximal percent certainty for a diagnosis was 10% to 98%. Pathology residents (Figure 6) felt that if IHC was not available in a nonspecific clinical scenario, it could limit the maximal percent certainty achievable to 10% to 80%. If IHC was performed, but with contradictory results (ie, the H&E diagnosis and IHC suggested diagnosis was discrepant), maximal percent certainty of the diagnosis ranged from 0% to 90%. In both scenarios, resident confidence was trending lower than pathology staff confidence but not significantly (IHC not available: F = 0.230, P = .6415; IHC contradictory: F = 0.207, P = .6579).

Figure 5. Staff pathologists, percent certainty assigned to results for immunohistochemistry (IHC) scenarios (n = 4 respondents). Black vertical lines represent range of responses. Blue triangles represent means. Y-axis: percentages.

Figure 6. Pathology residents, percent certainty assigned to results for immunohistochemistry (IHC) scenarios (n = 10 respondents). Black vertical lines represent range of responses. Blue triangles represent means. Y-axis: percentages (n = 16 respondents).

With respect to preferences in communication channels regarding notes on surgical pathology reports, clinical staff and nonpathology residents preferred tumor boards and face-to-face conversations for their consultations (Figures 7 and 8). Nearly all respondents found that tumor boards/interdisciplinary conferences, phone call, or face-to-face meetings could clarify a diagnosis “very well” or “well.” The majority of staff clinicians felt that e-mail and text message could clarify a diagnosis “well.” In contrast, the majority of nonpathologist resident clinicians felt e-mail or text message could only “somewhat” clarify a diagnosis. For these residents, texting was a “not at all” solution. The ANOVA revealed no significant differences for each communication channel between clinical staff and clinical residents, although some differences may represent trends.

Figure 7. Clinical staff, preferred modes for communication (n = 18 respondents).

Figure 8. Clinical residents, preferred modes for communication (n = 16 respondents).

It is noteworthy that only 72% of attending clinicians “always” read the comment portion of a pathology report (Figure 9). The remaining 28% did so “sometimes.” Fifty percent of resident clinicians read the comment “always,” and the other half indicated that they did so “sometimes” (Figure 10). However, this difference was not statistically significant.

Figure 9. Clinical staff, clarifications by surgical pathology report free-text comments (n = 18 respondents).

Figure 10. Clinical residents, clarification by surgical pathology report free-text comments (n = 16 respondents).

Of the attending pathologists surveyed, 75% indicated that they believed a surgical pathology report FTC had the potential to clarify a diagnosis “very well” (Figure 11). The lowest percent certainty, among pathologists, of the ability for an FTC to clarify a diagnosis was 25%. Pathology residents had less confidence in the ability for a comment on a surgical pathology report to clarify a diagnosis with the pathology residents expressing a wider range in responses. Thirty percent believed an FTC can clarify a diagnosis “very well,” 60% “well,” and 10% “somewhat” (Figure 12). This difference in the distribution of responses for staff pathologists versus pathology residents was statistically significant (χ2 = 46.36, P < .0001).

Figure 11. Staff pathologists, effectiveness of “clarification” by free-text comments on surgical pathology reports (n = 4 respondents).

Figure 12. Pathology residents, effectiveness of “clarification” by free-text comments on surgical pathology reports (n = 10 respondents).

Discussion
A previous British study showed that there was variability in the intended level of certainty communicated using a 1 to 5 scale for the 13 most common diagnostic phrases used at a British hospital.10 Another study found wide variability in the percent certainty of 7 diagnostic phrases by clinicians, pathology attendings, pathology residents, and medical students.11 Pathologists’ individual preferences for specific diagnostic phrases were examined in a study of veterinarian pathologists’ performances, which found 79 unique diagnosis phrases in use.12 This variability was associated with such factors as the implications of the diagnosis and pathologists’ prior experience in diagnostic pathology. Generally, there appears to be variability among the average perceived percent certainty for nearly any given phrase communicated in a medical report.1 A possible confounding factor is that there is even variability in the recall of the content of reports by clinicians. In 1 study, 30% of surgeons and surgery residents answered incorrectly when presented with an open-book examination-style questionnaire about the contents of the anatomic pathology reports they had recently seen.13 Thus, previous studies have demonstrated that a high degree of variability exists in both the uses of diagnostic phrases in surgical pathology reports and the interpretation of the meaning of the report to the reader.

Consistent with previous studies, our results showed pathologist and clinicians’ interpretations of phrases can vary widely, even when the descriptive terms are clearly communicated by FTCs.1,11 The mean level of certainty for staff pathologists and pathology residents for each phrase was approximately the same for many FTC words and phrases. For example, for the phrase “we favor,” staff pathologists averaged 65 percent certainty and pathology residents averaged 67.5 percent certainty. However, wide differences in ranges of percent certainty were apparent. For example, pathology residents felt “we favor” could mean that the surgical pathologist’s level of certainty fell in a 50% to 80% range. In contrast, staff pathologists indicated “we favor” could mean as low as 25 percent certainty or as high as 85 percent certainty. The ranges of responses for staff pathologists tended to be broader than the ranges of responses for pathology residents for most of the phrases examined in this study (compare Figures 1 and 2). This supports the notion that the ranges of variability for percent certainty for surgical pathology diagnoses expressed by residents could have the potential to be altered during training as the pathology residents learn which diagnostic phrases to use, in what context, and additional nuisances in the uses of the terms. Studies of larger numbers of residents, in each year of training, are needed to determine whether resident’s percent certainty is influenced by years of training, as has previously been documented by us for visual search strategies.14,15


Immunohistochemistry results had a variable impact on pathologist’s ability to have certainty in a diagnosis (Figures 5 and 6). An unavailable IHC, or IHC result that is contradictory, had the potential to drop the certainty in a diagnosis to 10%, or lower, for some pathology residents and pathology staff members.

Clinicians appeared to have clear preferences in the ways they communicate with a pathologist (Figures 7 and 8). Staff clinicians and residents generally agreed that tumor boards/interdisciplinary conferences, face-to-face meetings, and phone calls were the best ways to clarify a diagnosis. A sizeable portion of resident clinician respondents reported e-mail or text message to be “somewhat” or “not at all” beneficial at clarifying a diagnosis. Interestingly, this opinion was not shared by staff clinicians, the majority of whom maintained that e-mail or text message could clarify a diagnosis “well.”

Our data showed that pathologists rely heavily on the diagnosis comments used to clarify the level of uncertainty (Figure 8) and to further communicate important diagnostic information. On the other hand, our data supported the notion that clinicians did not always read surgical pathology report comments. Nonpathology residents were even worse, claiming to read pathology report FTCs only “sometimes” (Figure 9). However, as previous work has shown, a comment contextualizing the diagnosis, its level of certainty, and other differential diagnosis possibilities may be insufficient to overcome recall inaccuracy, let alone variability in the uses of diagnostic phraseology.13


One limitation of this study was introduced by the scenarios presented in the survey. In an attempt to be purposefully general, but meaningfully specific, little context was given in the scenarios. Thus, a pulmonary pathologist might imagine a widely different scenario of incongruent IHC, or nonexistent IHC, than a dermatopathologist. This likely contributed to the lack of consensus for how much certainty IHC can give, or take away, in each scenario. Additionally, for reasons of anonymity, no differentiation was made in the IHC surveys between residents and staff. It is plausible, as found in 1 study12 but not replicated in another,1 that experience may influence both the mean percent certainty and the variability in responses expressed among peers.

Interestingly, few respondents felt that one could ever be 100 percent certain. Although this is an interesting philosophical point, there is a practical legal aspect to this belief. The fear of the legal ramifications of over or under communicating a diagnosis may affect a pathologist’s interpretation and use of diagnostic phrasing.

On a fundamental level, the differences found among pathologists and clinicians do not imply that 1 group is right or that resident understanding is lacking. The College of American Pathologists and other advisory bodies have yet to standardize diagnostic phrasing. An individual’s training, personality, proficiency in the English language, location, and coworkers are all factors that might affect one’s understanding and use of diagnostic phrases.

Surveys can demonstrate the wide range in understanding for each diagnostic phrase, as confirmed in this study. This “variability in interpretation” problem might be partially overcome by writing a key conveying the relative level of certainty each phrase might have. For example, a key could say: “diagnostic of” > “compatible with” > “suspicious for.” This way, the examining pathologist, and the interpreting clinician, could quickly reference what each diagnostic phrase means in terms of the relative level of certainty it conveys. On the other hand, if additional physician–pathologist communication is needed to clarify the pathologist’s intended meaning in FTCs, perhaps more descriptive FTCs are preferable as the standard of care.

To establish such a key, national organizations could reach a consensus on the percent certainty a given diagnostic phrase can denote. This could help standardized pathology reports. This also might make the words used in line diagnosis more uniform and more clearly understood by the reader of the report. Hopefully, pathology residents would become more adept in their phraseology, using specific words appropriate to specific situations. This might not only increase their accuracy in communicating results but also stimulate educational opportunities to discuss why a specific histopathology meets, or fails to meet, certain thresholds needed for definitive diagnoses. As things currently stand, the interpretation of any particular “uncertainty phrase” is so variable and exhibits such overlap among respondents that each particular phrase ends up not really meaning anything other than “not sure.”

In order to do their part in decreasing this variability, academic pathology departments might consider standardizing their usage of phraseology in surgical pathology reports and providing formal training to house staff, as well as faculty if needed, on how to read and interpret free text within pathology reports. This training of house staff could be an important intervention at a formative time in clinician career development that could improve the widely variable outcomes that we report.

The Association of Directors of Anatomic and Surgical Pathology (ADASP) could have a special role in studying, and suggesting remedies for, this inconsistency problem. The ADASP is currently examining issues related to the ongoing building of health networks and how new intranetwork relationships among various individual institutions’ anatomic pathology practices are managed. We suggest that developing strategies to standardize and disseminate rules for the creation, and interpretation, of FTCs of pathology reports be on their list of topics needing stakeholder input and reconciliation.

There are critical limitations to this study which we acknowledge. We emphasize that this was a small pilot study, which was carried out at a single academic institution. Numbers of conferences at which participants were queried were few in number. Numbers of participants in each category were variable but, generally, relatively small. With regard to this, it is also noteworthy that there was a large amount of overlap between ranges of responses for the pathology staff and the clinical staff (compare Figures 1 and 3). There appeared to be less overlap in the ranges of responses for pathology residents as compared to clinical residents (compare Figures 2 and 4.) The ranges of responses were narrowest for the pathology residents (Figure 2).

Other factors may have influenced the specific results, although not necessarily the trends. At a single academic clinical conference, such as a tumor board conference, complex cases may include surgical pathology reports that were generated by several independent pathology laboratories, such as a community hospital laboratory and a reference laboratory. Under those circumstances, the mix of laboratory results, and their sources, could influence levels of uncertainty among the clinicians. In addition, specialty pathologists in academic medical centers and their clients in a nonacademic clinical environment may have differing experiences, use, and interpretations of free-text phrases. Also, the usefulness of face-to-face communication may be different since the opportunities to participate in tumor boards, and other direct interactions, may be less frequent, or may not exist at all, in community practice or for those pathologists practicing exclusively in commercial laboratories. Future studies also should address the role/effect of clinical information and the context of cases in influencing levels of certainty.

Finally, the results of this study should be interpreted and discussed within the context of a clinical culture of respect and humility.16 The full spectrum of “professional uncertainty,” ranging from ignorance through ambiguity up to knowledge and truth, is purposefully represented in the foundations upon which good medical practices rest. Consensus often only approximates truth even in ideal clinical settings. Curiosity, ambivalence, and skepticism each may influence ambiguity in its own particular way. Nevertheless, the wise clinical management of uncertainty is achievable and, fortunately, is apparent in high-quality medical practices even today.

Authors’ Note: All of the authors had access to the data and a role in writing the manuscript.

Declaration of Conflicting Interests: The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.

Funding: The author(s) received no financial support for the research, authorship, and/or publication of this article.
==== Refs
References
1 
Lindley SW Gillies EM Hassell LA  
Communicating diagnostic uncertainty in surgical pathology reports: disparities between sender and receiver . Pathol Res Pract . 2015 ;210 :628 –633 .
2 
Khorasani R Bates DW Teeger S Rothschild JM Adams DF Selyzer SE  
Is terminology used effectively to convey diagnostic certainty in radiology reports? 
Acad Radiol . 2003 ;10 :685 –688 .12809424 
3 
Clinger NJ Hunter TB Hillman BJ  
Radiology reporting: attitudes of referring clinicians . Radiol . 1988 ;169 :825 –826 .
4 
Sobel JL Pearson ML Gross K  
Information content and clarity of radiologists’ reports for chest radiography . Acad Radiol . 1996 ;3 :709 –717 .8883510 
5 
Bastuji-Garin S Schaeffer A Wolkenstein P  
Pulmonary embolism: lung scanning interpretation—about words . Chest . 1998 ;114 :1551 –1555 .9872187 
6 
Kenney RM  
Between never and always . N Engl J Med . 1981 ;305 (18 ):1097 –109 .
7 
Toogood JH  
What do we mean by “usually’? 
Lancet . 1980 ;1 :1094 .
8 
Antil JH  
Uses of response certainly in attitude measurement . Adv Consumer Res . 1983 ;10 :409 –415 .
9 
Tormala ZL Rucker DD  
Attitude certainty: a review of past findings and emerging perspectives . Soc Personality Psych Compass . 2007 ;1 :469 –492 .
10 
Attanoos RL Bull AD Douglas-Jones AG Fligelstone LJ Semararo D  
Phraseology in pathology reports. A comparative study of interpretation among pathologists and surgeons . J Clin Pathol . 1996 ;49 :79 –81 .8666692 
11 
Galloway M Taiyeb T  
The interpretation of phrases used to describe uncertainty in pathology reports . Pathol Res Int . 2011 ;2011 :656079 .
12 
Christopher MM Hotz CS  
Cytologic diagnosis: expression of probability by clinical pathologists . Vet Clin Pathol . 2004 ;33 :84 –95 .15195267 
13 
Powsner SM Costa J Homer RJ  
Clinicians are from Mars and pathologists are from Venus: clinician interpretation of pathology reports . Arch Pathol Lab Med . 2000 ;124 :1040 –1046 .10888781 
14 
Krupinski EA Tillack AA Richter L  
Eye-movement study and human performance using telepathlogy virtual slides. Implications for medical education and differences with experience . Hum Pathol . 2006 ;37 :1543 –1556 .17129792 
15 
Krupinski EA Graham AR Bhattacharyya AK Weinstein RS  
Characterizing the development of visual search expertise in pathology residents viewing whole slide images . Hum Pathol . 2013 ;44 :357 –364 .22835956 
16 
Domen RE  
The ethics of ambiguity: rethinking the role and importance of uncertainty in medical education and practice . Acad Pathol . 2016 ;3 .



==== Front
BMJBMJBMJ-USbmjThe BMJ0959-81381756-1833BMJ Publishing Group Ltd. sanr04819310.1136/bmj.l4109Research1779Changes in hospital safety following penalties in the US Hospital Acquired Condition Reduction Program: retrospective cohort study Sankaran Roshun medical student1 2Sukul Devraj cardiology fellow2Nuliyalu Ushapoorna statistician3 4Gulseren Baris health policy analyst1Engler Tedi A project manager1 3Arntson Emily graduate student1 2Zlotnick Hanna MPP student5Dimick Justin B George D Zuidema professor of surgery2 3 4http://orcid.org/0000-0002-2566-7763Ryan Andrew M associate professor1 3 4
1 University of Michigan School of Public Health, 1415 Washington Heights, Ann Arbor, MI 48109, USA
2 University of Michigan Medical School, Ann Arbor, MI, USA
3 Center for Healthcare Outcomes and Policy, Ann Arbor, MI, USA
4 Institute for Healthcare Policy and Innovation, Ann Arbor, MI, USA
5 University of Michigan Gerald R Ford School of Public Policy, Ann Arbor, MI, USACorrespondence to: A M Ryan amryan@umich.edu (or @andy_ryan_dydx on Twitter)2019 03 7 2019 366 l410925 4 2019 Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions2019BMJThis is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.Abstract
Objective
To evaluate the association between hospital penalization in the US Hospital Acquired Condition Reduction Program (HACRP) and subsequent changes in clinical outcomes.

Design
Regression discontinuity design applied to a retrospective cohort from inpatient Medicare claims.

Setting
3238 acute care hospitals in the United States.

Participants
Medicare fee-for-service beneficiaries discharged from acute care hospitals between 23 July 2014 and 30 November 2016 and eligible for at least one targeted hospital acquired condition (n=15 470 334).

Intervention
Hospital receipt of a penalty in the first year of the HACRP.

Main outcome measures
Episode level count of targeted hospital acquired conditions per 1000 episodes, 30 day readmissions, and 30 day mortality.

Results
Of 724 hospitals penalized under the HACRP in fiscal year 2015, 708 were represented in the study. Mean counts of hospital acquired conditions were 2.72 per 1000 episodes for penalized hospitals and 2.06 per 1000 episodes for non-penalized hospitals; 30 day readmissions were 14.4% and 14.0%, respectively, and 30 day mortality was 9.0% for both hospital groups. Penalized hospitals were more likely to be large, teaching institutions, and have a greater share of patients with low socioeconomic status than non-penalized hospitals. HACRP penalties were associated with a non-significant change of −0.16 hospital acquired conditions per 1000 episodes (95% confidence interval −0.53 to 0.20), −0.36 percentage points in 30 day readmission (−1.06 to 0.33), and −0.04 percentage points in 30 day mortality (−0.59 to 0.52). No clear patterns of clinical improvement were observed across hospital characteristics.

Conclusions
Penalization was not associated with significant changes in rates of hospital acquired conditions, 30 day readmission, or 30 day mortality, and does not appear to drive meaningful clinical improvements. By disproportionately penalizing hospitals caring for more disadvantaged patients, the HACRP could exacerbate inequities in care.
==== Body
Introduction
Reducing mortality and morbidity from hospital acquired conditions is a national priority in the United States.1 Historically, hospitals have faced limited incentives to invest in efforts to reduce these conditions, and could in fact benefit financially from certain conditions.2 The Hospital Acquired Condition Reduction Program (HACRP) was created by the US Patient Protection and Affordable Care Act to provide stronger incentives for hospitals to reduce hospital acquired conditions. Expanding on the previous Centers for Medicare and Medicare Services (CMS) policy of non-payment for these conditions, the HACRP imposes a penalty of 1% of Medicare payments on acute care hospitals whose performances on hospital acquired condition measures falls in the bottom quarter.3
4
5 In fiscal year 2015, 724 hospitals receiving payments from the CMS were penalized an estimated US$373m (£294m; €330m) for poor performance under the HACRP.3
6


However, how the receipt of a financial penalty for poor quality performance in the HACRP affects subsequent hospital behavior is poorly understood. On one hand, hospitals that are penalized might be motivated to improve through rigorous quality improvement initiatives.7 On the other hand, penalties might not alter existing efforts to improve or could reduce hospital resources for quality improvement over the longer term. Moreover, hospital characteristics that predict responsiveness to penalization under the HACRP and similar pay-for-performance programs are poorly understood.8 Recent research suggests that hospitals caring for more disadvantaged patients are more likely to be penalized under the HACRP.9 If these hospitals do not improve in response to penalization, it could lead to a long term reduction in payments, exacerbating inequities. These knowledge gaps are especially salient given the continued expansion of value based payment models in the US.10
11


In this study, we used national Medicare data to evaluate the association between a hospital’s penalty status under the HACRP and subsequent clinical performance in the first two years of the program. We also examined the hospital characteristics that were associated with penalization and performance improvement after penalization.

Methods
Data source
We used 100% Medicare provider analysis and review (MedPAR) inpatient claims data for Medicare fee-for-service beneficiaries who were discharged from acute care hospitals subject to the HACRP during the study period (fig 1). Citizens or legal permanent residents in the US are eligible for Medicare if they are 65 or older, have certain disabilities, or have end stage renal disease. Beneficiaries who are enrolled in a privately administered plan for Medicare health (and therefore not fee-for-service beneficiaries) were not included in our study.12 Hospitals’ scores for hospital acquired conditions and the list of penalized hospitals in fiscal years 2015 and 2016 were obtained from the CMS website.13 Other hospital level covariates were obtained from the CMS impact files from fiscal years 2014 and 2015, which provided information on geographical region, resident-to-bed ratio, number of beds, disproportionate share percentage (measuring socioeconomic disadvantage), case mix index (measuring patient severity), and Census Bureau statistical area designation (urban or rural). We used data from the 2012-14 annual surveys by the American Hospital Association for information on the proportion of Medicare and Medicaid days, nurse-to-bed ratio, and for-profit status. CMS Hospital Compare Data from 2014 and 2015 provided data on continuous levels of hospital performance under the HACRP.

Fig 1 Implementation of program to reduce hospital acquired conditions and study timeline. Performance period (Domain 1) ranges from 1 July 2011 to 30 June 2013. Performance period (Domain 2) ranges from 1 January 2012 to 31 December 2013. Study period ranges from 23 July 2014 to 30 November 2016. Penalty period ranges from 1 October 2014 to 30 September 2015. Penalties were announced on 23 July 2014. FY=fiscal year

Study population
The study population included all Medicare fee-for-service beneficiaries aged 65 and older who were discharged from an acute care hospital between 23 July 2014 and 30 November 2016 and who met denominator criteria for any of the hospital acquired conditions that comprise the Agency for Healthcare Research and Quality’s Patient Safety Indicator-90 composite (AHRQ PSI-90), which was targeted under the HACRP (n=15 470 334, appendix figure 1). We defined our study cohort using methods similar to those of the CMS hospital wide readmission measure. Patients were excluded from the study population if they were not enrolled in Medicare parts A and B, which cover inpatient hospital admission, outpatient care, and physician services, for 30 days after discharge; if Medicare was not the primary payer for the care episode; if the patient was transferred out of the hospital; if the patient was discharged against medical advice; or if the index admission was due to cancer treatment or the treatment of a psychiatric illness. Acute care hospitals were included if they had been assigned a total score for hospital acquired conditions in fiscal year 2015, were not located in Maryland or Puerto Rico, had data available from at least one American Hospital Association annual survey from 2012 to 2014, and had at least one eligible patient discharge during the study period. Maryland hospitals were excluded because the state is not part of Medicare’s inpatient prospective payment system, and therefore not eligible for the HACRP.

Outcomes
Our primary outcome was the number of hospital acquired conditions per patient episode. We evaluated those conditions that contributed to the AHRQ PSI-90 composite score. The composite score contributed 35% of the total hospital acquired condition score assigned under the HACRP in fiscal year 2015. Included conditions were: pressure ulcer (PSI-03), iatrogenic pneumothorax (PSI-06), central line-associated bloodstream infections (CLABSI; PSI-07), postoperative hip fracture (PSI-08), perioperative pulmonary embolism or deep vein thrombosis (PSI-12), postoperative sepsis (PSI-13), postoperative wound dehiscence (PSI-14), and accidental puncture or laceration (PSI-15). Patient safety indicators were calculated by AHRQ quality indicators software (version 6.0.2).14 We evaluated 30 day readmission and mortality as secondary outcomes.

Exposures
Hospitals with a total score for hospital acquired conditions in the worst performing quarter (score ≥7.025) received a 1% payment reduction from the CMS for all discharges occurring between 1 October 2014 and 30 September 2015. The CMS calculated these total scores using discharge data from 2011 to 2013. Hospitals were notified of their penalty status on 23 July 2014, before the start of the penalization period.15
16
17
18
19 Therefore, we included all discharges between 23 July 2014 (which marked the beginning of the review and correction period for penalized hospitals) and 30 November 2016 in our analyses (fig 1).


Study design
We used a regression discontinuity study design to investigate whether penalization was associated with improvements in the study outcomes. This design leverages the fact that hospitals immediately above and below the financial penalty threshold are unlikely to differ in ways that affect study outcomes, other than exposure to the HACRP financial penalty.20
21 These designs can therefore closely mimic randomized controlled trials under the assumption that hospitals cannot manipulate their total hospital acquired condition scores around the penalty threshold.22 Regression discontinuity designs are also resistant to confounding from regression to the mean.23


We fit separate models for each outcome of interest, estimating robust, bias corrected, treatment effects with local linear regression using data driven bandwidth selection.24 Evidence suggests that this approach provides the most reliable treatment effect estimates and confidence intervals with the best coverage in regression discontinuity designs.24
25 To examine whether hospital characteristics influenced responsiveness to penalization, we estimated stratified models across subgroups of hospitals. Subgroup analyses were performed by hospital size, disproportionate share index, case mix index,26 proportion of Medicare patient days, proportion of Medicaid patient days, nurse-to-bed ratio, for-profit status, teaching status, urbanicity, and whether the hospital was also penalized under the Hospital Readmissions Reduction Program.

We did several sensitivity analyses to support the validity of our results. Firstly, to examine whether variables other than penalization could have affected study outcomes, we performed falsification tests27 by testing discontinuities for several factors that should not be affected by the penalty threshold. These factors included hospital size (both as continuous and categorical variables), for-profit status, Medicare percentage of discharges, teaching status, and penalization status in fiscal year 2016 (appendix table 1, appendix figures 2-10). We then graphically assessed the presence of any discontinuity in the distribution of total hospital acquired condition scores around the penalization threshold, which could indicate potential manipulation of scores (fig 2).

Fig 2 Distribution of total hospital acquired condition scores under the Hospital Acquired Condition Reduction Program for first penalty period. Dashed line=penalty threshold; CMS=Centers for Medicare and Medicare Services

We also estimated alternate model specifications for each outcome using a fourth order polynomial fit and controlling for patient and hospital characteristics (appendix table 2). Total hospital acquired condition scores are a composite measure of two scores, referred to as Domain 1 (the AHRQ PSI-90 composite) and Domain 2 (the Centers for Disease Control and Prevention’s National Healthcare Safety Network healthcare-associated infection measure). We estimated models using patient discharges only from hospitals that reported both Domain 1 and Domain 2 scores under the HACRP, which differ systematically from hospitals that reported only Domain 1 scores (appendix figure 11).28 Finally, because hospitals could have focused quality improvement efforts on perioperative pulmonary embolism or deep vein thrombosis (PSI-12) and accidental puncture or laceration (PSI-15)—which are weighted most heavily in the AHRQ PSI-90 composite used to determine penalties in the first years of the HACRP—we fit models using the counts of only these two patient safety indicators as the outcome of interest (appendix figure 12).

Standard errors in all models were robust to hospital level clustering. P values were two sided with a threshold for significance of less than 0.05. All statistical analyses were conducted by use of Stata version 15 (StataCorp, College Station, TX, USA). This study was deemed exempt from review by the University of Michigan’s institutional review board.

Patient and public involvement
No patients were involved in setting the research question or the outcome measures, nor were they involved in developing plans for the design or implementation of the study. No patients were asked to advise on the interpretation or writing up of results. There are no specific plans to disseminate the results of the research to study participants or the relevant patient community.

Results
Our analytical sample included 15 470 334 discharges of patients between 23 July 2014 and 30 November 2016. Patients were eligible for at least one hospital acquired condition from 3238 hospitals. Of 724 hospitals penalized by the CMS under the HACRP in fiscal year 2015, 708 were represented in our sample.

Patients discharged from non-penalized hospitals had 2.06 hospital acquired conditions per 1000 patient episodes, while patients discharged from penalized hospitals had 2.72 conditions per 1000 patient episodes (table 1). The most common hospital acquired conditions that eligible patients experienced among all study hospitals were perioperative pulmonary embolism or deep vein thrombosis (0.91 and 1.23 per 1000 discharges for non-penalized and penalized hospitals, respectively), iatrogenic pneumothorax (0.30 and 0.36), postoperative sepsis (0.50 and 0.67), and pressure ulcers (0.15 and 0.21).

Table 1 Patient and hospital characteristics by penalization status in the Hospital Acquired Condition Reduction Program, from 23 July 2014 to 30 November 2016. 

	Non-penalized hospitals	Penalized hospitals	P value	

Patient characteristics
	
No of episodes	11 211 503	4 258 831	
—
	
Hospital acquired condition rate (No per 1000 episodes, mean (SD))	2.06 (0.05)	2.72 (0.05)	<0.001	
30 day readmission	1 567 504 (14.0)	612 243 (14.4)	<0.001	
30 day mortality	1 013 901 (9.0)	382 524 (9.0)	<0.001	
Age (years, mean (SD))	78.34 (8.78)	77.89 (8.81)	<0.001	
Female sex	6 383 169 (56.9)	2 383 862 (56.0)	<0.001	
Race of beneficiary	
 Non-white	1 583 091 (14.1)	762 318 (17.9)	<0.001	
 White	9 628 412 (85.9)	3 496 513 (82.1)	
Count of Elixhauser comorbidities (mean (SD))	3.49 (1.95)	3.50 (1.95)	<0.001	
Length of stay (mean (SD))	4.74 (4.66)	5.10 (5.56)	<0.001	

Hospital characteristics
	
No of hospitals	2530	708	
—
	
No of beds	
 <200	4 047 689 (36.1)	853 107 (20.0)	<0.001	
 200-349	3 141 064 (28.0)	1 305 761 (30.7)	
 350-499	1 997 988 (17.8)	741 298 (17.4)	
 ≥500	2 024 762 (18.1)	1 358 665 (31.9)	
Teaching status (resident-to-bed ratio)	
 Non-teaching (0.000)	6 048 786 (54.0)	1 478 803 (34.7)	<0.001	
 Very minor teaching (0.001-0.049)	1 790 524 (16.0)	471 126 (11.1)	
 Minor teaching (0.050-0.249)	2 156 753 (19.2)	1 006 948 (23.6)	
 Major teaching (0.250-0.599)	918 688 (8.2)	864 901 (20.3)	
 Very major teaching (≥0.600)	296 752 (2.6)	437 053 (10.3)	
Region	
 Northeast	2 022 531 (18.0)	1 084 081 (25.5)	<0.001	
 South	4 756 525 (42.4)	1 489 981 (35.0)	
 Midwest	2 720 144 (24.3)	924 000 (21.7)	
 West	1 712 303 (15.3)	760 769 (17.9)	
Safety net hospital*	2 171 448 (19.4)	1 281 009 (30.1)	<0.001	
Case mix index (mean (SD))	1.63 (0.25)	1.74 (0.27)	<0.001	
Urban hospital†	9 773 643 (87.2)	3 998 214 (93.9)	<0.001	
Proportion of Medicaid days (mean (SD))	0.19 (0.10)	0.22 (0.11)	<0.001	
Proportion of Medicare days (mean (SD))	0.52 (0.11)	0.47 (0.12)	<0.001	
Fourth quarter disproportionate share	2 176 269 (19.37)	1 284 993 (30.09)	<0.001	
Profit status	
 For-profit	2 008 622 (17.9)	471 728 (11.1)	<0.001	
 Not-for-profit	8 230 484 (73.4)	3 123 937 (73.4)	
 Other	972 397 (8.7)	663 166 (15.6)	
Nurse-to-bed ratio (mean (SD))	1.85 (0.64)	2.05 (0.67)	<0.001	
Penalized under HRRP fiscal year 2015‡	9 515 660 (84.9)	3 670 518 (86.2)	<0.001	
Hospitals not scored on CDC NHSN Measures	380 618 (3.4)	74 595 (1.8)	<0.001	
Hospitals scored on CDC NHSN Measures	10 830 885 (96.6)	4 184 236 (98.2)	<0.001	
Data are number or number (%) unless stated otherwise. SD=standard deviation; CDC= Centers for Disease Control and Prevention; NHSN=National Healthcare Safety Network; HRRP=Hospital Readmission Reduction Program.

* Based on Census Bureau statistical area designation.

† Two hospitals did not have Centers for Medicare and Medicare Services impact file data available for fiscal year 2015. Data for these hospitals are based on impact file data for fiscal year 2014.

‡ Continuous, normally distributed variables compared by analysis of variance; continuous, skewed variables compared by Wilcoxon rank sum test (two groups) or Kruskal-Wallis (more than two groups) test; categorical and binomial variables compared by Fisher’s exact test.

Penalized hospitals were more likely to be large, in the highest quarter for disproportionate share patients, and teaching institutions (table 1). Penalized hospitals also had a smaller proportion of inpatient days from Medicare patients, a larger proportion of inpatient days from Medicaid patients, and a higher nurse-to-bed ratio. Although they differed in aggregate, penalized and non-penalized hospitals did not differ meaningfully at the penalty threshold, as shown by falsification tests (appendix figures 2-10). These tests of covariates showed no significant discontinuity at the penalty threshold, although discontinuities in hospital size were close to significant (appendix table 1; appendix figures 2 and 6). A sensitivity analysis controlling for hospital size resulted in similar findings. (appendix table 2).


Figure 3 shows the relation between the CMS hospital acquired condition score and the study outcomes on both sides of the penalization threshold. A change in the intercept at the penalization threshold would indicate an association between penalization and the study outcome. Figure 4 shows the estimated association between financial penalization under the HACRP and each study outcome, along with estimated effects for subgroup analyses. 

Fig 3 Discontinuities in the association between Centers for Medicare and Medicare Services (CMS) hospital acquired condition score and rate of hospital acquired conditions per 1000 discharges (top), rate of readmission at 30 days (middle), and rate of mortality at 30 days (bottom). Graph shows local linear regression within data-driven bandwidths used to compute point estimates presented in Results and figure 4. Bins are evenly spaced and designed to mimic underlying variance in the data 

Fig 4 Change in rate of hospital acquired condition per 1000 discharges (top), rate of readmission at 30 days (middle), and rate of mortality at 30 days (bottom) associated with financial penalization under the Hospital Acquired Condition Reduction Program. Robust, bias corrected estimates of the treatment effect obtained through a regression discontinuity model using local linear regression and data driven bandwidth selection. Heterogeneous effects derived from subgroup analysis in which discharges were restricted to the subgroup of interest. Teaching hospitals in subgroup analyses defined as those hospitals that had residents (resident-to-bed ratio >0.00). Small hospitals defined as hospitals with fewer than 200 beds, and large hospitals defined as hospitals with more than 500 beds. Standard errors and confidence intervals were robust to hospital level clustering. P values were two sided with a threshold for significance of less than 0.05. HAC=hospital acquired condition; DSH=disproportionate share hospital; CMI=case mix index; RN=registered nurse; HRRP=Hospital Readmissions Reduction Program 

Regression discontinuity analysis showed that, overall, financial penalization under the HACRP was associated with a non-significant decrease of −0.16 hospital acquired conditions per 1000 patient episodes (95% confidence interval −0.53 to 0.20; fig 3 and fig 4). This finding was robust to alternate model specifications (appendix table 2a). Similar non-significant changes in hospital acquired condition rates were found for every hospital subgroup analyzed except for small hospitals, for which penalization was associated with change of −0.54 conditions per 1000 patient episodes (−1.03 to −0.05; fig 4). Yet these apparent improvements for small hospitals were sensitive to the choice of bandwidth (appendix tables 7-8), suggesting this finding is likely by chance.

The 30 day readmission rate was 14.0% for non-penalized hospitals and 14.4% for penalized hospitals in fiscal year 2015. Penalization under HACRP was associated with a non-significant change in readmissions of −0.36 percentage points (95% confidence interval −1.06 to 0.33; fig 3 and fig 4). This finding was also robust to alternate model specifications (appendix table 2b). Financial penalties were associated with significant reductions in 30 day readmission rates for small hospitals (−1.28 percentage points (−2.45 to −0.11)), and hospitals in the highest quarter for nurse-to-bed ratios (ratio ≥2.26; −2.20 percentage points (−3.68 to −0.71); fig 4).

Non-penalized hospitals had an average 30 day mortality rate of 9.0%, identical to that of penalized hospitals. We saw no significant association between a hospital’s penalty status and its subsequent 30 day mortality rate (−0.04 percentage points (95% confidence interval −0.59 to 0.52)), a finding that was robust to alternate model specifications (fig 3, fig 4, and appendix table 2c). Penalization was significantly associated with mortality among the lowest quarter of DSH hospitals (−1.78 percentage points (−2.74 to −0.82)), highest quarter of Medicare discharges (−1.70 (−2.51 to −0.89)), and for-profit hospitals (−2.13 (−3.71 to −0.055); fig 4). However, penalization was not associated with similar changes in HAC rates among these groups, making their mortality reductions likely to be chance findings.

Discussion
Principal findings
In this national study of the effect of the HACRP penalty on hospital acquired condition rates and other clinical outcomes using a regression discontinuity design, we report three main findings. Firstly, penalization under the program was more likely to occur for large, academic medical centers and hospitals that care for a higher proportion of disadvantaged patients. Secondly, penalization was not associated with a significant change in the rate of hospital acquired conditions. Thirdly, penalization was not associated with a significant overall change in important clinical outcomes, including 30 day readmission and 30 day mortality. While penalization was associated with a reduction in 30 day readmission and 30 day mortality for some subgroups, this finding is most likely to be by chance because the same subgroups did not show a concurrent reduction in hospital acquired condition rates. Penalization was also not associated with any clear pattern of results across different hospital characteristics. Overall, these findings suggest that financial penalties levied against hospitals performing poorly under the CMS’s HACRP have not meaningfully improved patient safety.

This study evaluates the effect of financial penalization under the HACRP on subsequent rates of hospital acquired conditions and other clinical outcomes. Pay-for-performance programs have been widely implemented throughout the world, including the Quality and Outcomes Framework in the United Kingdom,29 hospital pay-for-performance in France,30 and many others.31
32 However, we are not aware of strictly penalty based programs for patient safety programs outside of the US. Our study is consistent with previous research showing that penalties in the HACRP are more likely among major teaching hospitals and those caring for more disadvantaged patients.9 Our findings add to this literature by demonstrating that penalization does not appear to drive performance improvement in the program. Research finding that penalization was associated with improvement in the context of the Hospital Readmission Reduction Program could be biased by mean reversion; because penalties are determined in part on the basis of random noise, so-called improvement in the program could be driven by a return to hospitals’ steady state performance.33
34 Regression discontinuity designs using some form of pre-intervention outcome to determine treatment are not subject to this bias.23 This is because, in the absence of treatment, expectations for differences in post-intervention outcomes between treated and untreated units are the same, because both groups are close to the treatment threshold, or can be controlled for through statistical modeling.

Limitations
This study should be interpreted in the context of several important limitations. Firstly, while the HACRP evaluates hospitals using measures from both the AHRQ PSI-90 and the Centers for Disease Control and Prevention’s (CDC) National Healthcare Safety Network, because CDC data were not available, our study outcomes consisted only of measures included in the AHRQ PSI-90. In response to penalization, hospitals might have selectively targeted CDC measures, knowing that those were more heavily weighted under the HACRP. Nonetheless, we saw a strong correlation between patient safety indicator scores and overall hospital acquired condition scores (appendix table 3). Hospitals also varied with respect to reporting data on the CDC measures. The likelihood of reporting was correlated with hospital size, and the probability of penalization under the HACRP differs by domains reported.28 However, sensitivity analysis restricting our sample to discharges from only those hospitals that reported both Domain 1 and Domain 2 scores also found that penalization was not associated with any significant changes in rates of hospital acquired conditions. In addition, hospitals might have improved significantly on the narrow set of patient safety indicators that were most heavily weighted by the AHRQ PSI-90 composite.35 Again, sensitivity analysis found this potential bias was not the case.

It is also possible that hospitals were unable to make substantial process changes to improve rates of hospital acquired conditions in the timeframe we analyzed. However, this is unlikely for two reasons. The HACRP was announced at the beginning of fiscal year 2014, meaning that all hospitals had a full year to adapt to the program and implement changes before the first penalization period in fiscal year 2015.36 Furthermore, penalized hospitals were made aware of their impending penalization in July 2015, and our study period spanned nearly two and a half years after penalization, giving hospitals ample time to improve.

Factors other than penalization could have affected study outcomes, including participation in other value based payment reforms. Yet these reforms would only confound our results if they occurred precisely at the penalization threshold, which they did not. Another limitation was that our analysis might have been underpowered to detect heterogeneous responses to penalization. Inconsistencies among subgroup analyses of 30 day readmission and mortality support this limitation. Finally, our regression discontinuity approach indicated that penalization under the HACRP did not result in reduced rates of hospital acquired conditions, readmission, or mortality for hospitals close to the penalization threshold, but does not provide insight into the effects of penalization on hospitals that performed far below the threshold. Nonetheless, these findings show that hospitals with program performances close to the threshold, and therefore with the best chance at improving their hospital acquired condition scores in subsequent years, failed to do so in response to penalization.

Our findings that penalization under the HACRP was systematically associated with hospital characteristics but not associated with improved performance have important implications. Our study suggests the HACRP could be decreasing equity while not improving quality by penalizing hospitals caring for more disadvantaged patients.

Policy implications
The CMS should consider redesigning the HACRP to deal with two major design challenges. Firstly, instead of levying all-or-nothing penalties for hospitals performing in the bottom quarter, the CMS should consider graduated penalties for all hospitals with higher than expected rates of hospital conditions. This approach, used in the Hospital Readmission Reduction Program, is more equitable and provides incentives for improvement among a larger range of hospitals. Secondly, to improve equity, the CMS should consider modifying penalty thresholds based on hospitals’ share of disadvantaged patients. This potential change would be similar to recent reform to the Hospital Readmission Reduction Program, which established different penalty thresholds for different types of hospitals.37 Thirdly, the CMS should eliminate the financial disincentive to being scored on the CDC measures, which could be accomplished by creating separate penalty criteria according to whether hospitals are scored on the CDC measures. Fundamentally, future research should assess whether the measures used to evaluate patient safety and the design of the financial incentives in the HACRP are appropriately constructed to improve patient safety.

What is already known on this topic
Historically, hospitals have faced limited financial incentives to reduce hospital acquired conditions

Under the US Hospital Acquired Condition Reduction Program, the Centers for Medicare and Medicaid Services impose financial penalties on hospitals with the lowest safety performance (bottom quarter)

What this study adds
Penalization under the Hospital Acquired Condition Reduction Program was not associated with a significant change in the rate of hospital acquired conditions, 30 day readmission, or 30 day mortality

By penalizing hospitals that care for a higher share of patients with low socioeconomic status, the program could exacerbate inequities in care

Web extra Extra material supplied by authors


Web appendix: Supplemental material

 Contributors: RS, DS, EA, and AMR were responsible for the study concept and design. RS, UN, JBD, AMR, and BG contributed to the acquisition, analysis, and interpretation of the data. RS drafted the manuscript. All the authors were responsible for the critical revision of the manuscript for important intellectual content. RS, UN, AMR, and BG undertook the statistical analysis. JBD and AMR obtained funding. JBD, AMR, and TAE provided administrative, technical, and material support. The corresponding author attests that all listed authors meet authorship criteria and that no others meeting the criteria have been omitted. AMR is guarantor.

Funding: AR acknowledges funding from the National Institute on Aging (grant R01AG047932) and the Agency for Healthcare Research and Quality (R01 HS026244). JBD acknowledges funding from the National Institute on Aging (grant R01AG039434). The funding agencies had no involvement in the analysis presented herein.

Competing interests: All authors have completed the ICMJE uniform disclosure form at www.icmje.org/coi_disclosure.pdf and declare: support from the National Institute on Aging and the Agency for Healthcare Research and Quality for the submitted work; JBD has a financial interest in ArborMetrix, which has no role in the present analysis; no other financial relationships with any organizations that might have an interest in the submitted work in the previous three years; no other relationships or activities that could appear to have influenced the submitted work.

Ethical approval: This study was deemed exempt from oversight by the University of Michigan’s institutional review board.

Data sharing: The analytical files are not available for sharing. The analytical code will be made publicly available and is available on request.

The senior author affirms that the manuscript is an honest, accurate, and transparent account of the study being reported; that no important aspects of the study have been omitted; and that any discrepancies from the study as planned (and, if relevant, registered) have been explained.
==== Refs
1 Agency for Healthcare Research and Quality. 2015 National Healthcare Quality and Disparities Report and 5th Anniversary Update on the National Quality Strategy. 2016. https://www.ahrq.gov/sites/default/files/wysiwyg/research/findings/nhqrdr/nhqdr15/2015nhqdr.pdf

2 
Hsu E Lin D Evans SJ  
Doing well by doing good: assessing the cost savings of an intervention to reduce central line-associated bloodstream infections in a Hawaii hospital . Am J Med Qual 
2014 ;29 :13 -9 . 10.1177/1062860613486173  
23652336 
3 Center for Medicare and Medicaid Services. Federal Register. Vol 79. 2014. https://www.gpo.gov/fdsys/pkg/FR-2014-10-03/pdf/2014-23630.pdf

4 Scott RD II. The direct medical costs of healthcare-associated infections in US hospitals and the benefits of prevention. 2009. https://www.cdc.gov/hai/pdfs/hai/scott_costpaper.pdf

5 
Klevens RM Edwards JR Richards CL Jr 
Estimating health care-associated infections and deaths in U.S. hospitals, 2002 . Public Health Rep 
2007 ;122 :160 -6 . 10.1177/003335490712200205  
17357358 
6 Centers for Medicare and Medicaid Sevices. Hospital-acquired condition reductoin program fiscal year 2018 fact sheet. 2018. https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/AcuteInpatientPPS/Downloads/FY2018-HAC-Reduction-Program-Fact-Sheet.pdf

7 
Ibrahim AM Dimick JB Sinha SS Hollingsworth JM Nuliyalu U Ryan AM  
Association of coded severity with readmission reduction after the hospital readmissions reduction program . JAMA Intern Med 
2018 ;178 :290 -2 . 10.1001/jamainternmed.2017.6148  
29131896 
8 
Markovitz AA Ryan AM  
Pay-for-performance: disappointing results or masked heterogeneity? 
Med Care Res Rev 
2017 ;74 :3 -78 . 10.1177/1077558715619282  
26743502 
9 
Rajaram R Chung JW Kinnier CV  
Hospital characteristics associated with penalties in the Centers for Medicare & Medicaid Services Hospital-Acquired Condition Reduction Program . JAMA 
2015 ;314 :375 -83 . 10.1001/jama.2015.8609  
26219055 
10 
Navathe AS Liao JM Polsky D  
Comparison of hospitals participating in Medicare’s voluntary and mandatory orthopedic bundle programs . Health Aff (Millwood) 
2018 ;37 :854 -63 . 10.1377/hlthaff.2017.1358  
29863929 
11 
Zuckerman RB Sheingold SH Orav EJ Ruhter J Epstein AM  
Readmissions, Observation, and the Hospital Readmissions Reduction Program . N Engl J Med 
2016 ;374 :1543 -51 . 10.1056/NEJMsa1513024  
26910198 
12 Center for Medicare and Medicaid Services. Medicare Program - general information. 2018 [cited 2019 Mar 2]. https://www.cms.gov/Medicare/Medicare-General-Information/MedicareGenInfo/index.html

13 Centers for Medicare and Medicaid Sevices. FY 2015 final rule tables, table 17. FY2015 IPPS final rule. 2015 [cited 2018 Jun 10]. https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/AcuteInpatientPPS/FY2015-IPPS-Final-Rule-Home-Page-Items/FY2015-Final-Rule-Tables.html

14 Agency for Healthcare Research and Quality. Quality indicators software, version 6.0.2. 2016.
15 
Shoag J Halpern J Eisner B  
Efficacy of prostate-specific antigen screening: Use of regression discontinuity in the plco cancer screening trial . JAMA Oncol 
2015 ;1 :984 -6 . 10.1001/jamaoncol.2015.2993  
26291583 
16 
Moscoe E Bor J Bärnighausen T  
Regression discontinuity designs are underutilized in medicine, epidemiology, and public health: a review of current and best practice . J Clin Epidemiol 
2015 ;68 :122 -33 . 10.1016/j.jclinepi.2014.06.021  
25579639 
17 
Venkataramani AS Bor J Jena AB  
Regression discontinuity designs in healthcare research . BMJ 
2016 ;352 :i1216 . 10.1136/bmj.i1216  
26977086 
18 
Desai S McWilliams JM  
Consequences of the 340B Drug Pricing Program . N Engl J Med 
2018 ;378 :539 -48 . 10.1056/NEJMsa1706475  
29365282 
19 Centers for Medicare and Medicaid Sevices. Fiscal Year 2015 results for the CMS Hospital-Acquired Condition Reduction Program and Hospital Value-Based Purchasing Program. 2014 [cited 2018 Jun 15]. https://www.cms.gov/newsroom/fact-sheets/fiscal-year-2015-results-cms-hospital-acquired-condition-reduction-program-and-hospital-value-based

20 Imbens G, Lemieux T. Regression discontinuity designs: a guide to practice. 2007. Report No: Working Paper No 13039.
21 
Roberts ET Zaslavsky AM McWilliams JM  
The value-based payment modifier: Program outcomes and implications for disparities . Ann Intern Med 
2018 ;168 :255 -65 . 10.7326/M17-1740  
29181511 
22 
Lee DS Lemieux T  
Regression discontinuity designs in econometrics . J Econ Lit 
2010 ;48 
10.1257/jel.48.2.281 .
23 
Chay KY McEwan PJ  
The central role of noise in evaluating interventions that use test scores to rank schools . Am Econ Rev 
2005 ;95 :1237 -58 
10.1257/0002828054825529 .
24 
Calonico S Cattaneo MD Titunik R  
Robust data-drive inference in the regression-discontinuity design . Stata J 
2014 ;14 :909 -46 
10.1177/1536867X1401400413 .
25 
de la Cuesta B Imai K  
Misunderstandings about the regression discontinuity design in the study of close elections . Annu Rev Polit Sci 
2016 ;19 :375 -96 . 10.1146/annurev-polisci-032015-010115 .
26 Centers for Medicare and Medicaid Sevices. Case Mix Index. [cited 2018 Jun 15]. https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/AcuteInpatientPPS/Acute-Inpatient-Files-for-Download-Items/CMS022630.html

27 
Prasad V Jena AB  
Prespecified falsification end points: can they validate true observational associations? 
JAMA 
2013 ;309 :241 -2 . 10.1001/jama.2012.96867  
23321761 
28 
Fuller RL Goldfield NI Averill RF Hughes JS  
Is the CMS Hospital-Acquired Condition Reduction Program a valid measure of hospital performance? 
Am J Med Qual 
2017 ;32 :254 -60 . 10.1177/1062860616640883  
27037265 
29 
Doran T Fullwood C Kontopantelis E Reeves D  
Effect of financial incentives on inequalities in the delivery of primary clinical care in England: analysis of clinical activity indicators for the quality and outcomes framework . Lancet 
2008 ;372 :728 -36 . 10.1016/S0140-6736(08)61123-X  
18701159 
30 
Girault A Bellanger M Lalloué B Loirat P Moisdon JC Minvielle E  
Implementing hospital pay-for-performance: Lessons learned from the French pilot program. 
Health Policy , 2017 .
31 
Milstein R Schreyoegg J  
Pay for performance in the inpatient sector: A review of 34 P4P programs in 14 OECD countries . Health Policy 
2016 ;120 :1125 -40 . 10.1016/j.healthpol.2016.08.009  
27745916 
32 
Eijkenaar F Emmert M Scheppach M Schöffski O  
Effects of pay for performance in health care: a systematic review of systematic reviews . Health Policy 
2013 ;110 :115 -30 . 10.1016/j.healthpol.2013.01.008  
23380190 
33 
Desai NR Ross JS Kwon JY  
Association between hospital penalty status under the Hospital Readmission Reduction Program and readmission rates for target and nontarget conditions . JAMA 
2016 ;316 :2647 -56 . 10.1001/jama.2016.18533  
28027367 
34 
Press MJ Scanlon DP Ryan AM  
Limits of readmission rates in measuring hospital quality suggest the need for added metrics . Health Aff (Millwood) 
2013 ;32 :1083 -91 . 10.1377/hlthaff.2012.0518  
23733983 
35 PSI 90 fact sheet. Agency for Healthcare Research and Quality (AHRQ) quality indicators (QIs) fact sheet. 2016. Pages 1-8. https://www.qualityindicators.ahrq.gov/News/PSI90_Factsheet_FAQ.pdf

36 
Cassidy A  
Health policy brief: Medicare’s Hospital-Acquired Condition Reduction Program . Health Aff 
2015 .
37 114th Congress (2015-2016). HR34 21st century cures act. 2016. https://www.congress.gov/bill/114th-congress/house-bill/34/

